{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9867325c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 12:05:35.649621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from attrdict import AttrDict\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "\n",
    "from src import (\n",
    "    CONFIG_CLASSES,\n",
    "    TOKENIZER_CLASSES,\n",
    "    MODEL_FOR_SEQUENCE_CLASSIFICATION,\n",
    "    set_seed,\n",
    "    compute_metrics\n",
    ")\n",
    "\n",
    "from processor import seq_cls_load_and_cache_examples as load_and_cache_examples\n",
    "from processor import seq_cls_tasks_num_labels as tasks_num_labels   \n",
    "from processor import seq_cls_processors as processors\n",
    "from processor import seq_cls_output_modes as output_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c406fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'wellness' \n",
    "config_dir = '/home/ubuntu/chatbot/code/config/'\n",
    "config_file = 'koelectra-base.json'\n",
    "\n",
    "with open(os.path.join(config_dir, task, config_file)) as f:\n",
    "    args = AttrDict(json.load(f))\n",
    "\n",
    "args.output_dir = os.path.join(args.ckpt_dir, args.output_dir)\n",
    "set_seed(args)   # seed 값 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14125738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'task': 'wellness', 'data_dir': 'data', 'ckpt_dir': 'ckpt', 'train_file': '/home/ubuntu/chatbot/dataset/Wellness_Conversation_intent_train.tsv', 'dev_file': '/home/ubuntu/chatbot/dataset/Wellness_Conversation_intent_val.tsv', 'test_file': '/home/ubuntu/chatbot/dataset/Wellness_Conversation_intent_test.tsv', 'evaluate_test_during_training': True, 'eval_all_checkpoints': True, 'save_optimizer': False, 'do_lower_case': False, 'do_train': True, 'do_eval': True, 'max_seq_len': 128, 'num_train_epochs': 50, 'weight_decay': 0.0, 'gradient_accumulation_steps': 1, 'adam_epsilon': 1e-08, 'warmup_proportion': 0, 'max_steps': -1, 'max_grad_norm': 1.0, 'no_cuda': False, 'model_type': 'koelectra-base', 'model_name_or_path': 'monologg/koelectra-base-discriminator', 'output_dir': 'ckpt/koelectra-base-wellness-ckpt', 'seed': 42, 'train_batch_size': 32, 'eval_batch_size': 128, 'logging_steps': 2000, 'save_steps': 2000, 'learning_rate': 5e-05})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cabec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = processors[args.task](args) \n",
    "labels = processor.get_labels()\n",
    "\n",
    "# labels\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d05e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraConfig {\n",
       "  \"architectures\": [\n",
       "    \"ElectraForPreTraining\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"embedding_size\": 768,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"0\",\n",
       "    \"1\": \"1\",\n",
       "    \"10\": \"10\",\n",
       "    \"11\": \"11\",\n",
       "    \"12\": \"12\",\n",
       "    \"13\": \"13\",\n",
       "    \"14\": \"14\",\n",
       "    \"15\": \"15\",\n",
       "    \"16\": \"16\",\n",
       "    \"17\": \"17\",\n",
       "    \"18\": \"18\",\n",
       "    \"2\": \"2\",\n",
       "    \"3\": \"3\",\n",
       "    \"4\": \"4\",\n",
       "    \"5\": \"5\",\n",
       "    \"6\": \"6\",\n",
       "    \"7\": \"7\",\n",
       "    \"8\": \"8\",\n",
       "    \"9\": \"9\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"0\": 0,\n",
       "    \"1\": 1,\n",
       "    \"10\": 10,\n",
       "    \"11\": 11,\n",
       "    \"12\": 12,\n",
       "    \"13\": 13,\n",
       "    \"14\": 14,\n",
       "    \"15\": 15,\n",
       "    \"16\": 16,\n",
       "    \"17\": 17,\n",
       "    \"18\": 18,\n",
       "    \"2\": 2,\n",
       "    \"3\": 3,\n",
       "    \"4\": 4,\n",
       "    \"5\": 5,\n",
       "    \"6\": 6,\n",
       "    \"7\": 7,\n",
       "    \"8\": 8,\n",
       "    \"9\": 9\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"electra\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"summary_activation\": \"gelu\",\n",
       "  \"summary_last_dropout\": 0.1,\n",
       "  \"summary_type\": \"first\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.21.0\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32200\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = CONFIG_CLASSES[args.model_type].from_pretrained(   # ElectraConfig.from_pretrained\n",
    "        args.model_name_or_path,\n",
    "        num_labels=tasks_num_labels[args.task],   # args.task: wellness, num_labels = 19 \n",
    "        id2label={str(i): label for i, label in enumerate(labels)},   # labels: ['0', '1', '2', ... ,'18']\n",
    "        label2id={label: i for i, label in enumerate(labels)},\n",
    ")\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ef94983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TOKENIZER_CLASSES[args.model_type].from_pretrained(   # model_type: koelectra-base, ElectraTokenizer \n",
    "    args.model_name_or_path,\n",
    "    do_lower_case=args.do_lower_case,\n",
    "    \n",
    ")\n",
    "\n",
    "model = MODEL_FOR_SEQUENCE_CLASSIFICATION[args.model_type].from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b0d29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32200, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbeca3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/ubuntu/chatbot/code/model/'\n",
    "model_name = 'KoELECTRA_intent.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5cab9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "load_model = MODEL_FOR_SEQUENCE_CLASSIFICATION[args.model_type].from_pretrained(\n",
    "    args.model_name_or_path,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ca1c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32200, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.device = \"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\"\n",
    "\n",
    "load_model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd476a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model.load_state_dict(torch.load(os.path.join(model_path, model_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e628d4",
   "metadata": {},
   "source": [
    "'''\n",
    "train_dataset: /home/ubuntu/chatbot/dataset/Wellness_Conversation_intent_train.tsv\n",
    "test_dataset: /home/ubuntu/chatbot/dataset/Wellness_Conversation_intent_test.tsv\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c7407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_and_cache_examples(args, tokenizer, mode=\"train\") if args.train_file else None\n",
    "dev_dataset = load_and_cache_examples(args, tokenizer, mode=\"dev\") if args.dev_file else None\n",
    "test_dataset = load_and_cache_examples(args, tokenizer, mode=\"test\") if args.test_file else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b543ae15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(args, model, test_dataset):\n",
    "    results = {}\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=args.eval_batch_size)\n",
    "\n",
    "    preds = None\n",
    "    out_label_ids = None\n",
    "\n",
    "    for batch in progress_bar(test_dataloader):\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(args.device) for t in batch)   # args.device: cuda \n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = {\n",
    "                \"input_ids\": batch[0],\n",
    "                \"attention_mask\": batch[1],\n",
    "                \"labels\": batch[3]\n",
    "            }\n",
    "            if args.model_type not in [\"distilkobert\", \"xlm-roberta\"]:\n",
    "                inputs[\"token_type_ids\"] = batch[2]  # Distilkobert, XLM-Roberta don't use segment_ids\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]  \n",
    "        \n",
    "        if preds is None:   # 초기 \n",
    "            preds = logits.detach().cpu().numpy()   # 예측 확률 \n",
    "            out_label_ids = inputs[\"labels\"].detach().cpu().numpy()\n",
    "        else:\n",
    "            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)  \n",
    "            out_label_ids = np.append(out_label_ids, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    if output_modes[args.task] == \"classification\":\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        \n",
    "    return preds, out_label_ids  # label_idx  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af2f737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='31' class='' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [31/31 00:02&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3936, 3936)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_true = get_label(args, load_model, test_dataset)\n",
    "\n",
    "len(y_pred), len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ba2ae01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true[1], y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25e6700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['우울감', '슬픔', '외로움', '분노', '무기력', '감정조절이상', '상실감', '식욕저하', '식욕증가', \\\n",
    "       '불면', '초조함', '피로', '죄책감', '집중력저하', '자신감저하', '자존감저하', '절망감', '자살충동', '불안']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a40c344a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>491</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>214</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4   5   6    7   8    9    10   11   12  13  14   15  \\\n",
       "0   272    8    5    1   10   1   0    7   0    7    8    2    2   0   0    6   \n",
       "1     4  301    2   14    6   1   0    0   0    1    4    0   16   0   0    3   \n",
       "2     3    6  122    1    7   4   0    1   0    2    3    0    0   0   1    0   \n",
       "3     0    3    0  178    6   2   0    2   0    2   13    0    9   0   0    0   \n",
       "4     8    4    2    5  198   5   1    3   0    4    7    6    3   1   1    1   \n",
       "5     2    3    1    7    3  29   0    0   0    0    3    0    3   0   1    1   \n",
       "6     0    1    0    0    0   0  42    0   0    0    0    0    1   0   0    0   \n",
       "7     1    1    0    0    5   0   0  195  12    1    3    0    0   0   0    0   \n",
       "8     0    0    0    0    0   1   0    4  82    0    0    0    0   0   0    0   \n",
       "9     5    4    1    1    2   0   0    1   0  342    8    6    0   0   0    0   \n",
       "10    7    3    1    7    6   2   0    2   1    6  491    3    1   1   1    2   \n",
       "11    2    1    0    0    8   0   0    1   0   13    0  221    0   0   0    1   \n",
       "12    1    8    0   11    2   2   0    0   0    0    5    0  201   0   0    4   \n",
       "13    1    0    0    0    1   0   0    0   0    0    1    1    0  44   0    1   \n",
       "14    1    1    0    1    1   3   0    0   0    0    5    1    1   0  42    7   \n",
       "15    3    0    0    1    2   0   0    1   0    0    6    0    6   0   8  214   \n",
       "16    4    3    0    3    4   2   1    0   0    0    2    2    3   0   2    6   \n",
       "17    0    0    0    4    3   0   0    1   1    4    1    0    2   0   0    0   \n",
       "18    1    7    0    0    0   0   0    0   0    1   28    0    0   0   0    0   \n",
       "\n",
       "     16   17   18  \n",
       "0     0    2    0  \n",
       "1     4    1    1  \n",
       "2     2    2    1  \n",
       "3     0    2    0  \n",
       "4     3    6    0  \n",
       "5     1    0    0  \n",
       "6     0    0    0  \n",
       "7     0    1    0  \n",
       "8     0    0    0  \n",
       "9     0    1    2  \n",
       "10    2    0    4  \n",
       "11    0    2    0  \n",
       "12    1    1    0  \n",
       "13    0    0    0  \n",
       "14    1    0    0  \n",
       "15    4    0    0  \n",
       "16  108    4    0  \n",
       "17    0  113    0  \n",
       "18    0    1  146  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , confusion_matrix, f1_score, classification_report\n",
    "\n",
    "confusion_mt = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2281d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>우울감</th>\n",
       "      <th>슬픔</th>\n",
       "      <th>외로움</th>\n",
       "      <th>분노</th>\n",
       "      <th>무기력</th>\n",
       "      <th>감정조절이상</th>\n",
       "      <th>상실감</th>\n",
       "      <th>식욕저하</th>\n",
       "      <th>식욕증가</th>\n",
       "      <th>불면</th>\n",
       "      <th>초조함</th>\n",
       "      <th>피로</th>\n",
       "      <th>죄책감</th>\n",
       "      <th>집중력저하</th>\n",
       "      <th>자신감저하</th>\n",
       "      <th>자존감저하</th>\n",
       "      <th>절망감</th>\n",
       "      <th>자살충동</th>\n",
       "      <th>불안</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>우울감</th>\n",
       "      <td>272</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>슬픔</th>\n",
       "      <td>4</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>외로움</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>분노</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>무기력</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>감정조절이상</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>상실감</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>식욕저하</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>식욕증가</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불면</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>초조함</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>491</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>피로</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>죄책감</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>집중력저하</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자신감저하</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자존감저하</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>214</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>절망감</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자살충동</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불안</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        우울감   슬픔  외로움   분노  무기력  감정조절이상  상실감  식욕저하  식욕증가   불면  초조함   피로  죄책감  \\\n",
       "우울감     272    8    5    1   10       1    0     7     0    7    8    2    2   \n",
       "슬픔        4  301    2   14    6       1    0     0     0    1    4    0   16   \n",
       "외로움       3    6  122    1    7       4    0     1     0    2    3    0    0   \n",
       "분노        0    3    0  178    6       2    0     2     0    2   13    0    9   \n",
       "무기력       8    4    2    5  198       5    1     3     0    4    7    6    3   \n",
       "감정조절이상    2    3    1    7    3      29    0     0     0    0    3    0    3   \n",
       "상실감       0    1    0    0    0       0   42     0     0    0    0    0    1   \n",
       "식욕저하      1    1    0    0    5       0    0   195    12    1    3    0    0   \n",
       "식욕증가      0    0    0    0    0       1    0     4    82    0    0    0    0   \n",
       "불면        5    4    1    1    2       0    0     1     0  342    8    6    0   \n",
       "초조함       7    3    1    7    6       2    0     2     1    6  491    3    1   \n",
       "피로        2    1    0    0    8       0    0     1     0   13    0  221    0   \n",
       "죄책감       1    8    0   11    2       2    0     0     0    0    5    0  201   \n",
       "집중력저하     1    0    0    0    1       0    0     0     0    0    1    1    0   \n",
       "자신감저하     1    1    0    1    1       3    0     0     0    0    5    1    1   \n",
       "자존감저하     3    0    0    1    2       0    0     1     0    0    6    0    6   \n",
       "절망감       4    3    0    3    4       2    1     0     0    0    2    2    3   \n",
       "자살충동      0    0    0    4    3       0    0     1     1    4    1    0    2   \n",
       "불안        1    7    0    0    0       0    0     0     0    1   28    0    0   \n",
       "\n",
       "        집중력저하  자신감저하  자존감저하  절망감  자살충동   불안  \n",
       "우울감         0      0      6    0     2    0  \n",
       "슬픔          0      0      3    4     1    1  \n",
       "외로움         0      1      0    2     2    1  \n",
       "분노          0      0      0    0     2    0  \n",
       "무기력         1      1      1    3     6    0  \n",
       "감정조절이상      0      1      1    1     0    0  \n",
       "상실감         0      0      0    0     0    0  \n",
       "식욕저하        0      0      0    0     1    0  \n",
       "식욕증가        0      0      0    0     0    0  \n",
       "불면          0      0      0    0     1    2  \n",
       "초조함         1      1      2    2     0    4  \n",
       "피로          0      0      1    0     2    0  \n",
       "죄책감         0      0      4    1     1    0  \n",
       "집중력저하      44      0      1    0     0    0  \n",
       "자신감저하       0     42      7    1     0    0  \n",
       "자존감저하       0      8    214    4     0    0  \n",
       "절망감         0      2      6  108     4    0  \n",
       "자살충동        0      0      0    0   113    0  \n",
       "불안          0      0      0    0     1  146  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mt.columns = columns \n",
    "confusion_mt.index = columns \n",
    "\n",
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99f35b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.849"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = round(f1_score(y_true, y_pred, average='micro'), 3) \n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd8b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd4952cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108163798264329"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f616200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       331\n",
      "           1       0.85      0.84      0.85       358\n",
      "           2       0.91      0.79      0.84       155\n",
      "           3       0.76      0.82      0.79       217\n",
      "           4       0.75      0.77      0.76       258\n",
      "           5       0.56      0.54      0.55        54\n",
      "           6       0.95      0.95      0.95        44\n",
      "           7       0.89      0.89      0.89       219\n",
      "           8       0.85      0.94      0.90        87\n",
      "           9       0.89      0.92      0.90       373\n",
      "          10       0.84      0.91      0.87       540\n",
      "          11       0.91      0.89      0.90       249\n",
      "          12       0.81      0.85      0.83       236\n",
      "          13       0.96      0.90      0.93        49\n",
      "          14       0.75      0.66      0.70        64\n",
      "          15       0.87      0.87      0.87       245\n",
      "          16       0.86      0.75      0.80       144\n",
      "          17       0.83      0.88      0.85       129\n",
      "          18       0.95      0.79      0.86       184\n",
      "\n",
      "    accuracy                           0.85      3936\n",
      "   macro avg       0.85      0.83      0.84      3936\n",
      "weighted avg       0.85      0.85      0.85      3936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8978ef04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '           0       0.86      0.82      0.84       331',\n",
       " '           1       0.85      0.84      0.85       358',\n",
       " '           2       0.91      0.79      0.84       155',\n",
       " '           3       0.76      0.82      0.79       217',\n",
       " '           4       0.75      0.77      0.76       258',\n",
       " '           5       0.56      0.54      0.55        54',\n",
       " '           6       0.95      0.95      0.95        44',\n",
       " '           7       0.89      0.89      0.89       219',\n",
       " '           8       0.85      0.94      0.90        87',\n",
       " '           9       0.89      0.92      0.90       373',\n",
       " '          10       0.84      0.91      0.87       540',\n",
       " '          11       0.91      0.89      0.90       249',\n",
       " '          12       0.81      0.85      0.83       236',\n",
       " '          13       0.96      0.90      0.93        49',\n",
       " '          14       0.75      0.66      0.70        64',\n",
       " '          15       0.87      0.87      0.87       245',\n",
       " '          16       0.86      0.75      0.80       144',\n",
       " '          17       0.83      0.88      0.85       129',\n",
       " '          18       0.95      0.79      0.86       184',\n",
       " '',\n",
       " '    accuracy                           0.85      3936',\n",
       " '   macro avg       0.85      0.83      0.84      3936',\n",
       " 'weighted avg       0.85      0.85      0.85      3936',\n",
       " '']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr = classification_report(y_true, y_pred).split('\\n')\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a065c457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70875a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['precision', 'recall', 'f1-score', 'support'],\n",
       " [],\n",
       " ['0', '0.86', '0.82', '0.84', '331'],\n",
       " ['1', '0.85', '0.84', '0.85', '358'],\n",
       " ['2', '0.91', '0.79', '0.84', '155'],\n",
       " ['3', '0.76', '0.82', '0.79', '217'],\n",
       " ['4', '0.75', '0.77', '0.76', '258'],\n",
       " ['5', '0.56', '0.54', '0.55', '54'],\n",
       " ['6', '0.95', '0.95', '0.95', '44'],\n",
       " ['7', '0.89', '0.89', '0.89', '219'],\n",
       " ['8', '0.85', '0.94', '0.90', '87'],\n",
       " ['9', '0.89', '0.92', '0.90', '373'],\n",
       " ['10', '0.84', '0.91', '0.87', '540'],\n",
       " ['11', '0.91', '0.89', '0.90', '249'],\n",
       " ['12', '0.81', '0.85', '0.83', '236'],\n",
       " ['13', '0.96', '0.90', '0.93', '49'],\n",
       " ['14', '0.75', '0.66', '0.70', '64'],\n",
       " ['15', '0.87', '0.87', '0.87', '245'],\n",
       " ['16', '0.86', '0.75', '0.80', '144'],\n",
       " ['17', '0.83', '0.88', '0.85', '129'],\n",
       " ['18', '0.95', '0.79', '0.86', '184'],\n",
       " [],\n",
       " ['accuracy', '0.85', '3936'],\n",
       " ['macro', 'avg', '0.85', '0.83', '0.84', '3936'],\n",
       " ['weighted', 'avg', '0.85', '0.85', '0.85', '3936'],\n",
       " []]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = []\n",
    "\n",
    "for idx, line in enumerate(cr):\n",
    "    clr_df.append([])\n",
    "    if line == '':\n",
    "        continue\n",
    "    \n",
    "    word_list = line.strip().split(' ')\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word != '':\n",
    "            clr_df[idx].append(word)\n",
    "\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9622979",
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_df[-2][0] = ' '.join([clr_df[-2][0], clr_df[-2][1]])\n",
    "clr_df[-3][0] = ' '.join([clr_df[-3][0], clr_df[-3][1]])\n",
    "clr_df[-4].insert(1, ' ')\n",
    "clr_df[-4].insert(2, ' ')\n",
    "clr_df[0].insert(0, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "714db662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'precision', 'recall', 'f1-score', 'support'],\n",
       " ['0', '0.86', '0.82', '0.84', '331'],\n",
       " ['1', '0.85', '0.84', '0.85', '358'],\n",
       " ['2', '0.91', '0.79', '0.84', '155'],\n",
       " ['3', '0.76', '0.82', '0.79', '217'],\n",
       " ['4', '0.75', '0.77', '0.76', '258'],\n",
       " ['5', '0.56', '0.54', '0.55', '54'],\n",
       " ['6', '0.95', '0.95', '0.95', '44'],\n",
       " ['7', '0.89', '0.89', '0.89', '219'],\n",
       " ['8', '0.85', '0.94', '0.90', '87'],\n",
       " ['9', '0.89', '0.92', '0.90', '373'],\n",
       " ['10', '0.84', '0.91', '0.87', '540'],\n",
       " ['11', '0.91', '0.89', '0.90', '249'],\n",
       " ['12', '0.81', '0.85', '0.83', '236'],\n",
       " ['13', '0.96', '0.90', '0.93', '49'],\n",
       " ['14', '0.75', '0.66', '0.70', '64'],\n",
       " ['15', '0.87', '0.87', '0.87', '245'],\n",
       " ['16', '0.86', '0.75', '0.80', '144'],\n",
       " ['17', '0.83', '0.88', '0.85', '129'],\n",
       " ['18', '0.95', '0.79', '0.86', '184'],\n",
       " ['accuracy', ' ', ' ', '0.85', '3936'],\n",
       " ['macro avg', '0.85', '0.83', '0.84', '3936'],\n",
       " ['weighted avg', '0.85', '0.85', '0.85', '3936']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df[-2].pop(1)\n",
    "clr_df[-3].pop(1)\n",
    "clr_df.pop(1)\n",
    "clr_df.pop(-1)\n",
    "clr_df.pop(-4)\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98bfa325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.86</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>accuracy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index precision recall f1-score support\n",
       "0              0      0.86   0.82     0.84     331\n",
       "1              1      0.85   0.84     0.85     358\n",
       "2              2      0.91   0.79     0.84     155\n",
       "3              3      0.76   0.82     0.79     217\n",
       "4              4      0.75   0.77     0.76     258\n",
       "5              5      0.56   0.54     0.55      54\n",
       "6              6      0.95   0.95     0.95      44\n",
       "7              7      0.89   0.89     0.89     219\n",
       "8              8      0.85   0.94     0.90      87\n",
       "9              9      0.89   0.92     0.90     373\n",
       "10            10      0.84   0.91     0.87     540\n",
       "11            11      0.91   0.89     0.90     249\n",
       "12            12      0.81   0.85     0.83     236\n",
       "13            13      0.96   0.90     0.93      49\n",
       "14            14      0.75   0.66     0.70      64\n",
       "15            15      0.87   0.87     0.87     245\n",
       "16            16      0.86   0.75     0.80     144\n",
       "17            17      0.83   0.88     0.85     129\n",
       "18            18      0.95   0.79     0.86     184\n",
       "19      accuracy                      0.85    3936\n",
       "20     macro avg      0.85   0.83     0.84    3936\n",
       "21  weighted avg      0.85   0.85     0.85    3936"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = pd.DataFrame(clr_df[1:], columns=clr_df[0])\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf270f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.86</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall f1-score support\n",
       "index                                         \n",
       "0                 0.86   0.82     0.84     331\n",
       "1                 0.85   0.84     0.85     358\n",
       "2                 0.91   0.79     0.84     155\n",
       "3                 0.76   0.82     0.79     217\n",
       "4                 0.75   0.77     0.76     258\n",
       "5                 0.56   0.54     0.55      54\n",
       "6                 0.95   0.95     0.95      44\n",
       "7                 0.89   0.89     0.89     219\n",
       "8                 0.85   0.94     0.90      87\n",
       "9                 0.89   0.92     0.90     373\n",
       "10                0.84   0.91     0.87     540\n",
       "11                0.91   0.89     0.90     249\n",
       "12                0.81   0.85     0.83     236\n",
       "13                0.96   0.90     0.93      49\n",
       "14                0.75   0.66     0.70      64\n",
       "15                0.87   0.87     0.87     245\n",
       "16                0.86   0.75     0.80     144\n",
       "17                0.83   0.88     0.85     129\n",
       "18                0.95   0.79     0.86     184\n",
       "accuracy                          0.85    3936\n",
       "macro avg         0.85   0.83     0.84    3936\n",
       "weighted avg      0.85   0.85     0.85    3936"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df.index = clr_df['index']\n",
    "\n",
    "del clr_df['index']\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "199064c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.86</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall f1-score support\n",
       "index                                         \n",
       "6                 0.95   0.95     0.95      44\n",
       "13                0.96   0.90     0.93      49\n",
       "11                0.91   0.89     0.90     249\n",
       "8                 0.85   0.94     0.90      87\n",
       "9                 0.89   0.92     0.90     373\n",
       "7                 0.89   0.89     0.89     219\n",
       "15                0.87   0.87     0.87     245\n",
       "10                0.84   0.91     0.87     540\n",
       "18                0.95   0.79     0.86     184\n",
       "accuracy                          0.85    3936\n",
       "17                0.83   0.88     0.85     129\n",
       "weighted avg      0.85   0.85     0.85    3936\n",
       "1                 0.85   0.84     0.85     358\n",
       "2                 0.91   0.79     0.84     155\n",
       "macro avg         0.85   0.83     0.84    3936\n",
       "0                 0.86   0.82     0.84     331\n",
       "12                0.81   0.85     0.83     236\n",
       "16                0.86   0.75     0.80     144\n",
       "3                 0.76   0.82     0.79     217\n",
       "4                 0.75   0.77     0.76     258\n",
       "14                0.75   0.66     0.70      64\n",
       "5                 0.56   0.54     0.55      54"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df.sort_values(by='f1-score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3e6fd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df_1 = clr_df[:11]\n",
    "clr_df_2 = clr_df[11:]\n",
    "\n",
    "len(clr_df_1), len(clr_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41efdffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.85</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.84</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision recall f1-score support\n",
       "index                                  \n",
       "0          0.86   0.82     0.84     331\n",
       "1          0.85   0.84     0.85     358\n",
       "2          0.91   0.79     0.84     155\n",
       "3          0.76   0.82     0.79     217\n",
       "4          0.75   0.77     0.76     258\n",
       "5          0.56   0.54     0.55      54\n",
       "6          0.95   0.95     0.95      44\n",
       "7          0.89   0.89     0.89     219\n",
       "8          0.85   0.94     0.90      87\n",
       "9          0.89   0.92     0.90     373\n",
       "10         0.84   0.91     0.87     540"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91b94ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.80</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.86</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall f1-score support\n",
       "index                                         \n",
       "11                0.91   0.89     0.90     249\n",
       "12                0.81   0.85     0.83     236\n",
       "13                0.96   0.90     0.93      49\n",
       "14                0.75   0.66     0.70      64\n",
       "15                0.87   0.87     0.87     245\n",
       "16                0.86   0.75     0.80     144\n",
       "17                0.83   0.88     0.85     129\n",
       "18                0.95   0.79     0.86     184\n",
       "accuracy                          0.85    3936\n",
       "macro avg         0.85   0.83     0.84    3936\n",
       "weighted avg      0.85   0.85     0.85    3936"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca0ae643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_idx = list(range(len(columns)))\n",
    "intent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9d41451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize \n",
    "\n",
    "y_true = label_binarize(y_true, classes=intent_idx)\n",
    "y_pred = label_binarize(y_pred, classes=intent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "daaf431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_classes = 19\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict() \n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:,i], y_pred[:,i]) \n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "189c38fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "val = 0\n",
    "\n",
    "# font = {'size': 15}\n",
    "# plt.rc('font', **font)\n",
    "plt.rcParams.update({'font.size': 15, 'font.weight': 'normal'})\n",
    "\n",
    "for idx, i in enumerate(range(n_classes)):\n",
    "    if idx == 6 or idx == 5: \n",
    "        plt.subplot(121+val) \n",
    "        plt.plot(fpr[i], tpr[i], label = f'ROC curve(area = {round(roc_auc[i], 2)}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=18) \n",
    "        plt.ylabel('True Positive Rate', fontsize=18)\n",
    "        plt.title(f'Class {idx}', fontsize=18)\n",
    "        plt.legend(loc='lower right')\n",
    "        val += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c721a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
