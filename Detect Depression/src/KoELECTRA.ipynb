{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c9dbf2",
   "metadata": {},
   "source": [
    "### 1. Environment Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40e256a",
   "metadata": {},
   "source": [
    "#### 1.1 Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e218b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import os \n",
    "import re\n",
    "import time\n",
    "import math\n",
    "import argparse\n",
    "import pymysql\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from attrdict import AttrDict\n",
    "from transformers import ElectraConfig, ElectraTokenizer, ElectraForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401885e",
   "metadata": {},
   "source": [
    "#### 1.2 Setting Default Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2275e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/lamda_00/Depression_paper/data/\"\n",
    "model_path = \"/home/lamda_00/Depression_paper/model/\"\n",
    "model_name = os.path.join(model_path, 'electra_class.pt')\n",
    "ckpt_path = \"/home/lamda_00/Depression_paper/ckpt/\"\n",
    "config_path = \"/home/lamda_00/Depression_paper/config/\"\n",
    "log_path = \"/home/lamda_00/Depression_paper/log/\"\n",
    "config_file = \"koelectra-base.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4f1b19",
   "metadata": {},
   "source": [
    "#### 1.3 Load Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab8dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'model1_label.pickle'), 'rb') as f:\n",
    "    label = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c10afcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'model_train.pickle'), 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(data_path, 'model_dev.pickle'), 'rb') as f:\n",
    "    val_data = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(data_path, 'model_test.pickle'), 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f671f6c4",
   "metadata": {},
   "source": [
    "#### 1.4 Load Pretrained model & tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5552bca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_path, config_file)) as f:\n",
    "    args = AttrDict(json.load(f))\n",
    "    \n",
    "args.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49471d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(args.model_name, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09de0242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['우울감', '무기력', '외로움', '자신감', '자존감', '죄책감', '초조함']\n",
    "tokenizer.add_tokens(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75b8c51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ElectraConfig.from_pretrained(   \n",
    "        args.model_name,\n",
    "        num_labels=20,   \n",
    "        id2label={str(i): label for i, label in enumerate(label.keys())},   # labels: ['0', '1', '2', ... ,'18']\n",
    "        label2id={label: i for i, label in enumerate(label.keys())},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd926fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(args.model_name, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b600dc32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32207, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf4e57f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32207, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c79e9",
   "metadata": {},
   "source": [
    "### 2. Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d9d6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data.label)\n",
    "    \n",
    "    def reset_index(self):\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    # def clear_text(self)  => 전처리 코드를 여기에 넣을 경우 상당히 느려짐\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        return text, label\n",
    "        '''\n",
    "        self.reset_index()\n",
    "        text = self.data.text[idx]\n",
    "        label = self.data.label[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7213136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraProcessor():\n",
    "    def __init__(self, args, tokenizer, truncation=True):\n",
    "        self.tokenizer = tokenizer \n",
    "        self.max_len = args.max_seq_len\n",
    "        self.pad = args.pad\n",
    "        self.batch_size = args.train_batch_size\n",
    "        self.truncation = truncation\n",
    "    \n",
    "    def convert_data(self, data_file):\n",
    "        context2 = None    # single sentence classification\n",
    "        batch_encoding = self.tokenizer.batch_encode_plus(\n",
    "            [(data_file[idx][0], context2) for idx in range(len(data_file))], \n",
    "            max_length = self.max_len,\n",
    "            padding = self.pad,\n",
    "            truncation = self.truncation\n",
    "        )\n",
    "        \n",
    "        features = []\n",
    "        for i in range(len(data_file)):\n",
    "            inputs = {k: batch_encoding[k][i] for k in batch_encoding}\n",
    "            try:\n",
    "                inputs['label'] = data_file[i][1] \n",
    "            except:\n",
    "                inputs['label'] = 0 \n",
    "            features.append(inputs)\n",
    "        \n",
    "        all_input_ids = torch.tensor([f['input_ids'] for f in features], dtype=torch.long)\n",
    "        all_attention_mask = torch.tensor([f['attention_mask'] for f in features], dtype=torch.long)\n",
    "        all_token_type_ids = torch.tensor([f['token_type_ids'] for f in features], dtype=torch.long)\n",
    "        all_labels = torch.tensor([f['label'] for f in features], dtype=torch.long)\n",
    "\n",
    "        dataset = TensorDataset(all_input_ids, all_attention_mask, all_token_type_ids, all_labels)\n",
    "        return dataset\n",
    "    \n",
    "    def convert_sentence(self, sentence_list):   # 사용자 입력 문장 1개 -> 입력 형태 변환\n",
    "        pass\n",
    "    \n",
    "    def shuffle_data(self, dataset, data_type):\n",
    "        if data_type == 'train':\n",
    "            return RandomSampler(dataset)\n",
    "        elif data_type == 'eval' or data_type == 'test':\n",
    "            return SequentialSampler(dataset)\n",
    "        \n",
    "    def load_data(self, dataset, sampler):\n",
    "        return DataLoader(dataset, sampler=sampler, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdecbfd0",
   "metadata": {},
   "source": [
    "class ElectraRegressor(nn.Module):\n",
    "    '''\n",
    "    다중 분류 학습 시 선언하는 클래스 \n",
    "    '''\n",
    "    def __init__(self, electra, config):\n",
    "        # 부모 생성자 초기화, super().__init__(config) 시 오류 발생 \n",
    "        super(ElectraRegressor, self).__init__() \n",
    "        self.electra = electra\n",
    "        self.layer = nn.Linear(config.hidden_size, 128)\n",
    "        self.regressor = nn.Sequential(nn.Dropout(0.1), nn.Linear(128, 6))\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        outputs = self.electra(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids)\n",
    "        logits = outputs.last_hidden_state[:, 0, :]\n",
    "        output = self.layer(logits)\n",
    "        output = self.regressor(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8cb7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraTrainer():\n",
    "    def __init__(self, args, model, train_dataloader, eval_dataloader):\n",
    "        self.args = args \n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.eval_dataloader = eval_dataloader\n",
    "        self.test_dataloader = test_dataloader \n",
    "        \n",
    "    def set_seed(self):\n",
    "        random.seed(self.args.seed)\n",
    "        np.random.seed(self.args.seed)\n",
    "        torch.manual_seed(self.args.seed)\n",
    "        if not self.args.no_cuda and torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(self.args.seed)\n",
    "    \n",
    "    def train(self):\n",
    "        train_acc_list = []; eval_acc_list = [] \n",
    "        train_loss_list = []; eval_loss_list = []\n",
    "        best_acc = 0; best_loss = 3000\n",
    "        nb_eval_steps = 0\n",
    "        t_total = len(self.train_dataloader) // self.args.gradient_accumulation_steps * self.args.num_epochs\n",
    "\n",
    "        optimizer = AdamW(self.model.parameters(), lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(t_total * self.args.warmup_proportion), \\\n",
    "                                                    num_training_steps=t_total)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        for epoch in range(int(self.args.num_epochs)):\n",
    "            train_acc = 0.0; eval_acc = 0.0\n",
    "            train_loss = 0.0; eval_loss = 0.0 \n",
    "\n",
    "            for step, batch in enumerate(self.train_dataloader):\n",
    "                self.model.train()\n",
    "                batch = tuple(t.to(self.args.device) for t in batch)\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                loss = outputs[0]\n",
    "                loss.backward()\n",
    "                train_loss += loss.item()\n",
    "                train_acc += self.calc_accuracy(outputs[1], batch[3])\n",
    "\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                self.model.zero_grad()\n",
    "\n",
    "            train_acc = train_acc / (step + 1)\n",
    "            print(f'epoch: {epoch}, train_acc: {train_acc}')\n",
    "            train_acc_list.append(train_acc)\n",
    "            train_loss_list.append(train_loss)\n",
    "\n",
    "            for step2, batch2 in enumerate(self.eval_dataloader):\n",
    "                self.model.eval()\n",
    "                batch2 = tuple(t.to(self.args.device) for t in batch2)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    inputs = {\n",
    "                        \"input_ids\": batch2[0],\n",
    "                        \"attention_mask\": batch2[1],\n",
    "                        \"token_type_ids\": batch2[2],\n",
    "                        \"labels\": batch2[3]\n",
    "                    }\n",
    "                    outputs = self.model(**inputs)\n",
    "                    tmp_eval_loss, logits = outputs[:2]\n",
    "                    eval_loss += tmp_eval_loss.mean().item()\n",
    "                    eval_acc += self.calc_accuracy(outputs[1], batch2[3]) \n",
    "\n",
    "            eval_loss = eval_loss / (step2 + 1)\n",
    "            eval_acc = eval_acc / (step2 + 1)\n",
    "            eval_acc_list.append(eval_acc)\n",
    "            eval_loss_list.append(eval_loss)\n",
    "\n",
    "        return train_acc_list, train_loss_list, eval_acc_list, eval_loss_list\n",
    "\n",
    "    def calc_accuracy(self, X,Y):\n",
    "        max_vals, max_indices = torch.max(X, 1)\n",
    "        train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "        return train_acc\n",
    "    \n",
    "    def compute_metrics(self, labels, preds):\n",
    "        assert len(preds) == len(labels)\n",
    "        acc = (labels == preds).mean()\n",
    "        return {\"acc\": acc}\n",
    "    \n",
    "    def save_model(self, model_name):\n",
    "        torch.save(self.model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66386a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectraTester():\n",
    "    def __init__(self, args, vocab, load_model):\n",
    "        self.tokenizer = ElectraTokenizer.from_pretrained(args.model_name, do_lower_case=False)\n",
    "        self.tokenizer.add_tokens(vocab)\n",
    "        self.config = ElectraConfig.from_pretrained(\n",
    "            args.model_name,\n",
    "            num_labels=20,   \n",
    "            id2label={str(i): label for i, label in enumerate(label.keys())},\n",
    "            label2id={label: i for i, label in enumerate(label.keys())}\n",
    "        )\n",
    "        self.model = ElectraForSequenceClassification.from_pretrained(args.model_name, config=self.config)\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.model.load_state_dict(torch.load(load_model))\n",
    "        self.model.to(args.device)\n",
    "        \n",
    "    def get_label(self, args, test_dataloader):\n",
    "        results = {}\n",
    "\n",
    "        preds = None\n",
    "        labels = None\n",
    "\n",
    "        for batch in progress_bar(test_dataloader):\n",
    "            self.model.eval()\n",
    "            batch = tuple(t.to(args.device) for t in batch)   # args.device: cuda \n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs = {\n",
    "                    \"input_ids\": batch[0],\n",
    "                    \"attention_mask\": batch[1],\n",
    "                    \"token_type_ids\": batch[2],\n",
    "                    \"labels\": batch[3]\n",
    "                }\n",
    "                outputs = self.model(**inputs)\n",
    "                test_loss, logits = outputs[:2]  \n",
    "        \n",
    "            if preds is None:   # 초기 \n",
    "                preds = logits.detach().cpu().numpy()   # 예측 확률 \n",
    "                labels = inputs[\"labels\"].detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)  \n",
    "                out_label_ids = np.append(labels, inputs[\"labels\"].detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)        \n",
    "        return preds, labels \n",
    "    \n",
    "    def get_f1_score(self, args, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(args, test_dataloader)\n",
    "        return round(f1_score(y_true, y_pred, average='micro'), 3) \n",
    "     \n",
    "    def get_cl_report(self, args, test_dataloader):\n",
    "        y_pred, y_true = self.get_label(args, test_dataloader)\n",
    "        cr = classification_report(y_true, y_pred).split('\\n')\n",
    "        clr_df = []\n",
    "\n",
    "        for idx, line in enumerate(cr):\n",
    "            clr_df.append([])\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            word_list = line.strip().split(' ')\n",
    "\n",
    "            for word in word_list:\n",
    "                if word != '':\n",
    "                    clr_df[idx].append(word)\n",
    "\n",
    "        clr_df[-2][0] = ' '.join([clr_df[-2][0], clr_df[-2][1]])\n",
    "        clr_df[-3][0] = ' '.join([clr_df[-3][0], clr_df[-3][1]])\n",
    "        clr_df[-4].insert(1, ' ')\n",
    "        clr_df[-4].insert(2, ' ')\n",
    "        clr_df[0].insert(0, 'index')\n",
    "\n",
    "        clr_df[-2].pop(1)\n",
    "        clr_df[-3].pop(1)\n",
    "        clr_df.pop(1)\n",
    "        clr_df.pop(-1)\n",
    "        clr_df.pop(-4)\n",
    "        clr_df = pd.DataFrame(clr_df[1:], columns=clr_df[0])\n",
    "        clr_df.index = clr_df['index']\n",
    "\n",
    "        del clr_df['index']\n",
    "        return clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d1a95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ElectraDataset(train_data)\n",
    "val_file = ElectraDataset(val_data)\n",
    "test_file = ElectraDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bacfeb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27496, 6874, 8593)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_file), len(val_file), len(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4417358",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_processor = ElectraProcessor(args, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a727f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = electra_processor.convert_data(train_file)\n",
    "val_dataset = electra_processor.convert_data(val_file)\n",
    "test_dataset = electra_processor.convert_data(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01232724",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = electra_processor.shuffle_data(train_dataset, 'train')\n",
    "val_sampler = electra_processor.shuffle_data(val_dataset, 'eval')\n",
    "test_sampler = electra_processor.shuffle_data(test_dataset, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d4dd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = electra_processor.load_data(train_dataset, train_sampler)\n",
    "val_dataloader = electra_processor.load_data(val_dataset, val_sampler)\n",
    "test_dataloader = electra_processor.load_data(test_dataset, test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1b972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_trainer = ElectraTrainer(args, model, train_dataloader, val_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b6e9d5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamda_00/.local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train_acc: 0.695203488372093\n",
      "epoch: 1, train_acc: 0.8572311046511628\n",
      "epoch: 2, train_acc: 0.9139898255813953\n",
      "epoch: 3, train_acc: 0.9427325581395349\n",
      "epoch: 4, train_acc: 0.9581758720930232\n",
      "epoch: 5, train_acc: 0.9695494186046512\n",
      "epoch: 6, train_acc: 0.9750363372093023\n",
      "epoch: 7, train_acc: 0.9806686046511628\n",
      "epoch: 8, train_acc: 0.9812136627906977\n",
      "epoch: 9, train_acc: 0.9866279069767442\n",
      "epoch: 10, train_acc: 0.9877543604651163\n",
      "epoch: 11, train_acc: 0.9894985465116279\n",
      "epoch: 12, train_acc: 0.9897892441860465\n",
      "epoch: 13, train_acc: 0.9907703488372093\n",
      "epoch: 14, train_acc: 0.9912790697674418\n",
      "epoch: 15, train_acc: 0.9921511627906977\n",
      "epoch: 16, train_acc: 0.9936773255813953\n",
      "epoch: 17, train_acc: 0.993422965116279\n",
      "epoch: 18, train_acc: 0.9949127906976745\n",
      "epoch: 19, train_acc: 0.9952398255813953\n",
      "epoch: 20, train_acc: 0.9944040697674419\n",
      "epoch: 21, train_acc: 0.9949491279069768\n",
      "epoch: 22, train_acc: 0.9967659883720931\n",
      "epoch: 23, train_acc: 0.9967659883720931\n",
      "epoch: 24, train_acc: 0.9962936046511628\n",
      "epoch: 25, train_acc: 0.9962936046511628\n",
      "epoch: 26, train_acc: 0.997202034883721\n",
      "epoch: 27, train_acc: 0.996875\n",
      "epoch: 28, train_acc: 0.997202034883721\n",
      "epoch: 29, train_acc: 0.9976380813953488\n",
      "epoch: 30, train_acc: 0.9974200581395349\n",
      "epoch: 31, train_acc: 0.9981831395348837\n",
      "epoch: 32, train_acc: 0.9981831395348837\n",
      "epoch: 33, train_acc: 0.998328488372093\n",
      "epoch: 34, train_acc: 0.9989098837209303\n",
      "epoch: 35, train_acc: 0.9987281976744186\n",
      "epoch: 36, train_acc: 0.9990188953488373\n",
      "epoch: 37, train_acc: 0.9989098837209303\n",
      "epoch: 38, train_acc: 0.9994549418604651\n",
      "epoch: 39, train_acc: 0.9995276162790697\n",
      "epoch: 40, train_acc: 0.9996002906976744\n",
      "epoch: 41, train_acc: 0.9990915697674418\n",
      "epoch: 42, train_acc: 0.9992369186046511\n",
      "epoch: 43, train_acc: 0.9994549418604651\n",
      "epoch: 44, train_acc: 0.9996002906976744\n",
      "epoch: 45, train_acc: 0.9995639534883721\n",
      "epoch: 46, train_acc: 0.9997093023255814\n",
      "epoch: 47, train_acc: 0.9996002906976744\n",
      "epoch: 48, train_acc: 0.9996366279069767\n",
      "epoch: 49, train_acc: 0.9998546511627907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.695203488372093,\n",
       "  0.8572311046511628,\n",
       "  0.9139898255813953,\n",
       "  0.9427325581395349,\n",
       "  0.9581758720930232,\n",
       "  0.9695494186046512,\n",
       "  0.9750363372093023,\n",
       "  0.9806686046511628,\n",
       "  0.9812136627906977,\n",
       "  0.9866279069767442,\n",
       "  0.9877543604651163,\n",
       "  0.9894985465116279,\n",
       "  0.9897892441860465,\n",
       "  0.9907703488372093,\n",
       "  0.9912790697674418,\n",
       "  0.9921511627906977,\n",
       "  0.9936773255813953,\n",
       "  0.993422965116279,\n",
       "  0.9949127906976745,\n",
       "  0.9952398255813953,\n",
       "  0.9944040697674419,\n",
       "  0.9949491279069768,\n",
       "  0.9967659883720931,\n",
       "  0.9967659883720931,\n",
       "  0.9962936046511628,\n",
       "  0.9962936046511628,\n",
       "  0.997202034883721,\n",
       "  0.996875,\n",
       "  0.997202034883721,\n",
       "  0.9976380813953488,\n",
       "  0.9974200581395349,\n",
       "  0.9981831395348837,\n",
       "  0.9981831395348837,\n",
       "  0.998328488372093,\n",
       "  0.9989098837209303,\n",
       "  0.9987281976744186,\n",
       "  0.9990188953488373,\n",
       "  0.9989098837209303,\n",
       "  0.9994549418604651,\n",
       "  0.9995276162790697,\n",
       "  0.9996002906976744,\n",
       "  0.9990915697674418,\n",
       "  0.9992369186046511,\n",
       "  0.9994549418604651,\n",
       "  0.9996002906976744,\n",
       "  0.9995639534883721,\n",
       "  0.9997093023255814,\n",
       "  0.9996002906976744,\n",
       "  0.9996366279069767,\n",
       "  0.9998546511627907],\n",
       " [933.7983805835247,\n",
       "  439.28439247608185,\n",
       "  265.8412340222858,\n",
       "  177.4342374280095,\n",
       "  124.02191367791966,\n",
       "  91.78972993674688,\n",
       "  73.41613492998295,\n",
       "  57.61819946067408,\n",
       "  55.08752490533516,\n",
       "  41.39410925388802,\n",
       "  35.940389291907195,\n",
       "  31.06551475962624,\n",
       "  30.323863002529833,\n",
       "  28.2953998275334,\n",
       "  26.124085449584527,\n",
       "  21.548808023362653,\n",
       "  18.058402688475326,\n",
       "  18.66179523456958,\n",
       "  15.331795095553389,\n",
       "  14.192004523501964,\n",
       "  15.690659919157042,\n",
       "  15.121758034205413,\n",
       "  10.101749927605852,\n",
       "  10.55083677030052,\n",
       "  10.238221260049613,\n",
       "  10.855838943964045,\n",
       "  8.520247818902135,\n",
       "  8.593200353083375,\n",
       "  8.094086560791766,\n",
       "  6.729131187588791,\n",
       "  7.568006413297553,\n",
       "  5.062017095493502,\n",
       "  5.7981657527634525,\n",
       "  5.445623512699967,\n",
       "  2.3745203658654646,\n",
       "  4.310925017671252,\n",
       "  2.7558956285174645,\n",
       "  3.4437768156276434,\n",
       "  1.4781805404927582,\n",
       "  0.9307194991179131,\n",
       "  1.3159327584126004,\n",
       "  1.9190084183064755,\n",
       "  1.6427661179186543,\n",
       "  1.1041446223289313,\n",
       "  0.8868772302157595,\n",
       "  0.7755372866713515,\n",
       "  0.5004115786307466,\n",
       "  0.5406387188804729,\n",
       "  0.4940637919871733,\n",
       "  0.27914914630218846],\n",
       " [0.803175313059034,\n",
       "  0.8632714669051879,\n",
       "  0.8812611806797853,\n",
       "  0.892195885509839,\n",
       "  0.8847495527728085,\n",
       "  0.8885286225402504,\n",
       "  0.9001565295169947,\n",
       "  0.8876900715563506,\n",
       "  0.8875447227191413,\n",
       "  0.8980098389982111,\n",
       "  0.8900939177101969,\n",
       "  0.8955053667262969,\n",
       "  0.8875447227191413,\n",
       "  0.8957960644007156,\n",
       "  0.8875447227191413,\n",
       "  0.8985576923076922,\n",
       "  0.8956507155635063,\n",
       "  0.8955053667262969,\n",
       "  0.896925313059034,\n",
       "  0.8972160107334527,\n",
       "  0.8960532200357783,\n",
       "  0.8953264758497317,\n",
       "  0.8982669946332736,\n",
       "  0.9000111806797852,\n",
       "  0.8937947227191413,\n",
       "  0.8947450805008945,\n",
       "  0.8989601967799643,\n",
       "  0.8953600178890876,\n",
       "  0.9010621645796064,\n",
       "  0.904259838998211,\n",
       "  0.9007379248658318,\n",
       "  0.9022249552772809,\n",
       "  0.9019007155635063,\n",
       "  0.9045169946332736,\n",
       "  0.8998993738819321,\n",
       "  0.9049530411449016,\n",
       "  0.8979762969588551,\n",
       "  0.9030635062611807,\n",
       "  0.9019342576028623,\n",
       "  0.9041144901610018,\n",
       "  0.9030970483005367,\n",
       "  0.9074575134168158,\n",
       "  0.903242397137746,\n",
       "  0.9055679785330948,\n",
       "  0.9052772808586762,\n",
       "  0.9049865831842576,\n",
       "  0.9071668157423971,\n",
       "  0.9061493738819321,\n",
       "  0.9073121645796064,\n",
       "  0.9074575134168158],\n",
       " [0.7165452514970025,\n",
       "  0.4881041714271834,\n",
       "  0.4475443416643281,\n",
       "  0.4314408346534122,\n",
       "  0.47981274789848993,\n",
       "  0.50471256197062,\n",
       "  0.48342561594448813,\n",
       "  0.5579056072027184,\n",
       "  0.5509768683549969,\n",
       "  0.5260024962080426,\n",
       "  0.5723176552350958,\n",
       "  0.5947531366931967,\n",
       "  0.6187229681348558,\n",
       "  0.5754010151419248,\n",
       "  0.6053083348347871,\n",
       "  0.6159169737188698,\n",
       "  0.627137578786405,\n",
       "  0.6506533136872877,\n",
       "  0.6571060071144318,\n",
       "  0.6721872519712548,\n",
       "  0.6386714247336914,\n",
       "  0.6281265127551092,\n",
       "  0.6673404293869849,\n",
       "  0.6743295642585889,\n",
       "  0.6637365730815069,\n",
       "  0.6749877446623476,\n",
       "  0.6862449145042012,\n",
       "  0.6737679470254672,\n",
       "  0.6912128826467927,\n",
       "  0.6391046307844294,\n",
       "  0.69284543544318,\n",
       "  0.6955230046443365,\n",
       "  0.6864904817268198,\n",
       "  0.636948149797891,\n",
       "  0.7319647729609684,\n",
       "  0.6970115590602333,\n",
       "  0.7246584061571115,\n",
       "  0.7006915903295902,\n",
       "  0.7263931499508756,\n",
       "  0.7331778690692878,\n",
       "  0.7428408254247949,\n",
       "  0.7650208524297172,\n",
       "  0.779785320188019,\n",
       "  0.7698825636772516,\n",
       "  0.7807064869619776,\n",
       "  0.7737118905046034,\n",
       "  0.758110127808847,\n",
       "  0.7764398650876903,\n",
       "  0.7704954069786127,\n",
       "  0.7714677557405382])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc, train_loss, eval_acc, eval_loss = electra_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "868b31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_trainer.save_model(model_path, 'electra_class.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9cabbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "electra_tester = ElectraTester(args, vocab, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1acd9f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='269' class='' max='269' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [269/269 00:02&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred, y_true = electra_tester.get_label(args, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7db1779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>281</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>297</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>479</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4   5   6    7   8    9    10   11   12  13  14   15  \\\n",
       "0   281    3    3    1    5   1   1    5   1    6    4    2    4   1   0    6   \n",
       "1     4  297    2    9    1   5   1    2   1    1    2    0   17   0   0    5   \n",
       "2     4    6  121    1    3   0   0    0   0    0    3    1    0   0   0    3   \n",
       "3     0   11    2  163    2   1   0    1   0    3    9    0    7   0   1    1   \n",
       "4    14    6    1    1  177   4   0    4   0    5    5   13    1   1   2    5   \n",
       "5     3    3    2    4    2  30   0    0   0    0    5    0    0   0   1    2   \n",
       "6     0    1    0    0    0   0  42    0   0    0    0    0    0   0   0    0   \n",
       "7     1    1    0    1    4   0   0  201   5    0    2    0    0   0   0    0   \n",
       "8     0    0    1    0    1   0   0    6  72    0    1    0    0   0   0    0   \n",
       "9     5    3    2    0    1   0   0    0   1  334    5   12    0   0   0    0   \n",
       "10    4    3    0    5    4   3   0    4   1    3  479    3    1   0   0    3   \n",
       "11    1    1    1    0    6   0   0    0   0    8    0  225    0   0   0    2   \n",
       "12    0    7    0    2    3   0   0    0   0    0    4    0  199   0   3    8   \n",
       "13    1    0    0    0    0   0   0    1   0    0    2    0    0  43   0    1   \n",
       "14    0    0    0    1    3   0   0    0   0    0    2    0    0   2  44    8   \n",
       "15    0    0    0    0    1   0   0    1   0    0    3    0    2   0   4  224   \n",
       "16    3    2    2    3    3   4   1    0   0    0    1    1    2   0   1    5   \n",
       "17    0    0    0    2    2   0   0    1   1    2    0    1    1   0   0    1   \n",
       "18    0    2    0    0    0   0   0    0   1    1   14    0    0   0   0    1   \n",
       "19    4   20   10   13    8   0   0    9   6    3   31   12   10   3   5    6   \n",
       "\n",
       "     16   17   18    19  \n",
       "0     2    2    1     2  \n",
       "1     5    0    2     4  \n",
       "2     2    1    0    10  \n",
       "3     2    3    1    10  \n",
       "4     6    4    0     9  \n",
       "5     2    0    0     0  \n",
       "6     0    0    0     1  \n",
       "7     0    0    0     4  \n",
       "8     0    0    0     6  \n",
       "9     1    0    5     5  \n",
       "10    1    2   11    12  \n",
       "11    0    1    0     4  \n",
       "12    1    2    0     6  \n",
       "13    0    0    0     1  \n",
       "14    1    0    1     2  \n",
       "15    1    0    1     8  \n",
       "16  111    4    0     1  \n",
       "17    2  112    0     4  \n",
       "18    0    0  164     1  \n",
       "19    4    1    6  4507  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , confusion_matrix, f1_score, classification_report\n",
    "\n",
    "confusion_mt = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae909491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
