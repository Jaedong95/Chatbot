{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcMAFxQpDavF"
   },
   "source": [
    "[코드]\n",
    "후기 데이터셋 이용하여 KOBERT 모델 학습하고, 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q3vHY0gPzmRk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/chatbot/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 6394,
     "status": "ok",
     "timestamp": 1658406087829,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "1rpgi-tez-p1",
    "outputId": "f7d94460-b4a2-48bf-834e-022375ac3a4e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>keyword(임상키워드)</th>\n",
       "      <th>utterance(2차)</th>\n",
       "      <th>intent_label</th>\n",
       "      <th>intent_keyword</th>\n",
       "      <th>ik_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>우울감</td>\n",
       "      <td>우울</td>\n",
       "      <td>임신해서 우울해</td>\n",
       "      <td>0</td>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>우울감</td>\n",
       "      <td>우울</td>\n",
       "      <td>아이 가지고 나서 우울해</td>\n",
       "      <td>0</td>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>우울감</td>\n",
       "      <td>우울</td>\n",
       "      <td>아이 가졌는데 기분 하나도 안 좋고 울적해</td>\n",
       "      <td>0</td>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>우울감</td>\n",
       "      <td>우울</td>\n",
       "      <td>임신했는데 남편이 하나도 안 챙겨줘서 우울하다</td>\n",
       "      <td>0</td>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>우울감</td>\n",
       "      <td>우울</td>\n",
       "      <td>진단 결과 안 좋게 나올 것 같아서 우울해</td>\n",
       "      <td>0</td>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19671</th>\n",
       "      <td>불안</td>\n",
       "      <td>압박감</td>\n",
       "      <td>그래도 잠못자고 불안한건 여전해요.</td>\n",
       "      <td>18</td>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19672</th>\n",
       "      <td>불안</td>\n",
       "      <td>압박감</td>\n",
       "      <td>불안함에 항상 시달리니까 잠도 못잤어요.</td>\n",
       "      <td>18</td>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19673</th>\n",
       "      <td>불안</td>\n",
       "      <td>압박감</td>\n",
       "      <td>불안하고 초조해서 잠이 안 와.</td>\n",
       "      <td>18</td>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19674</th>\n",
       "      <td>불안</td>\n",
       "      <td>압박감</td>\n",
       "      <td>너무 불안하니까 밤만 되면 잠이 안 오고 너무 초조해.</td>\n",
       "      <td>18</td>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19675</th>\n",
       "      <td>불안</td>\n",
       "      <td>압박감</td>\n",
       "      <td>불안해서 그런지 요즘 잠도 잘 안 와서 너무 힘들어요.</td>\n",
       "      <td>18</td>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19676 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      intent keyword(임상키워드)                  utterance(2차)   intent_label  \\\n",
       "0        우울감             우울                        임신해서 우울해             0   \n",
       "1        우울감             우울                   아이 가지고 나서 우울해             0   \n",
       "2        우울감             우울         아이 가졌는데 기분 하나도 안 좋고 울적해             0   \n",
       "3        우울감             우울       임신했는데 남편이 하나도 안 챙겨줘서 우울하다             0   \n",
       "4        우울감             우울        진단 결과 안 좋게 나올 것 같아서 우울해              0   \n",
       "...      ...            ...                             ...           ...   \n",
       "19671     불안            압박감             그래도 잠못자고 불안한건 여전해요.            18   \n",
       "19672     불안            압박감          불안함에 항상 시달리니까 잠도 못잤어요.            18   \n",
       "19673     불안            압박감               불안하고 초조해서 잠이 안 와.            18   \n",
       "19674     불안            압박감  너무 불안하니까 밤만 되면 잠이 안 오고 너무 초조해.            18   \n",
       "19675     불안            압박감  불안해서 그런지 요즘 잠도 잘 안 와서 너무 힘들어요.            18   \n",
       "\n",
       "      intent_keyword  ik_label  \n",
       "0             우울감/우울         0  \n",
       "1             우울감/우울         0  \n",
       "2             우울감/우울         0  \n",
       "3             우울감/우울         0  \n",
       "4             우울감/우울         0  \n",
       "...              ...       ...  \n",
       "19671         불안/압박감       204  \n",
       "19672         불안/압박감       204  \n",
       "19673         불안/압박감       204  \n",
       "19674         불안/압박감       204  \n",
       "19675         불안/압박감       204  \n",
       "\n",
       "[19676 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_df = pd.read_csv(data_path + 'Wellness_Conversation_intent_keyword.csv')\n",
    "keyword_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iS6sU9Tt1iH1"
   },
   "source": [
    "#### KoBERT 모델로 main_cate 분류하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1658406089039,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "GYs_axGN1G3t",
    "outputId": "d7e9dd9e-a381-4d2b-ab46-a16a1379a7f9"
   },
   "outputs": [],
   "source": [
    "main_df = keyword_df[['intent_keyword', 'utterance(2차) ', 'ik_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1658406132892,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "ywqobT0luTZK",
    "outputId": "de476e78-14ea-4ff4-bcdc-c75cc95bbbd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19676 entries, 0 to 19675\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   intent_keyword  19676 non-null  object\n",
      " 1   utterance(2차)   19676 non-null  object\n",
      " 2   ik_label        19676 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 461.3+ KB\n"
     ]
    }
   ],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1658406137372,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "gSIhjIjqw-nX",
    "outputId": "93a25d27-34f5-4c19-a463-df70b5c6e2ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intent_keyword    0\n",
       "utterance(2차)     0\n",
       "ik_label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vFW7PP_d01rR"
   },
   "outputs": [],
   "source": [
    "main_df = main_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "h0rE4LHe05Fj"
   },
   "outputs": [],
   "source": [
    "main_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "executionInfo": {
     "elapsed": 1458,
     "status": "ok",
     "timestamp": 1658406201417,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "-cK1cYrzt_do",
    "outputId": "12286d15-f3df-4ec8-fb0f-4228695d8232",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_keyword</th>\n",
       "      <th>utterance(2차)</th>\n",
       "      <th>ik_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>임신해서 우울해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>아이 가지고 나서 우울해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>아이 가졌는데 기분 하나도 안 좋고 울적해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>임신했는데 남편이 하나도 안 챙겨줘서 우울하다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>우울감/우울</td>\n",
       "      <td>진단 결과 안 좋게 나올 것 같아서 우울해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19671</th>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>그래도 잠못자고 불안한건 여전해요.</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19672</th>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>불안함에 항상 시달리니까 잠도 못잤어요.</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19673</th>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>불안하고 초조해서 잠이 안 와.</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19674</th>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>너무 불안하니까 밤만 되면 잠이 안 오고 너무 초조해.</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19675</th>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>불안해서 그런지 요즘 잠도 잘 안 와서 너무 힘들어요.</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19676 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      intent_keyword                  utterance(2차)   ik_label\n",
       "0             우울감/우울                        임신해서 우울해         0\n",
       "1             우울감/우울                   아이 가지고 나서 우울해         0\n",
       "2             우울감/우울         아이 가졌는데 기분 하나도 안 좋고 울적해         0\n",
       "3             우울감/우울       임신했는데 남편이 하나도 안 챙겨줘서 우울하다         0\n",
       "4             우울감/우울        진단 결과 안 좋게 나올 것 같아서 우울해          0\n",
       "...              ...                             ...       ...\n",
       "19671         불안/압박감             그래도 잠못자고 불안한건 여전해요.       204\n",
       "19672         불안/압박감          불안함에 항상 시달리니까 잠도 못잤어요.       204\n",
       "19673         불안/압박감               불안하고 초조해서 잠이 안 와.       204\n",
       "19674         불안/압박감  너무 불안하니까 밤만 되면 잠이 안 오고 너무 초조해.       204\n",
       "19675         불안/압박감  불안해서 그런지 요즘 잠도 잘 안 와서 너무 힘들어요.       204\n",
       "\n",
       "[19676 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df['utterance(2차) '] = main_df['utterance(2차) '].apply(lambda x: x.replace('\\t', ''))\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ik_list = list(main_df['intent_keyword'].unique())\n",
    "len(ik_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EofqAJom_vN"
   },
   "source": [
    "##### 학습셋 테스트셋 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "t9pCxSAHGWGt"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(main_df, test_size=0.2, random_state=42, stratify=main_df['intent_keyword'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1658406214197,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "bDtIiqQxG8oX",
    "outputId": "7f689dfa-ab8b-4884-a53a-dac1b4e0ea9f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_keyword</th>\n",
       "      <th>utterance(2차)</th>\n",
       "      <th>ik_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3607</th>\n",
       "      <td>외로움/무의미함</td>\n",
       "      <td>외롭고 쓸쓸하고 의미 없는 시간 속에서 지쳐가</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17743</th>\n",
       "      <td>절망감/포기</td>\n",
       "      <td>임신을 포기하고 친구들도 잘 안 만나게 됐어</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11359</th>\n",
       "      <td>초조함/감정기복</td>\n",
       "      <td>임신하고 나서 몸이 너무 변하니까 감정기복이 심해졌어</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18594</th>\n",
       "      <td>자살충동/하찮음</td>\n",
       "      <td>나 같은 백수는 그냥 콱 죽는 게 낫지.</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>외로움/고독감</td>\n",
       "      <td>고독해서 힘들어요</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>우울감/집중력감소</td>\n",
       "      <td>평소에 우울할때가 많아요.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>슬픔/허망함</td>\n",
       "      <td>세상에 내 편이 없는 것 같아서 허망해요</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12133</th>\n",
       "      <td>초조함/욱함</td>\n",
       "      <td>아..근데 또 막상 공부를 안 하자니 성적이 떨어질까 걱정되네요.</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>분노/원망</td>\n",
       "      <td>남편이랑 말도 하기 싫은 거야</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6862</th>\n",
       "      <td>상실감/공허</td>\n",
       "      <td>사는 게 공허하다</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      intent_keyword                        utterance(2차)   ik_label\n",
       "3607        외로움/무의미함             외롭고 쓸쓸하고 의미 없는 시간 속에서 지쳐가        33\n",
       "17743         절망감/포기              임신을 포기하고 친구들도 잘 안 만나게 됐어       190\n",
       "11359       초조함/감정기복         임신하고 나서 몸이 너무 변하니까 감정기복이 심해졌어       120\n",
       "18594       자살충동/하찮음                나 같은 백수는 그냥 콱 죽는 게 낫지.       198\n",
       "3907         외로움/고독감                             고독해서 힘들어요        38\n",
       "...              ...                                   ...       ...\n",
       "1085       우울감/집중력감소                        평소에 우울할때가 많아요.        12\n",
       "2293          슬픔/허망함                세상에 내 편이 없는 것 같아서 허망해요        23\n",
       "12133        초조함/욱함   아..근데 또 막상 공부를 안 하자니 성적이 떨어질까 걱정되네요.       122\n",
       "4313           분노/원망                      남편이랑 말도 하기 싫은 거야        41\n",
       "6862          상실감/공허                             사는 게 공허하다        64\n",
       "\n",
       "[15740 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1658406214199,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "tCxNJeywtZKq",
    "outputId": "5a189a12-eec1-4749-a1aa-c28fdbf4fd6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 205)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.intent_keyword.unique()), len(X_test.intent_keyword.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EsrJ_wOrGm6h"
   },
   "outputs": [],
   "source": [
    "# tsv 데이터셋으로 변환\n",
    "X_train.to_csv(data_path + 'keyword_train.tsv', sep='\\t', encoding='utf-8', index=False)\n",
    "X_test.to_csv(data_path + 'keyword_test.tsv', sep='\\t', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuXUR8Q8IS5r"
   },
   "source": [
    "##### KoBERT 실행환경 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CsO0M-QYILcx"
   },
   "outputs": [],
   "source": [
    "# !pip install ipywidgets  # for vscode\n",
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8Bvmi__2IW2j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-16 01:48:28.270301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ik_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4AxBn9QEIyEn"
   },
   "outputs": [],
   "source": [
    "## CPU\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "## GPU\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9874,
     "status": "ok",
     "timestamp": 1658206216589,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "atw_Yw0eI06D",
    "outputId": "d19bfc1e-946c-4a06-ed94-ab43fd38f887",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/ubuntu/chatbot/code/.cache/kobert_v1.zip\n",
      "using cached model. /home/ubuntu/chatbot/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")   # BERT 모델 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "m-NJe76gI2wa"
   },
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(data_path + 'keyword_train.tsv', field_indices=[1, 2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(data_path + 'keyword_test.tsv', field_indices=[1, 2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1658206218898,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "iKGqtPfII_5E",
    "outputId": "9d6ebb38-411b-4d96-feb0-d3b4ca1b6cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아직 내가 하고 싶은 대로 살고 싶은데 너무 억울해', '26']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1658206218899,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "oInKXZzVJC2L",
    "outputId": "365226dc-d1af-468a-eafd-f2f90d78e337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/ubuntu/chatbot/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()   # 토크나이저 선언 \n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)   # token 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gluonnlp.data.dataset.TSVDataset at 0x7f51487e8c90>, 15740)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train, len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "IwWtCuebJHGf"
   },
   "outputs": [],
   "source": [
    "# BERT Dataset 클래스 생성 \n",
    "class BERTDataset(Dataset):   \n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bZu2NR_ZJJBC"
   },
   "outputs": [],
   "source": [
    "# 파라미터 설정 \n",
    "max_len = 64     # 토큰 최대 길이 \n",
    "batch_size = 64   # 배치 사이즈 \n",
    "warmup_ratio = 0.1   # 웜-업 비율 \n",
    "num_epochs = 50   # 학습 수  \n",
    "max_grad_norm = 1   # gradient 정규화 최대값 \n",
    "log_interval = 200   # interval 간격\n",
    "learning_rate =  5e-5   # 학습률 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15740, <gluonnlp.data.dataset.TSVDataset at 0x7f51487e8c90>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30682,
     "status": "ok",
     "timestamp": 1658206249576,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "FulvSDhqJKL9",
    "outputId": "93b17ae0-ee8c-49ef-f094-818521edcaca"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)   # 학습 데이터셋 생성 \n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)   # 테스트 데이터셋 생성 \n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "w94JmcTJJOrn"
   },
   "outputs": [],
   "source": [
    "# BERT Classifier 클래스 생성 \n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=len(ik_list),\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()    # 부모 클래스 생성자 초기화 \n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)   # 선형 분류기 생성 \n",
    "        if dr_rate:   # 드랍아웃 \n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask \\\n",
    "                              = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9PnWcSn7JvDG"
   },
   "outputs": [],
   "source": [
    "# 사전훈련된 BERT 모델 생성 \n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1658206257129,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "xDStspWU6e8F",
    "outputId": "7df13e14-f81d-4158-875f-273d90beb88b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/chatbot/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)   # 웜업 스텝 설정 \n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wWJRKEhz6jQo"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "id": "PElGJOoi6l3Y"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195accb5cc8f4d74a1fd9ceab86d8289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch id 1 loss 5.34111213684082 train acc 0.0\n",
      "epoch 1 batch id 201 loss 5.10125207901001 train acc 0.033271144278606966\n",
      "epoch 1 train acc 0.040667344173441734\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323ff26ff3da4fbfba9255ea0f283507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 val acc 0.0846774193548387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476c75fd55fe4704b5a48ffc19636917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch id 1 loss 4.9134345054626465 train acc 0.09375\n",
      "epoch 2 batch id 201 loss 4.413898468017578 train acc 0.09064054726368159\n",
      "epoch 2 train acc 0.09639227642276423\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdbe55782ca54ed2b33b6025983150d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 val acc 0.1580141129032258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd6611adc87498aa9a92ce4b0d6f65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch id 1 loss 4.154152870178223 train acc 0.1875\n",
      "epoch 3 batch id 201 loss 3.711594581604004 train acc 0.24432524875621892\n",
      "epoch 3 train acc 0.252612635501355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5339fca3e3814002980b2c566512c436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 val acc 0.3329133064516129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81735161523b4aa280a7885608536360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch id 1 loss 3.335918426513672 train acc 0.375\n",
      "epoch 4 batch id 201 loss 2.935448169708252 train acc 0.36551616915422885\n",
      "epoch 4 train acc 0.36937669376693766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2492a25a9d75476c9984bb8509ac8a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 val acc 0.4480846774193548\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c454f272414a9ab16aca49426c53e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch id 1 loss 2.8263161182403564 train acc 0.453125\n",
      "epoch 5 batch id 201 loss 2.5780391693115234 train acc 0.46323072139303484\n",
      "epoch 5 train acc 0.46764905149051494\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2cf72cf7344e74b1b3acdb9fd5a658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 val acc 0.5473790322580645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7669624cef994957a3eea6fb83d24579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch id 1 loss 2.372408390045166 train acc 0.578125\n",
      "epoch 6 batch id 201 loss 2.1454434394836426 train acc 0.5597792288557214\n",
      "epoch 6 train acc 0.5654598577235772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fba4a3015040319e60ef816b79e1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 val acc 0.6013104838709677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030324468acc4961b66784a3d26d182f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch id 1 loss 1.8822191953659058 train acc 0.65625\n",
      "epoch 7 batch id 201 loss 1.4751505851745605 train acc 0.6540733830845771\n",
      "epoch 7 train acc 0.6565633468834687\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28cae85bd6f4ebbbe64c7ac4be6a7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 val acc 0.6610383064516129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695e425f758b45ee96366b11aa884cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch id 1 loss 1.509796142578125 train acc 0.734375\n",
      "epoch 8 batch id 201 loss 1.337910771369934 train acc 0.7240360696517413\n",
      "epoch 8 train acc 0.7264439363143631\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f6cec11f7547488638d91d12772b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 val acc 0.6829637096774194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0e72525c9744c888d7af0977d27841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch id 1 loss 1.1163203716278076 train acc 0.75\n",
      "epoch 9 batch id 201 loss 1.064841866493225 train acc 0.78125\n",
      "epoch 9 train acc 0.7827235772357723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8782d44307a4f5eb5e5638f7606c936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 val acc 0.7084173387096774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbf21cf43394617b392b8e593967a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch id 1 loss 0.8317819237709045 train acc 0.875\n",
      "epoch 10 batch id 201 loss 0.7776275277137756 train acc 0.8252487562189055\n",
      "epoch 10 train acc 0.8261602303523036\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2138d5b9ab1e49d5b35c84eddfbe48e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 val acc 0.7290826612903226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289c6408669e45728253c7edf3e52a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 batch id 1 loss 0.5965453386306763 train acc 0.875\n",
      "epoch 11 batch id 201 loss 0.6704748868942261 train acc 0.8606187810945274\n",
      "epoch 11 train acc 0.8615599593495935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740dff84b56343a6a5eeac2e9d834500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 val acc 0.7313508064516129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7512430ca65242d4853e6047b38969ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 batch id 1 loss 0.4516134262084961 train acc 0.90625\n",
      "epoch 12 batch id 201 loss 0.6303747892379761 train acc 0.8940453980099502\n",
      "epoch 12 train acc 0.8933138550135502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c706f998326d41a5ba62df683b025326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 val acc 0.7376512096774194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fc83e50fa440cb9421973dacb8c9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 batch id 1 loss 0.32300257682800293 train acc 0.953125\n",
      "epoch 13 batch id 201 loss 0.3601747751235962 train acc 0.9105254975124378\n",
      "epoch 13 train acc 0.912059620596206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cca7f6d4f8447a3a4316c6d3b64afbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 val acc 0.7517641129032258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61a98b93df246d7ac26e4468fa4f108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 batch id 1 loss 0.2669094204902649 train acc 0.953125\n",
      "epoch 14 batch id 201 loss 0.365335077047348 train acc 0.9236629353233831\n",
      "epoch 14 train acc 0.9263634823848238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d195083fa5461ebe492e56dead9155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 val acc 0.7600806451612904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c7b093c3894c26a8fe0544273fcb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 batch id 1 loss 0.1787523627281189 train acc 0.984375\n",
      "epoch 15 batch id 201 loss 0.28245237469673157 train acc 0.9392101990049752\n",
      "epoch 15 train acc 0.9405191395663957\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684d53af712e45cda38bb2a67de6b5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 val acc 0.7527721774193549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c96e1bc73d435583d26e1b1a35f921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 batch id 1 loss 0.21890072524547577 train acc 0.9375\n",
      "epoch 16 batch id 201 loss 0.24516324698925018 train acc 0.9484608208955224\n",
      "epoch 16 train acc 0.9488482384823848\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c0bc787a8249828a3d89f332a181b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 val acc 0.7583165322580645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0b7de08c984087833a75c460562e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 batch id 1 loss 0.1313067376613617 train acc 0.984375\n",
      "epoch 17 batch id 201 loss 0.14819106459617615 train acc 0.9598103233830846\n",
      "epoch 17 train acc 0.9601710704607046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7912ade7e2374a96839242fa385c5996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 val acc 0.764616935483871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320226b85d6942a99df62352b843dfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 batch id 1 loss 0.1087663397192955 train acc 0.984375\n",
      "epoch 18 batch id 201 loss 0.17271757125854492 train acc 0.9659514925373134\n",
      "epoch 18 train acc 0.9662008807588076\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b7f6fa6bbe4470bfa860c8426b9ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 val acc 0.7641129032258065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1234888a2dd4258bdd909743328baa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 batch id 1 loss 0.08183453232049942 train acc 0.984375\n",
      "epoch 19 batch id 201 loss 0.10821091383695602 train acc 0.9712375621890548\n",
      "epoch 19 train acc 0.9722391598915988\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b154d7ecb2548bcad95cbe8d91f5d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 val acc 0.7739415322580645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3df4cf78e094c89b441591f5f03a036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 batch id 1 loss 0.07307644933462143 train acc 0.984375\n",
      "epoch 20 batch id 201 loss 0.0989377498626709 train acc 0.9752798507462687\n",
      "epoch 20 train acc 0.9753514566395663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1612071ffffd4c2cba58f059624022f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 val acc 0.7709173387096774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9acbb549c944ea8db83d3d207f6d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 batch id 1 loss 0.03667587786912918 train acc 1.0\n",
      "epoch 21 batch id 201 loss 0.06282099336385727 train acc 0.9782338308457711\n",
      "epoch 21 train acc 0.9786458333333333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b97dc7916e4d5699133de9910bde01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 val acc 0.7711693548387096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc3f409638e4511b51ec7b9ea45004f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 batch id 1 loss 0.04199948534369469 train acc 1.0\n",
      "epoch 22 batch id 201 loss 0.17456145584583282 train acc 0.982431592039801\n",
      "epoch 22 train acc 0.9829734078590785\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126ed99deb4140c282d7082db1c2b1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 val acc 0.7709173387096774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b36cc2c1d254285a892f9ad18fb08c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 batch id 1 loss 0.04087559133768082 train acc 1.0\n",
      "epoch 23 batch id 201 loss 0.05714114010334015 train acc 0.9849968905472637\n",
      "epoch 23 train acc 0.9858951558265582\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019d2daea3034fe085f3719d554c0d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 val acc 0.7782258064516129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47aa6556b0214b29bffc527587afc41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 batch id 1 loss 0.02947463095188141 train acc 1.0\n",
      "epoch 24 batch id 201 loss 0.03973786532878876 train acc 0.9894278606965174\n",
      "epoch 24 train acc 0.9894478319783198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dfb298ed1f4148af8984d15ded8689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 val acc 0.7840221774193549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53327c87bca423ea9b164d69a7dbc1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 batch id 1 loss 0.06621819734573364 train acc 0.984375\n",
      "epoch 25 batch id 201 loss 0.04227423295378685 train acc 0.9898165422885572\n",
      "epoch 25 train acc 0.9902777777777777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794031c0c7ca447fb7b315920b820054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 val acc 0.7779737903225806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb87e8d031144bdb3f86d4fb76a7410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 batch id 1 loss 0.019710393622517586 train acc 1.0\n",
      "epoch 26 batch id 201 loss 0.03080889768898487 train acc 0.9934701492537313\n",
      "epoch 26 train acc 0.9935213414634146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ea16a99af54b0aa93e50520e3611cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 val acc 0.7764616935483871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecbc7514fc944b7b62519930779eead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 batch id 1 loss 0.01465157512575388 train acc 1.0\n",
      "epoch 27 batch id 201 loss 0.041867006570100784 train acc 0.9953358208955224\n",
      "epoch 27 train acc 0.9951092479674797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25a1ad570084001b554af3e729e63aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 val acc 0.7754536290322581\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1750222467fb43ce8d8d596dbdc00c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 batch id 1 loss 0.012304246425628662 train acc 1.0\n",
      "epoch 28 batch id 201 loss 0.03741200268268585 train acc 0.9955690298507462\n",
      "epoch 28 train acc 0.9952997967479674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac09354bd6734a9eab1307dac80fe43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 val acc 0.7830141129032258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecaffec30634408ba81404a316c59874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 batch id 1 loss 0.012119951657950878 train acc 1.0\n",
      "epoch 29 batch id 201 loss 0.011160406284034252 train acc 0.9972792288557214\n",
      "epoch 29 train acc 0.9973323170731707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb09bb6610c49d7ac54abdeb135d656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 val acc 0.7779737903225806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e0be30b622452d8b75f5af6f23af95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 batch id 1 loss 0.0075401742942631245 train acc 1.0\n",
      "epoch 30 batch id 201 loss 0.007737632375210524 train acc 0.9973569651741293\n",
      "epoch 30 train acc 0.9973323170731707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf582bf12ac5466ba08ccfe03df965c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 val acc 0.7772177419354839\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1dcf0637b44c64aaec0ae7f7a6e8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 batch id 1 loss 0.0083512794226408 train acc 1.0\n",
      "epoch 31 batch id 201 loss 0.005867775063961744 train acc 0.9989894278606966\n",
      "epoch 31 train acc 0.9987931910569106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4693e3db1e5e432ba43973ea2d98a77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 val acc 0.7797379032258065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46dac95a960d435580185f32c0e13ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 batch id 1 loss 0.005646302364766598 train acc 1.0\n",
      "epoch 32 batch id 201 loss 0.008747413754463196 train acc 0.9989894278606966\n",
      "epoch 32 train acc 0.9987254403794037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761794ba1b634d60aeaaf994685aa95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 val acc 0.7784778225806451\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "464bfcb5e9874b10a570b19d21002822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 batch id 1 loss 0.005828913301229477 train acc 1.0\n",
      "epoch 33 batch id 201 loss 0.005522086285054684 train acc 0.9984452736318408\n",
      "epoch 33 train acc 0.9983485772357723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d0e3700a364a499c1710c4f95fc5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 val acc 0.7817540322580645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab3bff55e824dcfabc478816d2d8463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 batch id 1 loss 0.003972983453422785 train acc 1.0\n",
      "epoch 34 batch id 201 loss 0.0044632768258452415 train acc 0.9993003731343284\n",
      "epoch 34 train acc 0.9989795054200541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364b91e769eb435d870b7fc7a5663d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 val acc 0.7835181451612904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b197221f8aa4b8c96ae6cf525c6b643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 batch id 1 loss 0.0037479472812265158 train acc 1.0\n",
      "epoch 35 batch id 201 loss 0.004606915637850761 train acc 0.9993003731343284\n",
      "epoch 35 train acc 0.9991107723577236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e163b1e6bd4f7799740348143a2b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 val acc 0.7827620967741935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb0a199a76d422d8ccffee4df218906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 batch id 1 loss 0.0027343600522726774 train acc 1.0\n",
      "epoch 36 batch id 201 loss 0.005326630547642708 train acc 0.9995335820895522\n",
      "epoch 36 train acc 0.9994283536585366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085136f3b19b4b2d887ecdab65400a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 val acc 0.7870463709677419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c6e009f57c41f0bbce183cca248978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 batch id 1 loss 0.0030500751454383135 train acc 1.0\n",
      "epoch 37 batch id 201 loss 0.005260846111923456 train acc 0.9995335820895522\n",
      "epoch 37 train acc 0.999364837398374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb32f7cfa5f4ccab2877b437618b56c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 val acc 0.7870463709677419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c42f86c833422c9aaa7d830962590c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 batch id 1 loss 0.0022564297541975975 train acc 1.0\n",
      "epoch 38 batch id 201 loss 0.003034718334674835 train acc 0.9997667910447762\n",
      "epoch 38 train acc 0.9996189024390244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f3a2bda97f403293005ba51fa512bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 val acc 0.7878024193548387\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaafe566452c43e4985755557f5d9045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 batch id 1 loss 0.0026949774473905563 train acc 1.0\n",
      "epoch 39 batch id 201 loss 0.005024312529712915 train acc 0.9995335820895522\n",
      "epoch 39 train acc 0.9995553861788617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2124cd71d443bf82761b583983413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 val acc 0.7875504032258065\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a8e57e50274d6fab63b8b4fda55afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40 batch id 1 loss 0.0028276348020881414 train acc 1.0\n",
      "epoch 40 batch id 201 loss 0.002320436993613839 train acc 0.9996890547263682\n",
      "epoch 40 train acc 0.999682418699187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821ee58eae3f4ed6b3dedd03e8692219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40 val acc 0.7885584677419355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6535d8921c72437c8fc2e05ae332abd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 batch id 1 loss 0.0022899978794157505 train acc 1.0\n",
      "epoch 41 batch id 201 loss 0.0029680742882192135 train acc 0.9998445273631841\n",
      "epoch 41 train acc 0.9997459349593496\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd5462950cc483fbed25d23a304fab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 val acc 0.7860383064516129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed3e4e3bf224458b8aa8a01521ebb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 batch id 1 loss 0.002159286756068468 train acc 1.0\n",
      "epoch 42 batch id 201 loss 0.0021159679163247347 train acc 0.9999222636815921\n",
      "epoch 42 train acc 0.9998094512195121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59122a40d254ac6aeec4ab2c871235a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 val acc 0.7872983870967742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40e23eefedd46cf9288c30f1b095b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 batch id 1 loss 0.0023164956364780664 train acc 1.0\n",
      "epoch 43 batch id 201 loss 0.002801391761749983 train acc 0.9997667910447762\n",
      "epoch 43 train acc 0.9998094512195121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96f5f5bc8f443ccb780cb3a4cc25439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 val acc 0.7870463709677419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683d774b2b2b4e89aebafadbfa127b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44 batch id 1 loss 0.002395056886598468 train acc 1.0\n",
      "epoch 44 batch id 201 loss 0.0023936869110912085 train acc 0.9996113184079602\n",
      "epoch 44 train acc 0.9995553861788617\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cbfd2850fb4cda8d6d219e7bff56ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44 val acc 0.7872983870967742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b69f06eeb6c419cac7a5b4a673393dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 batch id 1 loss 0.002173510380089283 train acc 1.0\n",
      "epoch 45 batch id 201 loss 0.002594567835330963 train acc 0.9996890547263682\n",
      "epoch 45 train acc 0.9996189024390244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c037be8c19f41dd8793c466f42e00d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 val acc 0.7870463709677419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd481f76ace840e1a1fb6262cf783b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46 batch id 1 loss 0.004868726711720228 train acc 1.0\n",
      "epoch 46 batch id 201 loss 0.002378295175731182 train acc 0.9996890547263682\n",
      "epoch 46 train acc 0.9996189024390244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994326c964ed415ea26686b83c29e5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46 val acc 0.7857862903225806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e67044c96140cc90e0a200e97865d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47 batch id 1 loss 0.0019804902840405703 train acc 1.0\n",
      "epoch 47 batch id 201 loss 0.002650681883096695 train acc 0.9998445273631841\n",
      "epoch 47 train acc 0.9998094512195121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a672521c134445aca19de5f7776242f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47 val acc 0.7860383064516129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19d450d336d46a3a6ef2daeb638b934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48 batch id 1 loss 0.0017671006498858333 train acc 1.0\n",
      "epoch 48 batch id 201 loss 0.0022026654332876205 train acc 0.9998445273631841\n",
      "epoch 48 train acc 0.9998094512195121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a691d31c88c543dcb7e4fd3fc38edbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48 val acc 0.7860383064516129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bc1d31d98e4431a8763a9a33aadad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49 batch id 1 loss 0.0018936867127195 train acc 1.0\n",
      "epoch 49 batch id 201 loss 0.003020789474248886 train acc 0.9999222636815921\n",
      "epoch 49 train acc 0.9998094512195121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c16bad752e245d3a79ea13eae1ef926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49 val acc 0.7857862903225806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5878d420c1d949aa8605d7fc0fceba3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 batch id 1 loss 0.0020974017679691315 train acc 1.0\n",
      "epoch 50 batch id 201 loss 0.0029267664067447186 train acc 0.9997667910447762\n",
      "epoch 50 train acc 0.999682418699187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c8f99821274ff6b8c766fcef3364bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 val acc 0.7857862903225806\n"
     ]
    }
   ],
   "source": [
    "train_acc_list_50 = []\n",
    "test_acc_list_50 = []\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    batch = [] \n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    train_acc_list_50.append(train_acc / (batch_id+1))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} val acc {}\".format(e+1, test_acc / (batch_id+1)))\n",
    "    test_acc_list_50.append(test_acc / (batch_id+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_acc_list_50), len(train_acc_list_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0846774193548387,\n",
       " 0.1580141129032258,\n",
       " 0.3329133064516129,\n",
       " 0.4480846774193548,\n",
       " 0.5473790322580645,\n",
       " 0.6013104838709677,\n",
       " 0.6610383064516129,\n",
       " 0.6829637096774194,\n",
       " 0.7084173387096774,\n",
       " 0.7290826612903226,\n",
       " 0.7313508064516129,\n",
       " 0.7376512096774194,\n",
       " 0.7517641129032258,\n",
       " 0.7600806451612904,\n",
       " 0.7527721774193549,\n",
       " 0.7583165322580645,\n",
       " 0.764616935483871,\n",
       " 0.7641129032258065,\n",
       " 0.7739415322580645,\n",
       " 0.7709173387096774,\n",
       " 0.7711693548387096,\n",
       " 0.7709173387096774,\n",
       " 0.7782258064516129,\n",
       " 0.7840221774193549,\n",
       " 0.7779737903225806,\n",
       " 0.7764616935483871,\n",
       " 0.7754536290322581,\n",
       " 0.7830141129032258,\n",
       " 0.7779737903225806,\n",
       " 0.7772177419354839,\n",
       " 0.7797379032258065,\n",
       " 0.7784778225806451,\n",
       " 0.7817540322580645,\n",
       " 0.7835181451612904,\n",
       " 0.7827620967741935,\n",
       " 0.7870463709677419,\n",
       " 0.7870463709677419,\n",
       " 0.7878024193548387,\n",
       " 0.7875504032258065,\n",
       " 0.7885584677419355,\n",
       " 0.7860383064516129,\n",
       " 0.7872983870967742,\n",
       " 0.7870463709677419,\n",
       " 0.7872983870967742,\n",
       " 0.7870463709677419,\n",
       " 0.7857862903225806,\n",
       " 0.7860383064516129,\n",
       " 0.7860383064516129,\n",
       " 0.7857862903225806,\n",
       " 0.7857862903225806]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_list_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0846774193548387,\n",
       "  0.1580141129032258,\n",
       "  0.3329133064516129,\n",
       "  0.4480846774193548,\n",
       "  0.5473790322580645,\n",
       "  0.6013104838709677,\n",
       "  0.6610383064516129,\n",
       "  0.6829637096774194,\n",
       "  0.7084173387096774,\n",
       "  0.7290826612903226,\n",
       "  0.7313508064516129,\n",
       "  0.7376512096774194,\n",
       "  0.7517641129032258,\n",
       "  0.7600806451612904,\n",
       "  0.7527721774193549,\n",
       "  0.7583165322580645,\n",
       "  0.764616935483871,\n",
       "  0.7641129032258065,\n",
       "  0.7739415322580645,\n",
       "  0.7709173387096774,\n",
       "  0.7711693548387096,\n",
       "  0.7709173387096774,\n",
       "  0.7782258064516129,\n",
       "  0.7840221774193549,\n",
       "  0.7779737903225806,\n",
       "  0.7764616935483871,\n",
       "  0.7754536290322581,\n",
       "  0.7830141129032258,\n",
       "  0.7779737903225806,\n",
       "  0.7772177419354839,\n",
       "  0.7797379032258065,\n",
       "  0.7784778225806451,\n",
       "  0.7817540322580645,\n",
       "  0.7835181451612904,\n",
       "  0.7827620967741935,\n",
       "  0.7870463709677419,\n",
       "  0.7870463709677419,\n",
       "  0.7878024193548387,\n",
       "  0.7875504032258065,\n",
       "  0.7885584677419355,\n",
       "  0.7860383064516129,\n",
       "  0.7872983870967742,\n",
       "  0.7870463709677419,\n",
       "  0.7872983870967742,\n",
       "  0.7870463709677419,\n",
       "  0.7857862903225806,\n",
       "  0.7860383064516129,\n",
       "  0.7860383064516129,\n",
       "  0.7857862903225806,\n",
       "  0.7857862903225806],\n",
       " [0.040667344173441734,\n",
       "  0.09639227642276423,\n",
       "  0.252612635501355,\n",
       "  0.36937669376693766,\n",
       "  0.46764905149051494,\n",
       "  0.5654598577235772,\n",
       "  0.6565633468834687,\n",
       "  0.7264439363143631,\n",
       "  0.7827235772357723,\n",
       "  0.8261602303523036,\n",
       "  0.8615599593495935,\n",
       "  0.8933138550135502,\n",
       "  0.912059620596206,\n",
       "  0.9263634823848238,\n",
       "  0.9405191395663957,\n",
       "  0.9488482384823848,\n",
       "  0.9601710704607046,\n",
       "  0.9662008807588076,\n",
       "  0.9722391598915988,\n",
       "  0.9753514566395663,\n",
       "  0.9786458333333333,\n",
       "  0.9829734078590785,\n",
       "  0.9858951558265582,\n",
       "  0.9894478319783198,\n",
       "  0.9902777777777777,\n",
       "  0.9935213414634146,\n",
       "  0.9951092479674797,\n",
       "  0.9952997967479674,\n",
       "  0.9973323170731707,\n",
       "  0.9973323170731707,\n",
       "  0.9987931910569106,\n",
       "  0.9987254403794037,\n",
       "  0.9983485772357723,\n",
       "  0.9989795054200541,\n",
       "  0.9991107723577236,\n",
       "  0.9994283536585366,\n",
       "  0.999364837398374,\n",
       "  0.9996189024390244,\n",
       "  0.9995553861788617,\n",
       "  0.999682418699187,\n",
       "  0.9997459349593496,\n",
       "  0.9998094512195121,\n",
       "  0.9998094512195121,\n",
       "  0.9995553861788617,\n",
       "  0.9996189024390244,\n",
       "  0.9996189024390244,\n",
       "  0.9998094512195121,\n",
       "  0.9998094512195121,\n",
       "  0.9998094512195121,\n",
       "  0.999682418699187])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10번 학습 \n",
    "# test_acc_list, train_acc_list \n",
    "\n",
    "# 50번 학습 \n",
    "test_acc_list_50, train_acc_list_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_10 = list(range(0, 10))\n",
    "epochs_50 = list(range(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.xlabel('Train Accuracy')\n",
    "plt.plot(list(range(len(train_acc_list_50))), train_acc_list_50, label='train_acc')\n",
    "plt.plot(list(range(len(test_acc_list_50))), test_acc_list_50, label='test_acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1658213264749,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "5GRNQbDf9mtR",
    "outputId": "dd31dd73-db43-407e-b55a-b411bc8c249b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent_keyword</th>\n",
       "      <th>utterance(2차)</th>\n",
       "      <th>ik_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19464</th>\n",
       "      <td>불안/압박감</td>\n",
       "      <td>누가 신경줄을 갉아먹는 거 같아.</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2467</th>\n",
       "      <td>슬픔/억울</td>\n",
       "      <td>아직 내가 하고 싶은 대로 살고 싶은데 너무 억울해</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>죄책감/죄책감</td>\n",
       "      <td>애기 낳아도 잘 해줄 수 없을 거 같아서 너무 죄책감이 생겨</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6137</th>\n",
       "      <td>무기력/활동감소</td>\n",
       "      <td>근데 가서 너무 힘들었거든… 너무 지치고 힘들었어.</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>우울감/집중력감소</td>\n",
       "      <td>요즘 우울해서 그런지 철학책을 많이 읽게 됐어요.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>우울감/집중력감소</td>\n",
       "      <td>멍하고 평소에도 자주 멍때려.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15784</th>\n",
       "      <td>집중력저하/곤란</td>\n",
       "      <td>공부에도 집중해야하는데…</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17682</th>\n",
       "      <td>절망감/가치 없음</td>\n",
       "      <td>혼전임신이라고 사람들이 모욕감을 주니까 내가 너무 가치 없이 느껴져</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13773</th>\n",
       "      <td>피로/졸림</td>\n",
       "      <td>점심만 먹으면 졸리고 피곤해</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15505</th>\n",
       "      <td>죄책감/충동</td>\n",
       "      <td>다음 날이면 후회가 가득해요.</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3936 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      intent_keyword                         utterance(2차)   ik_label\n",
       "19464         불안/압박감                     누가 신경줄을 갉아먹는 거 같아.       204\n",
       "2467           슬픔/억울           아직 내가 하고 싶은 대로 살고 싶은데 너무 억울해        26\n",
       "14443        죄책감/죄책감      애기 낳아도 잘 해줄 수 없을 거 같아서 너무 죄책감이 생겨       136\n",
       "6137        무기력/활동감소           근데 가서 너무 힘들었거든… 너무 지치고 힘들었어.        57\n",
       "1266       우울감/집중력감소            요즘 우울해서 그런지 철학책을 많이 읽게 됐어요.        12\n",
       "...              ...                                    ...       ...\n",
       "836        우울감/집중력감소                       멍하고 평소에도 자주 멍때려.        12\n",
       "15784       집중력저하/곤란                          공부에도 집중해야하는데…       159\n",
       "17682      절망감/가치 없음  혼전임신이라고 사람들이 모욕감을 주니까 내가 너무 가치 없이 느껴져       189\n",
       "13773          피로/졸림                        점심만 먹으면 졸리고 피곤해       132\n",
       "15505         죄책감/충동                       다음 날이면 후회가 가득해요.       149\n",
       "\n",
       "[3936 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 감성분석 해보기 \n",
    "X_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1APeT3vbhcZL"
   },
   "source": [
    "torch.save(model.state_dict(), data_path + 'BERT_keyword_model_50.pt')\n",
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1658220525448,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "TCB64SVspOhM",
    "outputId": "674f8957-0c33-4817-dab0-14a296d91d9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = torch.load(data_path + 'BERT_keyword_model_50.pt')\n",
    "load_model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "load_model.load_state_dict(torch.load(data_path + 'BERT_keyword_model_50.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1658213264750,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "AOmQMe_HEl3Q",
    "outputId": "6268944f-a379-4562-a7a0-8510e81659d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19464                       누가 신경줄을 갉아먹는 거 같아.\n",
       "2467              아직 내가 하고 싶은 대로 살고 싶은데 너무 억울해\n",
       "14443        애기 낳아도 잘 해줄 수 없을 거 같아서 너무 죄책감이 생겨\n",
       "6137              근데 가서 너무 힘들었거든… 너무 지치고 힘들었어.\n",
       "1266               요즘 우울해서 그런지 철학책을 많이 읽게 됐어요.\n",
       "                         ...                  \n",
       "836                           멍하고 평소에도 자주 멍때려.\n",
       "15784                            공부에도 집중해야하는데…\n",
       "17682    혼전임신이라고 사람들이 모욕감을 주니까 내가 너무 가치 없이 느껴져\n",
       "13773                          점심만 먹으면 졸리고 피곤해\n",
       "15505                         다음 날이면 후회가 가득해요.\n",
       "Name: utterance(2차) , Length: 3936, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = X_test['utterance(2차) ']\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ofBPcHt4WMg4"
   },
   "outputs": [],
   "source": [
    "y_true = X_test['ik_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Ka8UqEZjWirg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 위에서 설정한 tok, max_len, batch_size, device를 그대로 입력\n",
    "# comment : 예측하고자 하는 텍스트 데이터 리스트\n",
    "def getSentimentValue(comment, tok, max_len, batch_size, device):\n",
    "    comments_list = [] # 텍스트 데이터를 담을 리스트\n",
    "    main_list = [] # 대분류 카테고리 값을 담을 리스트\n",
    "    \n",
    "    for c in comment: # 모든 댓글\n",
    "        comments_list.append( [c, 5] ) # [댓글, 임의의 양의 정수값] 설정\n",
    "        \n",
    "    pdData = pd.DataFrame(comments_list, columns = [['context', 'intent']] )\n",
    "    pdData = pdData.values\n",
    "    test_set = BERTDataset(pdData, 0, 1, tok, max_len, True, False) \n",
    "    test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_input):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length \n",
    "    \n",
    "        # 이때, out이 예측 결과 리스트\n",
    "        out = load_model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        for pred in out: \n",
    "            main_list.append(np.argmax(pred.detach().cpu()))\n",
    "        \n",
    "    return main_list # 텍스트 데이터에 1대1 매칭되는 감성값 리스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903019,
     "status": "ok",
     "timestamp": 1658215529419,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "JUlGmREfYNPL",
    "outputId": "e1e13c01-13e1-4c28-e9d9-2e2e58646985"
   },
   "outputs": [],
   "source": [
    "y_pred = getSentimentValue(comments, tok, max_len, batch_size, device)   # tok, max_len, batch_size, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1658158979345,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "wZ0MCQMrYSuE",
    "outputId": "8eae88f9-9318-43f3-c6d8-0151fc0f3508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19464    204\n",
       "2467      26\n",
       "14443    136\n",
       "6137      57\n",
       "1266      12\n",
       "        ... \n",
       "836       12\n",
       "15784    159\n",
       "17682    189\n",
       "13773    132\n",
       "15505    149\n",
       "Name: ik_label, Length: 3936, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1658216988016,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "e_6yxylmcFrR",
    "outputId": "c0bfdd75-77cd-44c5-f5b0-ac2ac048e828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3936, 3936)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "-sdeOFEA-ndF"
   },
   "outputs": [],
   "source": [
    "y_pred = list(map(int, y_pred)) \n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1658218375237,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "rERO39oaWK_W",
    "outputId": "ec7c9102-a063-4287-b31d-bc36447d07b3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "comments = ['너무 우울해', '죽고싶다', '아무것도하기싫다']\n",
    "\n",
    "y_pred = getSentimentValue(comments, tok, max_len, batch_size, device)   # tok, max_len, batch_size, device\n",
    "y_pred = list(map(int, y_pred)) \n",
    "\n",
    "print(intent_list[y_pred[0]], intent_list[y_pred[1]], intent_list[y_pred[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "3eWUc9v5dotY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    ...  195  196  197  \\\n",
       "0     17    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "1      0   11    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "2      0    0   13    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "3      0    0    0    5    0    0    0    0    0    0  ...    0    0    0   \n",
       "4      0    0    0    0   10    0    0    0    0    0  ...    0    0    0   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "200    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "201    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "202    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "203    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "204    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "\n",
       "     198  199  200  201  202  203  204  \n",
       "0      0    0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  \n",
       "200    0    0   19    0    0    0    0  \n",
       "201    0    0    0    6    0    0    0  \n",
       "202    0    0    0    0   16    0    0  \n",
       "203    0    1    0    0    0   16    0  \n",
       "204    0    5    0    0    0    0   66  \n",
       "\n",
       "[205 rows x 205 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , confusion_matrix, f1_score, classification_report\n",
    "\n",
    "confusion_mt = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "confusion_mt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1658218377236,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "TJLBiaQge8ml",
    "outputId": "26f2e011-3c8c-4186-df79-92b41762a52b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_mt.columns = ik_list \n",
    "confusion_mt.index = ik_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "N6ewx1z9gl0N"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>우울감/우울</th>\n",
       "      <th>우울감/침울</th>\n",
       "      <th>우울감/멍함</th>\n",
       "      <th>우울감/무기력</th>\n",
       "      <th>우울감/의욕감소</th>\n",
       "      <th>우울감/불면</th>\n",
       "      <th>우울감/흥미상실</th>\n",
       "      <th>우울감/식욕부진</th>\n",
       "      <th>우울감/자존감감소</th>\n",
       "      <th>우울감/패배감</th>\n",
       "      <th>...</th>\n",
       "      <th>절망감/나약</th>\n",
       "      <th>절망감/절박</th>\n",
       "      <th>절망감/하찮음</th>\n",
       "      <th>자살충동/하찮음</th>\n",
       "      <th>불안/불안</th>\n",
       "      <th>불안/긴장</th>\n",
       "      <th>불안/낭떠러지 끝에 있는 느낌</th>\n",
       "      <th>불안/두렵다</th>\n",
       "      <th>불안/울렁거리다</th>\n",
       "      <th>불안/압박감</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>우울감/우울</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>우울감/침울</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>우울감/멍함</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>우울감/무기력</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>우울감/의욕감소</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불안/긴장</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불안/낭떠러지 끝에 있는 느낌</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불안/두렵다</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불안/울렁거리다</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불안/압박감</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>205 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  우울감/우울  우울감/침울  우울감/멍함  우울감/무기력   우울감/의욕감소  우울감/불면  \\\n",
       "우울감/우울                17       0       0         0         0       0   \n",
       "우울감/침울                 0      11       0         0         0       0   \n",
       "우울감/멍함                 0       0      13         0         0       0   \n",
       "우울감/무기력                0       0       0         5         0       0   \n",
       "우울감/의욕감소               0       0       0         0        10       0   \n",
       "...                  ...     ...     ...       ...       ...     ...   \n",
       "불안/긴장                  0       0       0         0         0       0   \n",
       "불안/낭떠러지 끝에 있는 느낌       0       0       0         0         0       0   \n",
       "불안/두렵다                 0       0       0         0         0       0   \n",
       "불안/울렁거리다               0       0       0         0         0       0   \n",
       "불안/압박감                 0       0       0         0         0       0   \n",
       "\n",
       "                  우울감/흥미상실  우울감/식욕부진  우울감/자존감감소  우울감/패배감  ...  절망감/나약  절망감/절박  \\\n",
       "우울감/우울                   0         0          0        0  ...       0       0   \n",
       "우울감/침울                   0         0          0        0  ...       0       0   \n",
       "우울감/멍함                   0         0          0        0  ...       0       0   \n",
       "우울감/무기력                  0         0          0        0  ...       0       0   \n",
       "우울감/의욕감소                 0         0          0        0  ...       0       0   \n",
       "...                    ...       ...        ...      ...  ...     ...     ...   \n",
       "불안/긴장                    0         0          0        0  ...       0       0   \n",
       "불안/낭떠러지 끝에 있는 느낌         0         0          0        0  ...       0       0   \n",
       "불안/두렵다                   0         0          0        0  ...       0       0   \n",
       "불안/울렁거리다                 0         0          0        0  ...       0       0   \n",
       "불안/압박감                   0         0          0        0  ...       0       0   \n",
       "\n",
       "                  절망감/하찮음  자살충동/하찮음  불안/불안  불안/긴장  불안/낭떠러지 끝에 있는 느낌  불안/두렵다  \\\n",
       "우울감/우울                  0         0      0      0                 0       0   \n",
       "우울감/침울                  0         0      0      0                 0       0   \n",
       "우울감/멍함                  0         0      0      0                 0       0   \n",
       "우울감/무기력                 0         0      0      0                 0       0   \n",
       "우울감/의욕감소                0         0      0      0                 0       0   \n",
       "...                   ...       ...    ...    ...               ...     ...   \n",
       "불안/긴장                   0         0      0     19                 0       0   \n",
       "불안/낭떠러지 끝에 있는 느낌        0         0      0      0                 6       0   \n",
       "불안/두렵다                  0         0      0      0                 0      16   \n",
       "불안/울렁거리다                0         0      1      0                 0       0   \n",
       "불안/압박감                  0         0      5      0                 0       0   \n",
       "\n",
       "                  불안/울렁거리다  불안/압박감  \n",
       "우울감/우울                   0       0  \n",
       "우울감/침울                   0       0  \n",
       "우울감/멍함                   0       0  \n",
       "우울감/무기력                  0       0  \n",
       "우울감/의욕감소                 0       0  \n",
       "...                    ...     ...  \n",
       "불안/긴장                    0       0  \n",
       "불안/낭떠러지 끝에 있는 느낌         0       0  \n",
       "불안/두렵다                   0       0  \n",
       "불안/울렁거리다                16       0  \n",
       "불안/압박감                   0      66  \n",
       "\n",
       "[205 rows x 205 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.787"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = round(f1_score(y_true, y_pred, average='micro'), 3) \n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8762729244066882"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875715101145124"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ik_idx = list(range(len(ik_list)))\n",
    "ik_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/chatbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/chatbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ubuntu/anaconda3/envs/chatbot/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '           0       0.74      0.94      0.83        18',\n",
       " '           1       0.79      0.85      0.81        13',\n",
       " '           2       0.72      0.93      0.81        14',\n",
       " '           3       0.26      0.42      0.32        12',\n",
       " '           4       0.71      0.83      0.77        12',\n",
       " '           5       0.64      0.58      0.61        12',\n",
       " '           6       0.69      0.69      0.69        13',\n",
       " '           7       0.69      0.75      0.72        12',\n",
       " '           8       1.00      0.75      0.86        12',\n",
       " '           9       0.89      0.67      0.76        12',\n",
       " '          10       0.17      0.08      0.11        12',\n",
       " '          11       0.30      0.25      0.27        12',\n",
       " '          12       0.91      0.85      0.88       179',\n",
       " '          13       0.56      0.77      0.65        13',\n",
       " '          14       0.80      0.67      0.73        12',\n",
       " '          15       0.77      0.83      0.80        12',\n",
       " '          16       0.82      0.75      0.78        12',\n",
       " '          17       0.86      0.50      0.63        12',\n",
       " '          18       0.90      0.75      0.82        12',\n",
       " '          19       0.65      0.92      0.76        12',\n",
       " '          20       1.00      1.00      1.00        13',\n",
       " '          21       1.00      0.92      0.96        13',\n",
       " '          22       0.89      0.67      0.76        12',\n",
       " '          23       0.77      0.77      0.77        13',\n",
       " '          24       0.89      0.67      0.76        12',\n",
       " '          25       0.70      0.58      0.64        12',\n",
       " '          26       0.82      0.75      0.78        12',\n",
       " '          27       0.64      0.82      0.72        11',\n",
       " '          28       0.53      0.75      0.62        12',\n",
       " '          29       0.58      0.54      0.56        13',\n",
       " '          30       0.84      0.84      0.84       150',\n",
       " '          31       0.54      0.58      0.56        12',\n",
       " '          32       0.77      0.77      0.77        13',\n",
       " '          33       0.54      0.58      0.56        12',\n",
       " '          34       0.86      0.92      0.89        13',\n",
       " '          35       0.62      0.83      0.71        12',\n",
       " '          36       0.88      0.58      0.70        12',\n",
       " '          37       0.60      0.50      0.55        12',\n",
       " '          38       1.00      0.83      0.91        12',\n",
       " '          39       0.79      0.76      0.77        58',\n",
       " '          40       0.50      0.57      0.53        14',\n",
       " '          41       0.38      0.25      0.30        12',\n",
       " '          42       0.33      0.50      0.40        12',\n",
       " '          43       0.69      0.85      0.76        13',\n",
       " '          44       0.89      0.62      0.73        13',\n",
       " '          45       0.90      0.69      0.78        13',\n",
       " '          46       0.33      0.17      0.22        12',\n",
       " '          47       0.81      0.74      0.77       128',\n",
       " '          48       0.69      0.75      0.72        12',\n",
       " '          49       0.67      0.50      0.57        12',\n",
       " '          50       0.50      0.25      0.33        12',\n",
       " '          51       0.13      0.17      0.15        12',\n",
       " '          52       0.36      0.33      0.35        12',\n",
       " '          53       0.00      0.00      0.00         4',\n",
       " '          54       0.00      0.00      0.00         4',\n",
       " '          55       0.20      0.25      0.22         4',\n",
       " '          56       0.00      0.00      0.00         4',\n",
       " '          57       0.71      0.78      0.75       181',\n",
       " '          58       0.50      0.75      0.60         4',\n",
       " '          59       0.33      0.50      0.40         4',\n",
       " '          60       1.00      0.25      0.40         4',\n",
       " '          61       0.00      0.00      0.00         4',\n",
       " '          62       0.17      0.25      0.20         4',\n",
       " '          63       0.75      0.62      0.68        34',\n",
       " '          64       1.00      1.00      1.00         4',\n",
       " '          65       1.00      1.00      1.00         4',\n",
       " '          66       1.00      1.00      1.00         4',\n",
       " '          67       0.80      1.00      0.89         4',\n",
       " '          68       0.67      1.00      0.80         4',\n",
       " '          69       1.00      1.00      1.00         4',\n",
       " '          70       1.00      1.00      1.00         4',\n",
       " '          71       0.80      1.00      0.89         4',\n",
       " '          72       1.00      1.00      1.00         4',\n",
       " '          73       0.75      0.75      0.75         4',\n",
       " '          74       1.00      1.00      1.00         4',\n",
       " '          75       0.69      0.87      0.77        39',\n",
       " '          76       0.50      0.47      0.48        15',\n",
       " '          77       0.86      1.00      0.92        12',\n",
       " '          78       0.44      0.33      0.38        12',\n",
       " '          79       0.73      0.85      0.79        13',\n",
       " '          80       0.92      0.85      0.88        13',\n",
       " '          81       1.00      0.92      0.96        13',\n",
       " '          82       0.77      0.83      0.80        12',\n",
       " '          83       0.78      0.78      0.78        92',\n",
       " '          84       0.73      0.92      0.81        12',\n",
       " '          85       0.85      0.92      0.88        12',\n",
       " '          86       0.89      0.67      0.76        12',\n",
       " '          87       1.00      0.75      0.86        12',\n",
       " '          88       0.63      0.58      0.60        38',\n",
       " '          89       0.40      0.67      0.50        12',\n",
       " '          90       0.56      0.42      0.48        12',\n",
       " '          91       0.69      0.92      0.79        12',\n",
       " '          92       0.78      0.58      0.67        12',\n",
       " '          93       0.91      0.83      0.87        12',\n",
       " '          94       0.90      0.75      0.82        12',\n",
       " '          95       0.75      0.75      0.75        12',\n",
       " '          96       0.92      0.92      0.92        12',\n",
       " '          97       0.91      0.83      0.87        12',\n",
       " '          98       0.85      0.92      0.88        12',\n",
       " '          99       0.53      0.75      0.62        12',\n",
       " '         100       1.00      1.00      1.00        12',\n",
       " '         101       0.75      0.75      0.75        12',\n",
       " '         102       1.00      0.92      0.96        12',\n",
       " '         103       0.88      0.58      0.70        12',\n",
       " '         104       0.82      0.75      0.78        12',\n",
       " '         105       0.90      0.88      0.89       180',\n",
       " '         106       0.92      1.00      0.96        12',\n",
       " '         107       0.92      1.00      0.96        12',\n",
       " '         108       0.86      1.00      0.92        12',\n",
       " '         109       0.80      1.00      0.89        12',\n",
       " '         110       0.75      0.69      0.72        13',\n",
       " '         111       1.00      1.00      1.00        12',\n",
       " '         112       0.89      0.67      0.76        12',\n",
       " '         113       1.00      1.00      1.00        12',\n",
       " '         114       0.75      0.56      0.64        16',\n",
       " '         115       0.92      0.92      0.92        12',\n",
       " '         116       0.80      1.00      0.89        12',\n",
       " '         117       0.75      1.00      0.86        12',\n",
       " '         118       1.00      0.92      0.96        12',\n",
       " '         119       1.00      1.00      1.00        12',\n",
       " '         120       0.85      0.92      0.88        12',\n",
       " '         121       0.75      0.75      0.75        20',\n",
       " '         122       0.82      0.85      0.84       332',\n",
       " '         123       0.92      0.92      0.92        13',\n",
       " '         124       0.88      0.70      0.78        10',\n",
       " '         125       0.92      1.00      0.96        12',\n",
       " '         126       0.53      0.67      0.59        12',\n",
       " '         127       1.00      1.00      1.00        12',\n",
       " '         128       0.92      0.92      0.92        12',\n",
       " '         129       1.00      1.00      1.00        12',\n",
       " '         130       0.53      0.75      0.62        12',\n",
       " '         131       1.00      0.83      0.91        12',\n",
       " '         132       0.93      0.93      0.93        15',\n",
       " '         133       0.67      0.67      0.67        12',\n",
       " '         134       0.82      0.75      0.78        12',\n",
       " '         135       0.87      0.82      0.84       103',\n",
       " '         136       0.71      0.83      0.77        12',\n",
       " '         137       1.00      0.83      0.91        12',\n",
       " '         138       0.83      0.91      0.87        11',\n",
       " '         139       0.85      0.92      0.88        12',\n",
       " '         140       0.83      0.71      0.77         7',\n",
       " '         141       1.00      0.82      0.90        11',\n",
       " '         142       0.83      0.50      0.62        10',\n",
       " '         143       0.88      0.58      0.70        12',\n",
       " '         144       0.33      0.50      0.40         2',\n",
       " '         145       0.71      0.83      0.77        12',\n",
       " '         146       0.50      0.58      0.54        12',\n",
       " '         147       0.80      0.67      0.73        12',\n",
       " '         148       0.50      0.58      0.54        12',\n",
       " '         149       0.77      0.77      0.77        98',\n",
       " '         150       0.80      1.00      0.89         4',\n",
       " '         151       1.00      1.00      1.00         4',\n",
       " '         152       1.00      1.00      1.00         3',\n",
       " '         153       1.00      1.00      1.00         4',\n",
       " '         154       1.00      1.00      1.00         4',\n",
       " '         155       1.00      1.00      1.00         4',\n",
       " '         156       0.67      0.50      0.57         4',\n",
       " '         157       0.00      0.00      0.00         4',\n",
       " '         158       0.22      0.50      0.31         4',\n",
       " '         159       0.00      0.00      0.00         4',\n",
       " '         160       0.45      0.50      0.48        10',\n",
       " '         161       1.00      1.00      1.00         3',\n",
       " '         162       1.00      1.00      1.00         2',\n",
       " '         163       0.67      1.00      0.80         4',\n",
       " '         164       1.00      0.67      0.80         3',\n",
       " '         165       1.00      0.67      0.80         3',\n",
       " '         166       0.75      1.00      0.86         3',\n",
       " '         167       1.00      0.33      0.50         3',\n",
       " '         168       0.79      0.72      0.76        43',\n",
       " '         169       0.90      0.75      0.82        12',\n",
       " '         170       0.71      0.83      0.77        12',\n",
       " '         171       0.92      1.00      0.96        12',\n",
       " '         172       1.00      1.00      1.00        12',\n",
       " '         173       1.00      1.00      1.00        13',\n",
       " '         174       0.77      0.83      0.80        12',\n",
       " '         175       0.92      0.92      0.92        12',\n",
       " '         176       0.50      0.20      0.29        10',\n",
       " '         177       0.92      0.92      0.92        12',\n",
       " '         178       0.85      0.92      0.88        12',\n",
       " '         179       0.79      0.92      0.85        12',\n",
       " '         180       0.92      1.00      0.96        12',\n",
       " '         181       0.84      1.00      0.91        16',\n",
       " '         182       0.92      1.00      0.96        11',\n",
       " '         183       0.83      0.77      0.80        13',\n",
       " '         184       0.72      0.79      0.75        61',\n",
       " '         185       0.69      0.92      0.79        12',\n",
       " '         186       0.71      0.91      0.80        11',\n",
       " '         187       0.73      0.92      0.81        12',\n",
       " '         188       0.80      1.00      0.89        12',\n",
       " '         189       1.00      0.92      0.96        12',\n",
       " '         190       1.00      1.00      1.00        12',\n",
       " '         191       0.82      0.69      0.75        13',\n",
       " '         192       1.00      0.50      0.67         4',\n",
       " '         193       0.67      1.00      0.80         4',\n",
       " '         194       1.00      1.00      1.00         3',\n",
       " '         195       1.00      1.00      1.00         4',\n",
       " '         196       0.75      0.75      0.75         4',\n",
       " '         197       0.60      0.68      0.64        41',\n",
       " '         198       0.94      0.93      0.93       130',\n",
       " '         199       0.80      0.97      0.88        29',\n",
       " '         200       0.76      0.95      0.84        20',\n",
       " '         201       0.86      0.86      0.86         7',\n",
       " '         202       0.94      0.94      0.94        17',\n",
       " '         203       1.00      0.94      0.97        17',\n",
       " '         204       0.82      0.69      0.75        96',\n",
       " '',\n",
       " '    accuracy                           0.79      3936',\n",
       " '   macro avg       0.76      0.75      0.75      3936',\n",
       " 'weighted avg       0.79      0.79      0.78      3936',\n",
       " '']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr = classification_report(y_true, y_pred).split('\\n')\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['precision', 'recall', 'f1-score', 'support'],\n",
       " [],\n",
       " ['0', '0.74', '0.94', '0.83', '18'],\n",
       " ['1', '0.79', '0.85', '0.81', '13'],\n",
       " ['2', '0.72', '0.93', '0.81', '14'],\n",
       " ['3', '0.26', '0.42', '0.32', '12'],\n",
       " ['4', '0.71', '0.83', '0.77', '12'],\n",
       " ['5', '0.64', '0.58', '0.61', '12'],\n",
       " ['6', '0.69', '0.69', '0.69', '13'],\n",
       " ['7', '0.69', '0.75', '0.72', '12'],\n",
       " ['8', '1.00', '0.75', '0.86', '12'],\n",
       " ['9', '0.89', '0.67', '0.76', '12'],\n",
       " ['10', '0.17', '0.08', '0.11', '12'],\n",
       " ['11', '0.30', '0.25', '0.27', '12'],\n",
       " ['12', '0.91', '0.85', '0.88', '179'],\n",
       " ['13', '0.56', '0.77', '0.65', '13'],\n",
       " ['14', '0.80', '0.67', '0.73', '12'],\n",
       " ['15', '0.77', '0.83', '0.80', '12'],\n",
       " ['16', '0.82', '0.75', '0.78', '12'],\n",
       " ['17', '0.86', '0.50', '0.63', '12'],\n",
       " ['18', '0.90', '0.75', '0.82', '12'],\n",
       " ['19', '0.65', '0.92', '0.76', '12'],\n",
       " ['20', '1.00', '1.00', '1.00', '13'],\n",
       " ['21', '1.00', '0.92', '0.96', '13'],\n",
       " ['22', '0.89', '0.67', '0.76', '12'],\n",
       " ['23', '0.77', '0.77', '0.77', '13'],\n",
       " ['24', '0.89', '0.67', '0.76', '12'],\n",
       " ['25', '0.70', '0.58', '0.64', '12'],\n",
       " ['26', '0.82', '0.75', '0.78', '12'],\n",
       " ['27', '0.64', '0.82', '0.72', '11'],\n",
       " ['28', '0.53', '0.75', '0.62', '12'],\n",
       " ['29', '0.58', '0.54', '0.56', '13'],\n",
       " ['30', '0.84', '0.84', '0.84', '150'],\n",
       " ['31', '0.54', '0.58', '0.56', '12'],\n",
       " ['32', '0.77', '0.77', '0.77', '13'],\n",
       " ['33', '0.54', '0.58', '0.56', '12'],\n",
       " ['34', '0.86', '0.92', '0.89', '13'],\n",
       " ['35', '0.62', '0.83', '0.71', '12'],\n",
       " ['36', '0.88', '0.58', '0.70', '12'],\n",
       " ['37', '0.60', '0.50', '0.55', '12'],\n",
       " ['38', '1.00', '0.83', '0.91', '12'],\n",
       " ['39', '0.79', '0.76', '0.77', '58'],\n",
       " ['40', '0.50', '0.57', '0.53', '14'],\n",
       " ['41', '0.38', '0.25', '0.30', '12'],\n",
       " ['42', '0.33', '0.50', '0.40', '12'],\n",
       " ['43', '0.69', '0.85', '0.76', '13'],\n",
       " ['44', '0.89', '0.62', '0.73', '13'],\n",
       " ['45', '0.90', '0.69', '0.78', '13'],\n",
       " ['46', '0.33', '0.17', '0.22', '12'],\n",
       " ['47', '0.81', '0.74', '0.77', '128'],\n",
       " ['48', '0.69', '0.75', '0.72', '12'],\n",
       " ['49', '0.67', '0.50', '0.57', '12'],\n",
       " ['50', '0.50', '0.25', '0.33', '12'],\n",
       " ['51', '0.13', '0.17', '0.15', '12'],\n",
       " ['52', '0.36', '0.33', '0.35', '12'],\n",
       " ['53', '0.00', '0.00', '0.00', '4'],\n",
       " ['54', '0.00', '0.00', '0.00', '4'],\n",
       " ['55', '0.20', '0.25', '0.22', '4'],\n",
       " ['56', '0.00', '0.00', '0.00', '4'],\n",
       " ['57', '0.71', '0.78', '0.75', '181'],\n",
       " ['58', '0.50', '0.75', '0.60', '4'],\n",
       " ['59', '0.33', '0.50', '0.40', '4'],\n",
       " ['60', '1.00', '0.25', '0.40', '4'],\n",
       " ['61', '0.00', '0.00', '0.00', '4'],\n",
       " ['62', '0.17', '0.25', '0.20', '4'],\n",
       " ['63', '0.75', '0.62', '0.68', '34'],\n",
       " ['64', '1.00', '1.00', '1.00', '4'],\n",
       " ['65', '1.00', '1.00', '1.00', '4'],\n",
       " ['66', '1.00', '1.00', '1.00', '4'],\n",
       " ['67', '0.80', '1.00', '0.89', '4'],\n",
       " ['68', '0.67', '1.00', '0.80', '4'],\n",
       " ['69', '1.00', '1.00', '1.00', '4'],\n",
       " ['70', '1.00', '1.00', '1.00', '4'],\n",
       " ['71', '0.80', '1.00', '0.89', '4'],\n",
       " ['72', '1.00', '1.00', '1.00', '4'],\n",
       " ['73', '0.75', '0.75', '0.75', '4'],\n",
       " ['74', '1.00', '1.00', '1.00', '4'],\n",
       " ['75', '0.69', '0.87', '0.77', '39'],\n",
       " ['76', '0.50', '0.47', '0.48', '15'],\n",
       " ['77', '0.86', '1.00', '0.92', '12'],\n",
       " ['78', '0.44', '0.33', '0.38', '12'],\n",
       " ['79', '0.73', '0.85', '0.79', '13'],\n",
       " ['80', '0.92', '0.85', '0.88', '13'],\n",
       " ['81', '1.00', '0.92', '0.96', '13'],\n",
       " ['82', '0.77', '0.83', '0.80', '12'],\n",
       " ['83', '0.78', '0.78', '0.78', '92'],\n",
       " ['84', '0.73', '0.92', '0.81', '12'],\n",
       " ['85', '0.85', '0.92', '0.88', '12'],\n",
       " ['86', '0.89', '0.67', '0.76', '12'],\n",
       " ['87', '1.00', '0.75', '0.86', '12'],\n",
       " ['88', '0.63', '0.58', '0.60', '38'],\n",
       " ['89', '0.40', '0.67', '0.50', '12'],\n",
       " ['90', '0.56', '0.42', '0.48', '12'],\n",
       " ['91', '0.69', '0.92', '0.79', '12'],\n",
       " ['92', '0.78', '0.58', '0.67', '12'],\n",
       " ['93', '0.91', '0.83', '0.87', '12'],\n",
       " ['94', '0.90', '0.75', '0.82', '12'],\n",
       " ['95', '0.75', '0.75', '0.75', '12'],\n",
       " ['96', '0.92', '0.92', '0.92', '12'],\n",
       " ['97', '0.91', '0.83', '0.87', '12'],\n",
       " ['98', '0.85', '0.92', '0.88', '12'],\n",
       " ['99', '0.53', '0.75', '0.62', '12'],\n",
       " ['100', '1.00', '1.00', '1.00', '12'],\n",
       " ['101', '0.75', '0.75', '0.75', '12'],\n",
       " ['102', '1.00', '0.92', '0.96', '12'],\n",
       " ['103', '0.88', '0.58', '0.70', '12'],\n",
       " ['104', '0.82', '0.75', '0.78', '12'],\n",
       " ['105', '0.90', '0.88', '0.89', '180'],\n",
       " ['106', '0.92', '1.00', '0.96', '12'],\n",
       " ['107', '0.92', '1.00', '0.96', '12'],\n",
       " ['108', '0.86', '1.00', '0.92', '12'],\n",
       " ['109', '0.80', '1.00', '0.89', '12'],\n",
       " ['110', '0.75', '0.69', '0.72', '13'],\n",
       " ['111', '1.00', '1.00', '1.00', '12'],\n",
       " ['112', '0.89', '0.67', '0.76', '12'],\n",
       " ['113', '1.00', '1.00', '1.00', '12'],\n",
       " ['114', '0.75', '0.56', '0.64', '16'],\n",
       " ['115', '0.92', '0.92', '0.92', '12'],\n",
       " ['116', '0.80', '1.00', '0.89', '12'],\n",
       " ['117', '0.75', '1.00', '0.86', '12'],\n",
       " ['118', '1.00', '0.92', '0.96', '12'],\n",
       " ['119', '1.00', '1.00', '1.00', '12'],\n",
       " ['120', '0.85', '0.92', '0.88', '12'],\n",
       " ['121', '0.75', '0.75', '0.75', '20'],\n",
       " ['122', '0.82', '0.85', '0.84', '332'],\n",
       " ['123', '0.92', '0.92', '0.92', '13'],\n",
       " ['124', '0.88', '0.70', '0.78', '10'],\n",
       " ['125', '0.92', '1.00', '0.96', '12'],\n",
       " ['126', '0.53', '0.67', '0.59', '12'],\n",
       " ['127', '1.00', '1.00', '1.00', '12'],\n",
       " ['128', '0.92', '0.92', '0.92', '12'],\n",
       " ['129', '1.00', '1.00', '1.00', '12'],\n",
       " ['130', '0.53', '0.75', '0.62', '12'],\n",
       " ['131', '1.00', '0.83', '0.91', '12'],\n",
       " ['132', '0.93', '0.93', '0.93', '15'],\n",
       " ['133', '0.67', '0.67', '0.67', '12'],\n",
       " ['134', '0.82', '0.75', '0.78', '12'],\n",
       " ['135', '0.87', '0.82', '0.84', '103'],\n",
       " ['136', '0.71', '0.83', '0.77', '12'],\n",
       " ['137', '1.00', '0.83', '0.91', '12'],\n",
       " ['138', '0.83', '0.91', '0.87', '11'],\n",
       " ['139', '0.85', '0.92', '0.88', '12'],\n",
       " ['140', '0.83', '0.71', '0.77', '7'],\n",
       " ['141', '1.00', '0.82', '0.90', '11'],\n",
       " ['142', '0.83', '0.50', '0.62', '10'],\n",
       " ['143', '0.88', '0.58', '0.70', '12'],\n",
       " ['144', '0.33', '0.50', '0.40', '2'],\n",
       " ['145', '0.71', '0.83', '0.77', '12'],\n",
       " ['146', '0.50', '0.58', '0.54', '12'],\n",
       " ['147', '0.80', '0.67', '0.73', '12'],\n",
       " ['148', '0.50', '0.58', '0.54', '12'],\n",
       " ['149', '0.77', '0.77', '0.77', '98'],\n",
       " ['150', '0.80', '1.00', '0.89', '4'],\n",
       " ['151', '1.00', '1.00', '1.00', '4'],\n",
       " ['152', '1.00', '1.00', '1.00', '3'],\n",
       " ['153', '1.00', '1.00', '1.00', '4'],\n",
       " ['154', '1.00', '1.00', '1.00', '4'],\n",
       " ['155', '1.00', '1.00', '1.00', '4'],\n",
       " ['156', '0.67', '0.50', '0.57', '4'],\n",
       " ['157', '0.00', '0.00', '0.00', '4'],\n",
       " ['158', '0.22', '0.50', '0.31', '4'],\n",
       " ['159', '0.00', '0.00', '0.00', '4'],\n",
       " ['160', '0.45', '0.50', '0.48', '10'],\n",
       " ['161', '1.00', '1.00', '1.00', '3'],\n",
       " ['162', '1.00', '1.00', '1.00', '2'],\n",
       " ['163', '0.67', '1.00', '0.80', '4'],\n",
       " ['164', '1.00', '0.67', '0.80', '3'],\n",
       " ['165', '1.00', '0.67', '0.80', '3'],\n",
       " ['166', '0.75', '1.00', '0.86', '3'],\n",
       " ['167', '1.00', '0.33', '0.50', '3'],\n",
       " ['168', '0.79', '0.72', '0.76', '43'],\n",
       " ['169', '0.90', '0.75', '0.82', '12'],\n",
       " ['170', '0.71', '0.83', '0.77', '12'],\n",
       " ['171', '0.92', '1.00', '0.96', '12'],\n",
       " ['172', '1.00', '1.00', '1.00', '12'],\n",
       " ['173', '1.00', '1.00', '1.00', '13'],\n",
       " ['174', '0.77', '0.83', '0.80', '12'],\n",
       " ['175', '0.92', '0.92', '0.92', '12'],\n",
       " ['176', '0.50', '0.20', '0.29', '10'],\n",
       " ['177', '0.92', '0.92', '0.92', '12'],\n",
       " ['178', '0.85', '0.92', '0.88', '12'],\n",
       " ['179', '0.79', '0.92', '0.85', '12'],\n",
       " ['180', '0.92', '1.00', '0.96', '12'],\n",
       " ['181', '0.84', '1.00', '0.91', '16'],\n",
       " ['182', '0.92', '1.00', '0.96', '11'],\n",
       " ['183', '0.83', '0.77', '0.80', '13'],\n",
       " ['184', '0.72', '0.79', '0.75', '61'],\n",
       " ['185', '0.69', '0.92', '0.79', '12'],\n",
       " ['186', '0.71', '0.91', '0.80', '11'],\n",
       " ['187', '0.73', '0.92', '0.81', '12'],\n",
       " ['188', '0.80', '1.00', '0.89', '12'],\n",
       " ['189', '1.00', '0.92', '0.96', '12'],\n",
       " ['190', '1.00', '1.00', '1.00', '12'],\n",
       " ['191', '0.82', '0.69', '0.75', '13'],\n",
       " ['192', '1.00', '0.50', '0.67', '4'],\n",
       " ['193', '0.67', '1.00', '0.80', '4'],\n",
       " ['194', '1.00', '1.00', '1.00', '3'],\n",
       " ['195', '1.00', '1.00', '1.00', '4'],\n",
       " ['196', '0.75', '0.75', '0.75', '4'],\n",
       " ['197', '0.60', '0.68', '0.64', '41'],\n",
       " ['198', '0.94', '0.93', '0.93', '130'],\n",
       " ['199', '0.80', '0.97', '0.88', '29'],\n",
       " ['200', '0.76', '0.95', '0.84', '20'],\n",
       " ['201', '0.86', '0.86', '0.86', '7'],\n",
       " ['202', '0.94', '0.94', '0.94', '17'],\n",
       " ['203', '1.00', '0.94', '0.97', '17'],\n",
       " ['204', '0.82', '0.69', '0.75', '96'],\n",
       " [],\n",
       " ['accuracy', '0.79', '3936'],\n",
       " ['macro', 'avg', '0.76', '0.75', '0.75', '3936'],\n",
       " ['weighted', 'avg', '0.79', '0.79', '0.78', '3936'],\n",
       " []]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = []\n",
    "\n",
    "for idx, line in enumerate(cr):\n",
    "    clr_df.append([])\n",
    "    if line == '':\n",
    "        continue\n",
    "    \n",
    "    word_list = line.strip().split(' ')\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word != '':\n",
    "            clr_df[idx].append(word)\n",
    "\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_df[-2][0] = ' '.join([clr_df[-2][0], clr_df[-2][1]])\n",
    "clr_df[-3][0] = ' '.join([clr_df[-3][0], clr_df[-3][1]])\n",
    "clr_df[-4].insert(1, ' ')\n",
    "clr_df[-4].insert(2, ' ')\n",
    "clr_df[0].insert(0, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'precision', 'recall', 'f1-score', 'support'],\n",
       " ['0', '0.74', '0.94', '0.83', '18'],\n",
       " ['1', '0.79', '0.85', '0.81', '13'],\n",
       " ['2', '0.72', '0.93', '0.81', '14'],\n",
       " ['3', '0.26', '0.42', '0.32', '12'],\n",
       " ['4', '0.71', '0.83', '0.77', '12'],\n",
       " ['5', '0.64', '0.58', '0.61', '12'],\n",
       " ['6', '0.69', '0.69', '0.69', '13'],\n",
       " ['7', '0.69', '0.75', '0.72', '12'],\n",
       " ['8', '1.00', '0.75', '0.86', '12'],\n",
       " ['9', '0.89', '0.67', '0.76', '12'],\n",
       " ['10', '0.17', '0.08', '0.11', '12'],\n",
       " ['11', '0.30', '0.25', '0.27', '12'],\n",
       " ['12', '0.91', '0.85', '0.88', '179'],\n",
       " ['13', '0.56', '0.77', '0.65', '13'],\n",
       " ['14', '0.80', '0.67', '0.73', '12'],\n",
       " ['15', '0.77', '0.83', '0.80', '12'],\n",
       " ['16', '0.82', '0.75', '0.78', '12'],\n",
       " ['17', '0.86', '0.50', '0.63', '12'],\n",
       " ['18', '0.90', '0.75', '0.82', '12'],\n",
       " ['19', '0.65', '0.92', '0.76', '12'],\n",
       " ['20', '1.00', '1.00', '1.00', '13'],\n",
       " ['21', '1.00', '0.92', '0.96', '13'],\n",
       " ['22', '0.89', '0.67', '0.76', '12'],\n",
       " ['23', '0.77', '0.77', '0.77', '13'],\n",
       " ['24', '0.89', '0.67', '0.76', '12'],\n",
       " ['25', '0.70', '0.58', '0.64', '12'],\n",
       " ['26', '0.82', '0.75', '0.78', '12'],\n",
       " ['27', '0.64', '0.82', '0.72', '11'],\n",
       " ['28', '0.53', '0.75', '0.62', '12'],\n",
       " ['29', '0.58', '0.54', '0.56', '13'],\n",
       " ['30', '0.84', '0.84', '0.84', '150'],\n",
       " ['31', '0.54', '0.58', '0.56', '12'],\n",
       " ['32', '0.77', '0.77', '0.77', '13'],\n",
       " ['33', '0.54', '0.58', '0.56', '12'],\n",
       " ['34', '0.86', '0.92', '0.89', '13'],\n",
       " ['35', '0.62', '0.83', '0.71', '12'],\n",
       " ['36', '0.88', '0.58', '0.70', '12'],\n",
       " ['37', '0.60', '0.50', '0.55', '12'],\n",
       " ['38', '1.00', '0.83', '0.91', '12'],\n",
       " ['39', '0.79', '0.76', '0.77', '58'],\n",
       " ['40', '0.50', '0.57', '0.53', '14'],\n",
       " ['41', '0.38', '0.25', '0.30', '12'],\n",
       " ['42', '0.33', '0.50', '0.40', '12'],\n",
       " ['43', '0.69', '0.85', '0.76', '13'],\n",
       " ['44', '0.89', '0.62', '0.73', '13'],\n",
       " ['45', '0.90', '0.69', '0.78', '13'],\n",
       " ['46', '0.33', '0.17', '0.22', '12'],\n",
       " ['47', '0.81', '0.74', '0.77', '128'],\n",
       " ['48', '0.69', '0.75', '0.72', '12'],\n",
       " ['49', '0.67', '0.50', '0.57', '12'],\n",
       " ['50', '0.50', '0.25', '0.33', '12'],\n",
       " ['51', '0.13', '0.17', '0.15', '12'],\n",
       " ['52', '0.36', '0.33', '0.35', '12'],\n",
       " ['53', '0.00', '0.00', '0.00', '4'],\n",
       " ['54', '0.00', '0.00', '0.00', '4'],\n",
       " ['55', '0.20', '0.25', '0.22', '4'],\n",
       " ['56', '0.00', '0.00', '0.00', '4'],\n",
       " ['57', '0.71', '0.78', '0.75', '181'],\n",
       " ['58', '0.50', '0.75', '0.60', '4'],\n",
       " ['59', '0.33', '0.50', '0.40', '4'],\n",
       " ['60', '1.00', '0.25', '0.40', '4'],\n",
       " ['61', '0.00', '0.00', '0.00', '4'],\n",
       " ['62', '0.17', '0.25', '0.20', '4'],\n",
       " ['63', '0.75', '0.62', '0.68', '34'],\n",
       " ['64', '1.00', '1.00', '1.00', '4'],\n",
       " ['65', '1.00', '1.00', '1.00', '4'],\n",
       " ['66', '1.00', '1.00', '1.00', '4'],\n",
       " ['67', '0.80', '1.00', '0.89', '4'],\n",
       " ['68', '0.67', '1.00', '0.80', '4'],\n",
       " ['69', '1.00', '1.00', '1.00', '4'],\n",
       " ['70', '1.00', '1.00', '1.00', '4'],\n",
       " ['71', '0.80', '1.00', '0.89', '4'],\n",
       " ['72', '1.00', '1.00', '1.00', '4'],\n",
       " ['73', '0.75', '0.75', '0.75', '4'],\n",
       " ['74', '1.00', '1.00', '1.00', '4'],\n",
       " ['75', '0.69', '0.87', '0.77', '39'],\n",
       " ['76', '0.50', '0.47', '0.48', '15'],\n",
       " ['77', '0.86', '1.00', '0.92', '12'],\n",
       " ['78', '0.44', '0.33', '0.38', '12'],\n",
       " ['79', '0.73', '0.85', '0.79', '13'],\n",
       " ['80', '0.92', '0.85', '0.88', '13'],\n",
       " ['81', '1.00', '0.92', '0.96', '13'],\n",
       " ['82', '0.77', '0.83', '0.80', '12'],\n",
       " ['83', '0.78', '0.78', '0.78', '92'],\n",
       " ['84', '0.73', '0.92', '0.81', '12'],\n",
       " ['85', '0.85', '0.92', '0.88', '12'],\n",
       " ['86', '0.89', '0.67', '0.76', '12'],\n",
       " ['87', '1.00', '0.75', '0.86', '12'],\n",
       " ['88', '0.63', '0.58', '0.60', '38'],\n",
       " ['89', '0.40', '0.67', '0.50', '12'],\n",
       " ['90', '0.56', '0.42', '0.48', '12'],\n",
       " ['91', '0.69', '0.92', '0.79', '12'],\n",
       " ['92', '0.78', '0.58', '0.67', '12'],\n",
       " ['93', '0.91', '0.83', '0.87', '12'],\n",
       " ['94', '0.90', '0.75', '0.82', '12'],\n",
       " ['95', '0.75', '0.75', '0.75', '12'],\n",
       " ['96', '0.92', '0.92', '0.92', '12'],\n",
       " ['97', '0.91', '0.83', '0.87', '12'],\n",
       " ['98', '0.85', '0.92', '0.88', '12'],\n",
       " ['99', '0.53', '0.75', '0.62', '12'],\n",
       " ['100', '1.00', '1.00', '1.00', '12'],\n",
       " ['101', '0.75', '0.75', '0.75', '12'],\n",
       " ['102', '1.00', '0.92', '0.96', '12'],\n",
       " ['103', '0.88', '0.58', '0.70', '12'],\n",
       " ['104', '0.82', '0.75', '0.78', '12'],\n",
       " ['105', '0.90', '0.88', '0.89', '180'],\n",
       " ['106', '0.92', '1.00', '0.96', '12'],\n",
       " ['107', '0.92', '1.00', '0.96', '12'],\n",
       " ['108', '0.86', '1.00', '0.92', '12'],\n",
       " ['109', '0.80', '1.00', '0.89', '12'],\n",
       " ['110', '0.75', '0.69', '0.72', '13'],\n",
       " ['111', '1.00', '1.00', '1.00', '12'],\n",
       " ['112', '0.89', '0.67', '0.76', '12'],\n",
       " ['113', '1.00', '1.00', '1.00', '12'],\n",
       " ['114', '0.75', '0.56', '0.64', '16'],\n",
       " ['115', '0.92', '0.92', '0.92', '12'],\n",
       " ['116', '0.80', '1.00', '0.89', '12'],\n",
       " ['117', '0.75', '1.00', '0.86', '12'],\n",
       " ['118', '1.00', '0.92', '0.96', '12'],\n",
       " ['119', '1.00', '1.00', '1.00', '12'],\n",
       " ['120', '0.85', '0.92', '0.88', '12'],\n",
       " ['121', '0.75', '0.75', '0.75', '20'],\n",
       " ['122', '0.82', '0.85', '0.84', '332'],\n",
       " ['123', '0.92', '0.92', '0.92', '13'],\n",
       " ['124', '0.88', '0.70', '0.78', '10'],\n",
       " ['125', '0.92', '1.00', '0.96', '12'],\n",
       " ['126', '0.53', '0.67', '0.59', '12'],\n",
       " ['127', '1.00', '1.00', '1.00', '12'],\n",
       " ['128', '0.92', '0.92', '0.92', '12'],\n",
       " ['129', '1.00', '1.00', '1.00', '12'],\n",
       " ['130', '0.53', '0.75', '0.62', '12'],\n",
       " ['131', '1.00', '0.83', '0.91', '12'],\n",
       " ['132', '0.93', '0.93', '0.93', '15'],\n",
       " ['133', '0.67', '0.67', '0.67', '12'],\n",
       " ['134', '0.82', '0.75', '0.78', '12'],\n",
       " ['135', '0.87', '0.82', '0.84', '103'],\n",
       " ['136', '0.71', '0.83', '0.77', '12'],\n",
       " ['137', '1.00', '0.83', '0.91', '12'],\n",
       " ['138', '0.83', '0.91', '0.87', '11'],\n",
       " ['139', '0.85', '0.92', '0.88', '12'],\n",
       " ['140', '0.83', '0.71', '0.77', '7'],\n",
       " ['141', '1.00', '0.82', '0.90', '11'],\n",
       " ['142', '0.83', '0.50', '0.62', '10'],\n",
       " ['143', '0.88', '0.58', '0.70', '12'],\n",
       " ['144', '0.33', '0.50', '0.40', '2'],\n",
       " ['145', '0.71', '0.83', '0.77', '12'],\n",
       " ['146', '0.50', '0.58', '0.54', '12'],\n",
       " ['147', '0.80', '0.67', '0.73', '12'],\n",
       " ['148', '0.50', '0.58', '0.54', '12'],\n",
       " ['149', '0.77', '0.77', '0.77', '98'],\n",
       " ['150', '0.80', '1.00', '0.89', '4'],\n",
       " ['151', '1.00', '1.00', '1.00', '4'],\n",
       " ['152', '1.00', '1.00', '1.00', '3'],\n",
       " ['153', '1.00', '1.00', '1.00', '4'],\n",
       " ['154', '1.00', '1.00', '1.00', '4'],\n",
       " ['155', '1.00', '1.00', '1.00', '4'],\n",
       " ['156', '0.67', '0.50', '0.57', '4'],\n",
       " ['157', '0.00', '0.00', '0.00', '4'],\n",
       " ['158', '0.22', '0.50', '0.31', '4'],\n",
       " ['159', '0.00', '0.00', '0.00', '4'],\n",
       " ['160', '0.45', '0.50', '0.48', '10'],\n",
       " ['161', '1.00', '1.00', '1.00', '3'],\n",
       " ['162', '1.00', '1.00', '1.00', '2'],\n",
       " ['163', '0.67', '1.00', '0.80', '4'],\n",
       " ['164', '1.00', '0.67', '0.80', '3'],\n",
       " ['165', '1.00', '0.67', '0.80', '3'],\n",
       " ['166', '0.75', '1.00', '0.86', '3'],\n",
       " ['167', '1.00', '0.33', '0.50', '3'],\n",
       " ['168', '0.79', '0.72', '0.76', '43'],\n",
       " ['169', '0.90', '0.75', '0.82', '12'],\n",
       " ['170', '0.71', '0.83', '0.77', '12'],\n",
       " ['171', '0.92', '1.00', '0.96', '12'],\n",
       " ['172', '1.00', '1.00', '1.00', '12'],\n",
       " ['173', '1.00', '1.00', '1.00', '13'],\n",
       " ['174', '0.77', '0.83', '0.80', '12'],\n",
       " ['175', '0.92', '0.92', '0.92', '12'],\n",
       " ['176', '0.50', '0.20', '0.29', '10'],\n",
       " ['177', '0.92', '0.92', '0.92', '12'],\n",
       " ['178', '0.85', '0.92', '0.88', '12'],\n",
       " ['179', '0.79', '0.92', '0.85', '12'],\n",
       " ['180', '0.92', '1.00', '0.96', '12'],\n",
       " ['181', '0.84', '1.00', '0.91', '16'],\n",
       " ['182', '0.92', '1.00', '0.96', '11'],\n",
       " ['183', '0.83', '0.77', '0.80', '13'],\n",
       " ['184', '0.72', '0.79', '0.75', '61'],\n",
       " ['185', '0.69', '0.92', '0.79', '12'],\n",
       " ['186', '0.71', '0.91', '0.80', '11'],\n",
       " ['187', '0.73', '0.92', '0.81', '12'],\n",
       " ['188', '0.80', '1.00', '0.89', '12'],\n",
       " ['189', '1.00', '0.92', '0.96', '12'],\n",
       " ['190', '1.00', '1.00', '1.00', '12'],\n",
       " ['191', '0.82', '0.69', '0.75', '13'],\n",
       " ['192', '1.00', '0.50', '0.67', '4'],\n",
       " ['193', '0.67', '1.00', '0.80', '4'],\n",
       " ['194', '1.00', '1.00', '1.00', '3'],\n",
       " ['195', '1.00', '1.00', '1.00', '4'],\n",
       " ['196', '0.75', '0.75', '0.75', '4'],\n",
       " ['197', '0.60', '0.68', '0.64', '41'],\n",
       " ['198', '0.94', '0.93', '0.93', '130'],\n",
       " ['199', '0.80', '0.97', '0.88', '29'],\n",
       " ['200', '0.76', '0.95', '0.84', '20'],\n",
       " ['201', '0.86', '0.86', '0.86', '7'],\n",
       " ['202', '0.94', '0.94', '0.94', '17'],\n",
       " ['203', '1.00', '0.94', '0.97', '17'],\n",
       " ['204', '0.82', '0.69', '0.75', '96'],\n",
       " ['accuracy', ' ', ' ', '0.79', '3936'],\n",
       " ['macro avg', '0.76', '0.75', '0.75', '3936'],\n",
       " ['weighted avg', '0.79', '0.79', '0.78', '3936']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df[-2].pop(1)\n",
    "clr_df[-3].pop(1)\n",
    "clr_df.pop(1)\n",
    "clr_df.pop(-1)\n",
    "clr_df.pop(-4)\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.32</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>203</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>204</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>accuracy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.79</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index precision recall f1-score support\n",
       "0               0      0.74   0.94     0.83      18\n",
       "1               1      0.79   0.85     0.81      13\n",
       "2               2      0.72   0.93     0.81      14\n",
       "3               3      0.26   0.42     0.32      12\n",
       "4               4      0.71   0.83     0.77      12\n",
       "..            ...       ...    ...      ...     ...\n",
       "203           203      1.00   0.94     0.97      17\n",
       "204           204      0.82   0.69     0.75      96\n",
       "205      accuracy                      0.79    3936\n",
       "206     macro avg      0.76   0.75     0.75    3936\n",
       "207  weighted avg      0.79   0.79     0.78    3936\n",
       "\n",
       "[208 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = pd.DataFrame(clr_df[1:], columns=clr_df[0])\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.83</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.32</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.97</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.79</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall f1-score support\n",
       "index                                         \n",
       "0                 0.74   0.94     0.83      18\n",
       "1                 0.79   0.85     0.81      13\n",
       "2                 0.72   0.93     0.81      14\n",
       "3                 0.26   0.42     0.32      12\n",
       "4                 0.71   0.83     0.77      12\n",
       "...                ...    ...      ...     ...\n",
       "203               1.00   0.94     0.97      17\n",
       "204               0.82   0.69     0.75      96\n",
       "accuracy                          0.79    3936\n",
       "macro avg         0.76   0.75     0.75    3936\n",
       "weighted avg      0.79   0.79     0.78    3936\n",
       "\n",
       "[208 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df.index = clr_df['index']\n",
    "\n",
    "del clr_df['index']\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_clr_df = clr_df.sort_values(by='f1-score',ascending=False)\n",
    "top = sorted_clr_df[:10]\n",
    "low = sorted_clr_df[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision recall f1-score support\n",
       "index                                  \n",
       "162        1.00   1.00     1.00       2\n",
       "70         1.00   1.00     1.00       4\n",
       "66         1.00   1.00     1.00       4\n",
       "65         1.00   1.00     1.00       4\n",
       "72         1.00   1.00     1.00       4\n",
       "64         1.00   1.00     1.00       4\n",
       "74         1.00   1.00     1.00       4\n",
       "173        1.00   1.00     1.00      13\n",
       "172        1.00   1.00     1.00      12\n",
       "20         1.00   1.00     1.00      13"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision recall f1-score support\n",
       "index                                  \n",
       "46         0.33   0.17     0.22      12\n",
       "62         0.17   0.25     0.20       4\n",
       "51         0.13   0.17     0.15      12\n",
       "10         0.17   0.08     0.11      12\n",
       "61         0.00   0.00     0.00       4\n",
       "56         0.00   0.00     0.00       4\n",
       "54         0.00   0.00     0.00       4\n",
       "53         0.00   0.00     0.00       4\n",
       "159        0.00   0.00     0.00       4\n",
       "157        0.00   0.00     0.00       4"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize \n",
    "\n",
    "y_true = label_binarize(y_true, classes=ik_idx)\n",
    "y_pred = label_binarize(y_pred, classes=ik_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ik_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_classes = 205\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict() \n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:,i], y_pred[:,i]) \n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "val = 0\n",
    "\n",
    "# font = {'size': 15}\n",
    "# plt.rc('font', **font)\n",
    "plt.rcParams.update({'font.size': 15, 'font.weight': 'normal'})\n",
    "\n",
    "for idx, i in enumerate(range(n_classes)):\n",
    "    if idx == 162 or idx == 10: \n",
    "        plt.subplot(121+val) \n",
    "        plt.plot(fpr[i], tpr[i], label = f'ROC curve(area = {round(roc_auc[i], 2)}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=18) \n",
    "        plt.ylabel('True Positive Rate', fontsize=18)\n",
    "        plt.title(f'Class {idx}', fontsize=18)\n",
    "        plt.legend(loc='lower right')\n",
    "        val += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'자신감저하/느긋'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ik_list[162]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPD8x6FW4vG0NXoXRHBJD8H",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1e8sLlhMCKkL6-4wvgqN6z1c0CeIA9H6M",
   "name": "Modeling.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
