{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcMAFxQpDavF"
   },
   "source": [
    "[코드]\n",
    "후기 데이터셋 이용하여 KOBERT 모델 학습하고, 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q3vHY0gPzmRk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/ubuntu/chatbot/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 6394,
     "status": "ok",
     "timestamp": 1658406087829,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "1rpgi-tez-p1",
    "outputId": "f7d94460-b4a2-48bf-834e-022375ac3a4e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>intent</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11122</td>\n",
       "      <td>초조함</td>\n",
       "      <td>내 미래를 생각하니까 너무 갑갑해</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3694</td>\n",
       "      <td>외로움</td>\n",
       "      <td>울적해지지 않으려고 해도 왜 이렇게 울적한지</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3391</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>볼때마다 안쓰럽고 슬프고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15876</td>\n",
       "      <td>자신감저하</td>\n",
       "      <td>내가 많이 위축된 거 같아</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2858</td>\n",
       "      <td>슬픔</td>\n",
       "      <td>유리병 깨서 손목 긋고 발로 밟고 피 흘리면서 오열을 했어</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12587</th>\n",
       "      <td>3786</td>\n",
       "      <td>외로움</td>\n",
       "      <td>임신 중 주말근무 때문에 이건 사람이 사는 게 아니다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12588</th>\n",
       "      <td>16917</td>\n",
       "      <td>자존감저하</td>\n",
       "      <td>유산했다고 시어머니가 죄인 취급을 하니까 자존감이 떨어지는것 같아</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12589</th>\n",
       "      <td>15507</td>\n",
       "      <td>죄책감</td>\n",
       "      <td>요즘 자소서 쓰는데 자소서만 봐도 후회만 돼요.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12590</th>\n",
       "      <td>12452</td>\n",
       "      <td>초조함</td>\n",
       "      <td>근데 의사 말 듣고 나니까 엄청 걱정이 돼요.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12591</th>\n",
       "      <td>17602</td>\n",
       "      <td>절망감</td>\n",
       "      <td>몸이 힘들어 죽겠는데 희망 같은게 있을 수가 없지</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12592 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id intent                               context  label\n",
       "0      11122    초조함                    내 미래를 생각하니까 너무 갑갑해     10\n",
       "1       3694    외로움              울적해지지 않으려고 해도 왜 이렇게 울적한지      2\n",
       "2       3391     슬픔                        볼때마다 안쓰럽고 슬프고.      1\n",
       "3      15876  자신감저하                        내가 많이 위축된 거 같아     14\n",
       "4       2858     슬픔      유리병 깨서 손목 긋고 발로 밟고 피 흘리면서 오열을 했어      1\n",
       "...      ...    ...                                   ...    ...\n",
       "12587   3786    외로움         임신 중 주말근무 때문에 이건 사람이 사는 게 아니다      2\n",
       "12588  16917  자존감저하  유산했다고 시어머니가 죄인 취급을 하니까 자존감이 떨어지는것 같아     15\n",
       "12589  15507    죄책감            요즘 자소서 쓰는데 자소서만 봐도 후회만 돼요.     12\n",
       "12590  12452    초조함             근데 의사 말 듣고 나니까 엄청 걱정이 돼요.     10\n",
       "12591  17602    절망감           몸이 힘들어 죽겠는데 희망 같은게 있을 수가 없지     16\n",
       "\n",
       "[12592 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_df = pd.read_csv(data_path + 'Wellness_Conversation_intent_train.tsv', sep='\\t')\n",
    "intent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['초조함',\n",
       " '외로움',\n",
       " '슬픔',\n",
       " '자신감저하',\n",
       " '불면',\n",
       " '죄책감',\n",
       " '자살충동',\n",
       " '절망감',\n",
       " '식욕저하',\n",
       " '분노',\n",
       " '불안',\n",
       " '피로',\n",
       " '우울감',\n",
       " '식욕증가',\n",
       " '무기력',\n",
       " '감정조절이상',\n",
       " '집중력저하',\n",
       " '자존감저하',\n",
       " '상실감']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_list = list(intent_df['intent'].unique())\n",
    "intent_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuXUR8Q8IS5r"
   },
   "source": [
    "##### KoBERT 실행환경 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CsO0M-QYILcx"
   },
   "outputs": [],
   "source": [
    "# !pip install ipywidgets  # for vscode\n",
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8Bvmi__2IW2j"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4AxBn9QEIyEn"
   },
   "outputs": [],
   "source": [
    "## CPU\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "## GPU\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9874,
     "status": "ok",
     "timestamp": 1658206216589,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "atw_Yw0eI06D",
    "outputId": "d19bfc1e-946c-4a06-ed94-ab43fd38f887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/ubuntu/chatbot/code/.cache/kobert_v1.zip\n",
      "using cached model. /home/ubuntu/chatbot/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")   # BERT 모델 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "m-NJe76gI2wa"
   },
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(data_path + 'Wellness_Conversation_intent_train.tsv', field_indices=[2, 3], num_discard_samples=1)\n",
    "dataset_val = nlp.data.TSVDataset(data_path + 'Wellness_Conversation_intent_val.tsv', field_indices=[2, 3], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(data_path + 'Wellness_Conversation_intent_test.tsv', field_indices=[2, 3], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1658206218898,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "iKGqtPfII_5E",
    "outputId": "9d6ebb38-411b-4d96-feb0-d3b4ca1b6cae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['급 기억력 감퇴 와서 진심 우울해', '0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1658206218899,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "oInKXZzVJC2L",
    "outputId": "365226dc-d1af-468a-eafd-f2f90d78e337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model. /home/ubuntu/chatbot/code/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()   # 토크나이저 선언 \n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)   # token 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<gluonnlp.data.dataset.TSVDataset at 0x7f2584d35dd0>, 12592)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train, len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IwWtCuebJHGf"
   },
   "outputs": [],
   "source": [
    "# BERT Dataset 클래스 생성 \n",
    "class BERTDataset(Dataset):   \n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bZu2NR_ZJJBC"
   },
   "outputs": [],
   "source": [
    "# 파라미터 설정 \n",
    "max_len = 64     # 토큰 최대 길이 \n",
    "batch_size = 64   # 배치 사이즈 \n",
    "warmup_ratio = 0.1   # 웜-업 비율 \n",
    "num_epochs = 50   # 학습 수  \n",
    "max_grad_norm = 1   # gradient 정규화 최대값 \n",
    "log_interval = 200   # interval 간격\n",
    "learning_rate =  5e-5   # 학습률 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12592, <gluonnlp.data.dataset.TSVDataset at 0x7f2584d35dd0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train), dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30682,
     "status": "ok",
     "timestamp": 1658206249576,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "FulvSDhqJKL9",
    "outputId": "93b17ae0-ee8c-49ef-f094-818521edcaca"
   },
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)   # 학습 데이터셋 생성 \n",
    "data_val = BERTDataset(dataset_val, 0, 1, tok, max_len, True, False)   # 테스트 데이터셋 생성 \n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)   # 테스트 데이터셋 생성 \n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "val_dataloader = torch.utils.data.DataLoader(data_val, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "w94JmcTJJOrn"
   },
   "outputs": [],
   "source": [
    "# BERT Classifier 클래스 생성 \n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=len(intent_list),\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()    # 부모 클래스 생성자 초기화 \n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)   # 선형 분류기 생성 \n",
    "        if dr_rate:   # 드랍아웃 \n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask \\\n",
    "                              = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        else:\n",
    "            out = pooler\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "9PnWcSn7JvDG"
   },
   "outputs": [],
   "source": [
    "# 사전훈련된 BERT 모델 생성 \n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1658206257129,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "xDStspWU6e8F",
    "outputId": "7df13e14-f81d-4158-875f-273d90beb88b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/chatbot/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]\n",
    "\n",
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)   # 웜업 스텝 설정 \n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "wWJRKEhz6jQo"
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    print('acc:',len(X), len(Y), type(X), type(Y))\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    print('acc2:',max_vals, max_indices)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PElGJOoi6l3Y"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b77967fb7a47de9ed7b2f36755db28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7062, 0.3558, 0.6850, 0.4952, 0.7771, 0.4983, 0.3735, 0.8425, 1.0121,\n",
      "        0.7469, 0.7519, 0.9367, 0.4704, 0.6444, 0.8843, 0.5882, 0.6098, 0.7130,\n",
      "        0.5456, 0.7461, 0.5212, 0.6441, 0.4825, 1.0779, 0.8180, 0.5735, 0.6924,\n",
      "        0.6954, 0.4959, 0.5019, 0.8568, 0.5977, 0.8542, 0.8003, 0.3846, 0.6607,\n",
      "        0.7931, 0.5042, 0.6516, 0.4025, 0.5832, 0.6037, 0.5970, 0.4757, 0.5076,\n",
      "        0.6437, 0.5191, 0.5123, 0.2997, 0.6320, 0.5854, 1.0656, 0.6752, 0.5884,\n",
      "        0.5386, 0.6615, 0.6409, 0.5671, 0.3653, 0.3295, 0.8494, 0.7370, 0.3740,\n",
      "        0.5774], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 3,  0,  8,  8,  8, 11, 13,  8,  8, 11,  8,  3, 10,  2,  8,  5, 11,  5,\n",
      "         8,  3,  3,  8,  8,  8, 16,  8,  3,  6, 18, 13,  0,  7,  8,  8, 12, 10,\n",
      "        12,  8,  8,  7, 18,  3,  6, 18, 12,  3, 18, 16,  8,  6, 18,  3, 10,  7,\n",
      "         8, 10,  3,  8, 11, 11,  8,  8,  8, 18], device='cuda:0')\n",
      "0\n",
      "epoch 1 batch id 1 loss 3.009756088256836 train acc 0.015625\n",
      "batch: 1\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.3494, 0.3676, 0.5431, 1.0589, 0.6842, 0.9133, 0.5621, 0.4044, 0.3805,\n",
      "        0.7832, 0.7110, 0.4671, 0.5353, 0.4866, 0.9944, 0.6911, 0.8578, 0.5219,\n",
      "        0.8141, 0.3647, 0.4972, 0.3506, 0.5929, 0.5042, 0.8762, 0.5885, 0.8845,\n",
      "        0.7194, 0.4264, 0.6816, 0.7826, 0.7307, 0.6923, 0.3656, 0.7226, 0.7433,\n",
      "        0.8733, 0.7413, 0.9789, 0.7317, 0.6236, 0.7909, 0.5195, 0.9411, 0.5605,\n",
      "        0.6132, 0.5356, 0.4920, 0.7940, 0.7449, 0.6394, 0.5295, 0.8258, 0.6519,\n",
      "        0.7216, 1.1195, 0.3083, 0.7551, 0.6976, 0.6569, 0.7721, 0.8117, 0.6708,\n",
      "        0.6833], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 1, 14, 18,  3,  8, 10, 12, 10,  8,  3,  8,  5,  8,  6, 18,  3,  3,  8,\n",
      "         8, 11,  2,  8,  8, 11,  0, 15, 18, 18, 17, 18,  5,  5, 18, 18,  8, 10,\n",
      "        18,  8,  3,  3, 18,  8,  8, 18,  1, 12,  7,  8, 10, 16, 18,  8, 18, 18,\n",
      "         8,  8,  1, 18,  8,  6,  3,  4,  8,  5], device='cuda:0')\n",
      "1\n",
      "batch: 2\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7072, 0.8286, 0.7526, 0.6488, 0.6326, 0.5388, 0.7328, 0.9181, 0.4494,\n",
      "        0.5211, 0.4414, 0.5850, 1.0303, 0.3727, 0.3252, 0.4742, 0.5264, 0.8581,\n",
      "        0.5774, 0.5234, 1.0202, 0.4020, 0.2133, 0.5500, 0.6871, 0.2104, 0.4809,\n",
      "        0.4504, 0.8633, 0.4053, 0.8877, 0.9295, 0.6458, 0.7620, 0.4709, 0.9605,\n",
      "        0.5300, 0.8798, 0.4773, 0.3737, 0.6005, 0.5588, 0.3914, 0.6544, 0.6406,\n",
      "        0.5336, 0.8269, 0.5952, 0.5774, 0.6754, 0.4887, 0.5952, 0.5497, 0.6009,\n",
      "        0.9589, 0.4654, 0.6149, 0.6977, 0.4290, 0.8515, 0.4173, 0.4622, 0.8677,\n",
      "        1.0614], device='cuda:0', grad_fn=<MaxBackward0>) tensor([18, 18, 18,  8, 18,  8, 18, 10,  5, 12,  8, 15, 16, 12, 17, 18,  3,  8,\n",
      "        18,  8, 16,  7, 16,  8,  8, 14, 15, 18,  3, 13,  3,  5,  8, 18,  0,  3,\n",
      "        11, 18, 10,  0,  3,  8,  5, 18, 14, 14,  8, 11,  5, 11,  1,  8,  6,  0,\n",
      "         8, 15,  5,  3, 18,  3,  8, 11,  8,  3], device='cuda:0')\n",
      "2\n",
      "batch: 3\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([1.0910, 0.6658, 0.6682, 0.5609, 0.6357, 0.6379, 0.4993, 0.4492, 0.7403,\n",
      "        0.7277, 0.7092, 0.5685, 0.4111, 0.4326, 0.5031, 0.6327, 0.5034, 0.6325,\n",
      "        0.6274, 0.5183, 0.8591, 0.5264, 0.6007, 0.6548, 0.7891, 0.3674, 0.4805,\n",
      "        0.5522, 0.4654, 0.7813, 0.7456, 0.5921, 0.6528, 0.8015, 0.4559, 0.8789,\n",
      "        0.7344, 0.7499, 0.4824, 0.3983, 0.7433, 0.2525, 0.6741, 0.3828, 0.5959,\n",
      "        0.5852, 0.7314, 0.6272, 0.8527, 0.7715, 0.4419, 0.6190, 0.4651, 0.8677,\n",
      "        0.8590, 0.4798, 0.4516, 0.7611, 0.6541, 0.4380, 0.6294, 0.6321, 1.1048,\n",
      "        0.4747], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 3,  6, 11, 15,  3, 15,  8, 11,  0, 10,  3,  8,  1,  8,  8, 18,  8, 10,\n",
      "        10,  6, 10, 18, 14, 18, 10,  7,  5, 18, 16,  5,  0,  8,  8, 10, 16,  3,\n",
      "         0, 16,  7,  3,  3, 12, 13,  5, 10, 15,  3,  4, 10,  3,  8, 10, 14,  0,\n",
      "        18, 10,  8,  8, 18,  0,  8,  5, 10, 15], device='cuda:0')\n",
      "3\n",
      "batch: 4\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.6114, 0.7401, 0.5962, 0.5094, 0.5947, 0.6998, 0.4246, 0.7905, 0.7699,\n",
      "        0.5219, 0.5167, 0.3956, 0.3336, 0.8173, 0.5965, 0.7305, 0.7751, 0.8379,\n",
      "        0.6580, 0.6504, 0.5664, 0.7790, 0.7236, 0.7596, 0.9411, 0.8536, 0.4343,\n",
      "        0.5636, 0.3855, 1.0992, 1.0693, 0.6970, 0.4983, 0.5539, 0.4458, 0.6227,\n",
      "        0.3701, 0.8618, 0.6303, 0.3628, 0.7713, 0.9818, 0.8487, 0.4683, 0.5397,\n",
      "        0.7402, 0.5438, 0.7160, 0.7125, 0.5491, 0.8743, 0.7707, 0.5671, 0.8329,\n",
      "        0.4042, 0.4747, 0.9465, 0.8998, 0.8733, 0.9710, 0.6621, 0.4411, 0.6629,\n",
      "        0.7210], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 5, 18,  3,  9,  8,  3,  0,  8, 10, 11,  3, 13, 12, 12,  6,  3,  6,  8,\n",
      "         8, 16, 18,  8,  3, 18, 13,  8, 11, 12, 18, 18,  3,  8,  5, 15, 18, 10,\n",
      "        13,  3, 10, 10,  3, 12, 12, 13,  4,  8, 10, 12,  1, 12, 10, 18, 18, 15,\n",
      "         0,  7, 13, 10,  8,  8, 12, 10,  6,  3], device='cuda:0')\n",
      "4\n",
      "batch: 5\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7300, 1.0449, 0.4497, 1.0226, 0.5937, 0.6394, 0.2723, 0.7835, 0.3851,\n",
      "        0.6855, 0.9159, 0.3549, 0.7271, 0.9022, 0.3530, 0.5322, 0.5313, 0.5631,\n",
      "        0.5542, 1.0631, 0.8440, 0.6203, 0.6014, 0.7158, 0.9683, 0.5273, 0.7441,\n",
      "        0.5488, 0.5772, 0.8076, 0.5258, 0.4391, 0.5590, 0.5527, 0.5054, 0.3503,\n",
      "        0.7242, 0.4672, 0.5640, 0.8665, 0.8566, 0.9777, 0.3431, 0.7308, 0.5338,\n",
      "        0.9970, 0.9046, 0.5248, 0.5470, 0.3720, 0.6333, 0.6723, 0.8223, 0.9825,\n",
      "        0.4101, 0.7070, 0.8261, 0.3293, 0.9563, 0.9600, 0.7419, 0.9885, 0.7520,\n",
      "        0.8708], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 8,  6,  3, 10,  2, 12,  8, 10,  8, 10, 18,  9,  0,  5, 18,  8,  8, 13,\n",
      "         3, 18,  3, 12,  5,  3,  8, 13, 18,  8,  8,  6,  8, 10,  3, 12,  8, 13,\n",
      "        10, 18,  8, 18,  3,  5,  7,  8, 14, 18,  3, 13, 10,  8,  5,  4,  3, 10,\n",
      "         7,  3, 16, 14, 10,  3,  5, 18, 12, 10], device='cuda:0')\n",
      "5\n",
      "batch: 6\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7363, 0.3651, 0.5156, 0.3748, 0.7466, 0.5759, 0.8290, 0.4871, 0.3339,\n",
      "        0.2603, 0.4321, 0.5944, 0.9326, 0.6778, 0.8079, 0.6001, 0.6459, 0.4801,\n",
      "        0.7678, 0.3966, 0.5860, 0.5038, 0.4509, 0.6229, 0.8431, 0.6329, 1.5083,\n",
      "        0.6938, 1.0751, 0.5204, 0.4936, 0.4402, 0.7983, 0.5834, 0.5895, 0.7514,\n",
      "        0.7302, 0.3770, 0.3252, 0.2093, 0.6220, 0.3569, 0.8504, 0.4649, 0.5886,\n",
      "        0.3564, 0.6078, 0.3486, 0.9214, 0.4860, 0.4376, 0.9251, 0.6570, 0.8946,\n",
      "        0.3892, 0.4950, 0.7853, 0.4943, 0.9083, 0.8620, 0.5277, 0.5611, 0.7210,\n",
      "        0.6719], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 8, 11, 15, 18,  8, 18, 18, 18, 12,  0,  8,  8,  3,  3,  8,  5, 14,  8,\n",
      "         3, 12,  6,  7,  7,  3,  3,  8, 10, 12,  3, 15, 16,  6,  5, 18, 12, 10,\n",
      "        12,  8, 18, 11,  5,  3, 12,  8,  8,  8, 13, 18,  8, 15,  3,  8,  8, 13,\n",
      "        11,  6,  8,  3,  3,  3,  8,  5,  6, 16], device='cuda:0')\n",
      "6\n",
      "batch: 7\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7093, 0.5869, 1.0531, 0.3882, 0.8049, 0.7393, 0.3120, 0.5843, 0.6736,\n",
      "        0.6709, 0.7900, 0.7699, 0.5609, 0.6051, 0.6229, 0.7845, 0.4766, 0.4427,\n",
      "        0.7301, 0.5523, 0.8228, 0.5940, 0.4875, 0.9895, 0.3517, 0.4439, 0.9567,\n",
      "        0.2565, 0.7484, 0.8916, 0.8947, 0.7089, 0.4982, 0.4912, 0.7801, 0.7896,\n",
      "        0.5884, 0.6644, 0.7761, 0.5809, 0.5233, 0.2174, 0.7433, 0.6106, 0.8438,\n",
      "        0.6556, 0.3116, 0.5969, 0.7106, 0.9916, 0.2772, 0.4362, 0.5991, 0.6019,\n",
      "        0.5676, 0.1021, 0.7865, 0.2771, 0.3980, 0.8942, 0.4934, 0.7737, 0.8658,\n",
      "        0.7645], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 8,  8,  3,  8,  3,  8, 13,  8,  8, 16, 18,  7, 18,  8, 16, 15,  3,  7,\n",
      "         8, 10,  3,  8,  8, 15, 11,  5,  8,  4,  3,  3,  3,  8, 11, 13,  3,  3,\n",
      "        12,  2,  0,  8, 18, 12,  3, 16,  6, 18, 14, 18,  8,  3, 11,  3,  0, 10,\n",
      "        10,  8, 12,  8, 13,  5,  8, 18, 13,  6], device='cuda:0')\n",
      "7\n",
      "batch: 8\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7640, 0.5501, 0.4220, 0.7541, 0.5374, 0.5446, 1.0067, 0.6810, 0.5223,\n",
      "        0.7130, 0.6770, 0.8218, 0.8485, 0.7929, 0.7666, 0.6392, 0.4583, 0.5122,\n",
      "        0.4800, 0.4268, 0.8450, 0.8234, 0.7747, 0.4839, 0.9375, 0.6750, 0.5365,\n",
      "        0.8713, 1.0515, 0.5940, 0.3941, 0.4369, 0.6597, 0.8507, 0.7176, 0.7233,\n",
      "        0.7484, 0.7608, 0.9690, 0.7570, 0.6217, 0.3147, 0.6833, 0.5357, 0.5978,\n",
      "        0.6038, 0.7101, 0.3751, 0.4848, 0.6429, 0.6762, 0.4168, 0.3129, 0.6586,\n",
      "        0.7585, 0.6627, 0.5745, 0.7541, 0.6221, 0.4924, 0.2982, 0.4525, 1.0077,\n",
      "        0.5267], device='cuda:0', grad_fn=<MaxBackward0>) tensor([13,  8,  5,  8, 10, 12,  3, 12,  8,  6,  5,  6, 18,  5,  8,  3,  6, 10,\n",
      "        11, 16,  3, 18, 18,  6,  8,  8,  5,  5, 13,  3,  8,  3,  6, 10, 16,  3,\n",
      "         6,  7,  8,  8,  0,  0, 16, 11,  2, 10,  8,  4, 18, 10, 15, 18,  0, 18,\n",
      "         3, 12,  5,  8, 18,  6, 15,  8,  3, 10], device='cuda:0')\n",
      "8\n",
      "batch: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([1.0494, 0.8683, 0.3024, 0.8101, 0.4454, 0.3696, 0.7055, 0.6389, 0.7827,\n",
      "        0.8210, 0.5814, 0.7477, 1.2187, 0.5231, 0.8580, 0.7054, 0.4962, 0.7506,\n",
      "        0.6125, 0.7227, 0.5418, 1.0342, 0.7278, 1.0053, 0.8127, 0.4169, 0.6654,\n",
      "        0.7065, 0.4500, 0.8896, 0.4835, 0.7187, 0.7801, 0.6602, 0.6961, 0.7891,\n",
      "        0.6083, 1.1516, 0.5097, 0.8731, 0.5641, 0.6569, 0.4195, 0.6662, 0.3870,\n",
      "        0.4197, 0.7752, 0.6617, 0.5517, 0.6995, 0.7227, 0.6867, 0.4310, 0.3761,\n",
      "        0.5029, 0.5780, 0.9070, 0.8700, 0.3836, 0.3816, 0.5838, 1.0213, 0.7984,\n",
      "        0.8256], device='cuda:0', grad_fn=<MaxBackward0>) tensor([10,  3,  7,  1,  8,  8,  8, 10, 10,  3, 18, 18,  3,  5,  5,  6,  5, 10,\n",
      "        18,  0, 13,  8, 12,  5,  8, 18, 18,  3, 11,  8,  6, 18,  3,  3,  3, 10,\n",
      "        13, 15, 12, 16,  8, 16, 13,  3,  8,  0, 12,  2,  8, 12,  1,  6, 11,  8,\n",
      "         6,  8,  3, 18,  6, 11,  3,  8, 10,  8], device='cuda:0')\n",
      "9\n",
      "batch: 10\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.8148, 0.3841, 0.5230, 0.4795, 0.4239, 0.7780, 0.6179, 0.3812, 0.8234,\n",
      "        0.5458, 0.3608, 0.7027, 0.5723, 0.7767, 0.5828, 0.2448, 0.4482, 0.5741,\n",
      "        0.8020, 0.3628, 0.4024, 0.3767, 0.5320, 0.5439, 0.8101, 0.6387, 0.7989,\n",
      "        0.8052, 0.4671, 0.6126, 0.3295, 0.7685, 0.5824, 0.1847, 0.3607, 0.5654,\n",
      "        0.3514, 0.4422, 0.6448, 0.6852, 0.6336, 0.5482, 0.4812, 0.4603, 0.5373,\n",
      "        0.5718, 0.6089, 0.7479, 0.7124, 0.5753, 0.7189, 0.7934, 0.5299, 0.7387,\n",
      "        0.6664, 0.6654, 0.6330, 0.7367, 0.6168, 0.5439, 0.3404, 1.0490, 0.5974,\n",
      "        0.5436], device='cuda:0', grad_fn=<MaxBackward0>) tensor([18, 16, 14,  8, 14,  5,  0,  0, 10,  5,  1, 18,  1, 18,  0, 11,  8, 18,\n",
      "         3, 11,  3, 10,  8,  0,  8,  5, 12, 12,  7,  1,  9,  8,  8, 14,  8,  8,\n",
      "         8, 18, 16,  8,  3,  8,  4,  0, 11,  3, 18,  8,  3, 12,  3, 18,  3,  6,\n",
      "        18,  5,  8,  3,  3, 18, 11,  3, 18,  3], device='cuda:0')\n",
      "10\n",
      "batch: 11\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.9647, 0.5130, 0.6680, 1.0603, 0.4385, 0.7482, 0.3600, 0.4243, 0.9031,\n",
      "        0.7025, 0.4867, 0.7942, 0.7670, 0.7328, 0.4101, 0.5019, 0.8374, 0.4985,\n",
      "        0.6547, 0.5281, 0.6137, 0.6809, 0.5060, 0.4907, 0.6513, 1.0766, 0.5644,\n",
      "        0.8136, 0.6811, 0.5885, 0.4800, 0.6211, 0.5778, 0.5820, 0.7465, 0.4836,\n",
      "        0.6658, 0.6780, 0.4181, 0.4997, 0.6554, 0.7786, 0.4161, 0.2817, 1.0796,\n",
      "        0.4564, 0.5970, 0.8156, 0.3041, 1.2136, 0.6830, 0.6207, 0.6042, 0.6312,\n",
      "        0.2116, 0.5714, 0.7431, 0.7124, 0.6994, 0.3313, 0.6079, 0.8251, 0.8659,\n",
      "        1.0472], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 8, 10,  3, 18, 18, 18, 12, 18,  3,  3, 18, 16, 13, 18,  3,  8,  8,  1,\n",
      "        18, 11,  5,  8, 12,  1, 13,  3,  8,  3, 18,  8, 18, 18,  9, 12,  3, 18,\n",
      "         0,  6,  7, 18, 10, 18, 18,  8, 18,  3,  8,  8, 18, 12,  5, 18,  6, 18,\n",
      "        10,  0, 18, 10,  8,  8, 18, 14, 18,  3], device='cuda:0')\n",
      "11\n",
      "batch: 12\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([1.0115, 0.7401, 0.2802, 0.9031, 0.6633, 0.5442, 0.6317, 0.5898, 0.7500,\n",
      "        1.0169, 0.6480, 0.3271, 0.6054, 0.2365, 0.7791, 0.3073, 0.9579, 0.7779,\n",
      "        0.3659, 0.6397, 0.6014, 0.3779, 0.5137, 0.4748, 0.6889, 0.5175, 0.4845,\n",
      "        0.3135, 0.5129, 0.5350, 0.5369, 0.5189, 0.5618, 0.6316, 0.6767, 0.5352,\n",
      "        0.6235, 0.6069, 0.3750, 0.7598, 0.4500, 0.5383, 0.5342, 0.8297, 0.3309,\n",
      "        0.4485, 1.1032, 0.5298, 0.5439, 0.6677, 0.6861, 0.5066, 0.8633, 0.7176,\n",
      "        1.0644, 1.0540, 0.7873, 0.6058, 0.4981, 0.3853, 0.4949, 0.8474, 0.8496,\n",
      "        0.4694], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 3, 18, 14,  8, 18, 16, 15, 10,  4,  8, 12,  8, 14, 18,  8,  7,  8, 15,\n",
      "         4,  3, 16, 16, 10, 18, 18,  5, 10,  0, 11, 12,  3,  0,  5, 16, 18,  8,\n",
      "         6, 18, 11, 13, 16,  3, 14,  4, 17,  5,  3, 18,  3, 18, 10, 18, 16,  8,\n",
      "         3,  3, 16, 16, 16, 14, 13, 18,  3,  4], device='cuda:0')\n",
      "12\n",
      "batch: 13\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.6992, 0.3870, 0.3436, 0.7915, 0.6845, 0.6054, 0.2589, 0.6861, 0.4440,\n",
      "        0.7786, 0.6014, 0.7931, 0.4124, 1.3012, 0.5340, 0.8725, 0.6044, 0.7411,\n",
      "        0.4608, 0.5535, 0.5668, 0.4105, 0.6589, 0.6938, 0.3442, 0.5441, 0.3655,\n",
      "        0.9199, 0.6221, 0.6260, 0.4960, 0.7105, 0.5604, 0.7828, 0.5456, 0.8043,\n",
      "        0.7265, 0.8504, 0.7782, 0.4632, 0.3462, 0.7459, 0.6595, 1.1815, 0.5324,\n",
      "        1.0191, 0.5076, 0.6506, 0.5185, 0.6141, 0.8127, 0.3710, 0.5400, 0.9483,\n",
      "        0.3720, 0.6836, 0.6660, 0.5982, 0.5999, 0.7314, 0.5571, 0.7077, 0.7635,\n",
      "        0.9457], device='cuda:0', grad_fn=<MaxBackward0>) tensor([10,  7, 15,  3, 18,  0, 10,  3, 16, 10,  8,  8, 16,  3, 18, 18,  3, 16,\n",
      "        18, 12, 10,  5, 18, 10,  7,  8, 11, 18, 18, 15,  7, 10, 16, 12,  3, 15,\n",
      "         3, 12,  1, 11, 18, 18,  8,  3, 13,  8,  8, 18,  3, 10,  3, 18, 18,  3,\n",
      "        10, 18, 16, 11,  1, 11, 18,  3,  8, 15], device='cuda:0')\n",
      "13\n",
      "batch: 14\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([1.1017, 0.2649, 0.5740, 0.9533, 0.5260, 0.7855, 0.6416, 0.4450, 0.5277,\n",
      "        0.7826, 0.6619, 0.6520, 0.8286, 0.4084, 0.5440, 0.5250, 0.5588, 0.7334,\n",
      "        0.5065, 0.6497, 0.4728, 0.7341, 0.5621, 0.7571, 0.6270, 0.3587, 0.7876,\n",
      "        0.3551, 0.3178, 0.5142, 0.4460, 0.4461, 0.5578, 1.1998, 0.7115, 0.3419,\n",
      "        0.7887, 0.7385, 0.5614, 0.6279, 0.2852, 0.7811, 0.6201, 0.6739, 0.3803,\n",
      "        0.3997, 0.3270, 0.5604, 0.8287, 0.5140, 0.7521, 0.8053, 0.3812, 0.5408,\n",
      "        0.7196, 0.8015, 0.3802, 0.5705, 0.6549, 0.7262, 0.6444, 0.8257, 0.2506,\n",
      "        1.0164], device='cuda:0', grad_fn=<MaxBackward0>) tensor([12,  7, 13,  3, 15, 12,  8, 17, 10,  3, 18, 18,  3, 11, 11,  8, 12, 10,\n",
      "         8,  8, 11,  8,  6,  8,  2, 15, 11,  0,  8, 12,  8, 18, 16,  7, 18,  1,\n",
      "        18,  3,  5,  5, 11, 10,  5,  5,  1,  7, 11,  3, 18,  1, 18,  8, 10, 18,\n",
      "        13, 10,  1,  3, 18,  3, 11,  3,  1,  8], device='cuda:0')\n",
      "14\n",
      "batch: 15\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.6623, 0.9476, 0.5761, 0.2756, 0.7570, 0.6020, 0.5681, 0.5187, 0.6403,\n",
      "        0.6886, 0.4596, 0.5496, 0.6968, 0.8257, 0.6880, 0.6877, 0.6012, 0.3199,\n",
      "        0.5831, 0.6418, 1.0304, 0.5828, 0.6402, 0.4638, 0.4789, 0.7846, 1.0470,\n",
      "        0.6882, 0.6360, 0.4926, 0.2777, 0.8141, 0.6082, 0.6263, 0.6543, 0.4399,\n",
      "        0.6335, 0.6450, 0.7220, 0.4221, 0.5973, 0.8558, 0.8611, 0.4080, 0.3404,\n",
      "        0.9140, 0.6240, 0.8701, 0.5700, 0.7897, 0.5619, 0.6862, 0.6697, 0.6840,\n",
      "        0.4767, 0.5241, 0.7129, 0.4995, 0.6345, 0.3385, 0.4350, 0.8900, 0.2277,\n",
      "        0.8125], device='cuda:0', grad_fn=<MaxBackward0>) tensor([18,  3,  1,  7,  8, 18,  6,  8, 18,  8,  3,  3,  8, 18, 10,  8, 18, 17,\n",
      "         8,  8,  3,  3, 10, 10, 16, 12, 10,  0, 18, 18,  8,  8, 16,  7, 14,  8,\n",
      "        18,  8, 18, 16, 18,  8, 10,  7,  9,  3,  8,  3,  5, 12,  8, 18, 13, 15,\n",
      "         5,  1,  3,  8, 15, 15,  8,  8, 11, 15], device='cuda:0')\n",
      "15\n",
      "batch: 16\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7154, 0.4530, 0.8330, 0.3890, 0.7008, 0.6694, 0.7188, 0.7119, 0.7203,\n",
      "        0.7974, 0.4510, 0.5454, 0.5451, 0.7500, 0.7301, 0.7792, 0.9170, 0.8472,\n",
      "        0.5198, 0.3584, 0.6626, 1.0064, 0.6532, 0.5409, 0.7308, 0.6796, 0.3192,\n",
      "        0.6818, 0.6656, 0.8246, 0.8432, 0.6550, 0.4678, 0.7297, 0.3859, 0.4407,\n",
      "        0.7111, 0.5822, 0.4344, 0.4116, 0.8101, 0.7612, 0.5879, 0.4213, 0.6110,\n",
      "        0.3134, 0.5372, 0.5254, 0.5131, 0.3517, 0.8484, 0.3954, 0.7274, 0.4757,\n",
      "        0.8173, 0.6227, 0.6046, 0.7616, 0.6838, 0.7788, 0.4839, 1.5201, 0.7817,\n",
      "        0.6319], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 3,  8,  3,  7,  3,  8, 12,  3,  3,  8, 11,  7, 15,  8, 10, 18, 18,  3,\n",
      "        11,  7,  8,  5,  8, 16, 18, 15,  5,  8,  3, 10,  8, 15,  3,  3, 11,  8,\n",
      "        18,  5,  5,  8, 18,  6,  0,  8, 16, 11, 10, 16, 18,  6,  5, 10,  5, 12,\n",
      "        13,  8,  4,  8,  8, 18,  3,  3, 14, 18], device='cuda:0')\n",
      "16\n",
      "batch: 17\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.6949, 1.0405, 1.0099, 0.7093, 0.4871, 0.7977, 0.6352, 0.6800, 0.8332,\n",
      "        0.7239, 0.7320, 0.6961, 0.8895, 0.6507, 0.5966, 0.3164, 0.6432, 0.5523,\n",
      "        0.3219, 0.5573, 0.7028, 0.8116, 0.8501, 0.8107, 0.5697, 0.5585, 0.8680,\n",
      "        0.8722, 0.6568, 0.6895, 0.7197, 0.5687, 0.6726, 0.6099, 0.7447, 0.5873,\n",
      "        0.7236, 0.4589, 0.2948, 0.5309, 0.8909, 0.7217, 0.7369, 0.2071, 0.6301,\n",
      "        0.4419, 0.4231, 0.8219, 0.3048, 0.7651, 0.4926, 0.4274, 0.6859, 0.4612,\n",
      "        0.7593, 0.8840, 0.6193, 0.6505, 0.8058, 0.5219, 0.3372, 0.3667, 0.4956,\n",
      "        0.6339], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 8,  5,  3, 10, 18,  8, 15,  8,  3, 12,  8, 12, 12,  5, 12, 13, 18, 18,\n",
      "        12,  5,  8, 18, 18,  3, 18,  6,  1, 12,  8,  2, 18,  0,  8, 18, 10,  5,\n",
      "         8,  8, 11,  8, 10, 18,  3,  0,  5,  1, 18,  3,  5,  3,  7,  8,  5,  8,\n",
      "         8,  3,  6, 10, 10,  7, 10, 10,  1,  3], device='cuda:0')\n",
      "17\n",
      "batch: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7322, 0.9194, 0.8524, 0.4687, 0.8424, 0.3836, 0.6630, 0.7753, 0.8811,\n",
      "        0.5987, 0.3697, 0.5369, 0.4676, 0.4784, 0.7935, 0.6532, 0.9770, 0.6028,\n",
      "        0.7261, 0.7883, 1.0548, 0.5325, 0.5836, 0.6904, 0.4845, 1.0470, 0.4183,\n",
      "        0.5611, 0.3362, 0.3379, 1.1443, 0.6676, 0.3445, 0.4531, 0.6480, 0.7324,\n",
      "        0.5979, 0.6077, 0.7757, 0.4047, 0.6073, 0.3974, 0.6754, 0.8163, 0.5240,\n",
      "        0.5099, 0.7624, 0.4008, 0.3734, 0.4258, 0.6860, 0.6712, 0.5419, 0.8374,\n",
      "        0.9080, 0.6670, 0.6842, 0.6360, 0.5184, 0.4975, 0.6906, 0.5034, 0.8149,\n",
      "        0.6488], device='cuda:0', grad_fn=<MaxBackward0>) tensor([18,  3,  0,  3,  8, 18,  8,  8, 15, 12, 12,  2, 17, 15,  0, 18,  3, 18,\n",
      "        18,  4,  3,  3, 16,  3,  3, 12, 16,  8,  7, 11,  3,  8,  6,  6, 12,  3,\n",
      "         4, 10,  3,  8,  5, 18,  8, 13,  2,  8,  3,  6, 18, 18,  3,  8, 15, 10,\n",
      "         6, 10,  6, 18,  5,  4, 18,  8,  8,  3], device='cuda:0')\n",
      "18\n",
      "batch: 19\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.4244, 0.5578, 0.4239, 0.6061, 0.7970, 0.3929, 0.4542, 0.5644, 0.9008,\n",
      "        0.9546, 0.6948, 0.4677, 0.8315, 0.7290, 1.1000, 0.6880, 0.5360, 0.4434,\n",
      "        0.6348, 0.7012, 0.9933, 0.4260, 0.6850, 0.3312, 0.8207, 0.5302, 0.3051,\n",
      "        0.8939, 0.8426, 0.4587, 0.4930, 0.5620, 0.5415, 0.5603, 0.6950, 0.3813,\n",
      "        0.9022, 0.2966, 0.9328, 0.8347, 0.5577, 0.6279, 0.8471, 0.7168, 0.9132,\n",
      "        0.7247, 0.2703, 0.8274, 0.6759, 0.3645, 0.4623, 0.7580, 0.8577, 0.2499,\n",
      "        0.4382, 0.6856, 0.3384, 0.2446, 0.3743, 0.7847, 0.8307, 0.6677, 1.1346,\n",
      "        0.7388], device='cuda:0', grad_fn=<MaxBackward0>) tensor([10, 18, 12, 10,  1, 16, 18,  6,  3, 10, 18, 18, 18, 18,  3, 10,  8, 11,\n",
      "         5, 18,  8, 10,  3,  8,  3,  3, 18,  8,  3,  8, 18,  5, 18,  5,  8, 11,\n",
      "         3, 18, 12, 18,  7,  5, 18,  3,  8, 18,  8, 10, 18, 18,  8, 18,  6,  8,\n",
      "        13,  5,  7,  0, 13, 13, 16, 10, 10,  6], device='cuda:0')\n",
      "19\n",
      "batch: 20\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.5161, 0.7751, 0.5390, 0.4649, 0.4911, 0.3762, 1.0439, 0.8323, 0.3572,\n",
      "        0.6303, 0.8413, 0.4713, 0.6682, 0.4234, 0.9733, 0.6105, 0.3812, 0.6743,\n",
      "        0.5707, 0.5044, 0.8852, 0.6068, 0.3256, 0.8648, 1.2252, 0.4433, 0.6464,\n",
      "        0.5088, 0.8772, 0.4957, 0.4684, 0.6428, 0.6589, 0.7111, 0.5716, 1.0456,\n",
      "        0.5260, 1.1054, 0.5234, 0.6122, 0.6883, 0.8501, 0.3057, 0.9218, 0.8323,\n",
      "        0.8530, 0.7653, 0.5416, 0.7354, 0.5747, 0.3170, 0.5908, 0.5663, 0.2949,\n",
      "        0.7964, 0.7457, 0.6494, 1.1011, 0.5512, 1.1647, 0.8294, 0.5857, 0.9349,\n",
      "        0.5703], device='cuda:0', grad_fn=<MaxBackward0>) tensor([16,  7,  3, 10, 16,  6,  3, 18, 11, 18, 18,  6,  3, 15, 10,  4,  7,  3,\n",
      "        18,  8, 18,  8, 11,  6, 10, 18,  3,  8,  5, 18,  8, 18,  4,  8,  6,  8,\n",
      "         8, 10, 18,  3, 18, 16,  8,  4,  8, 10,  6, 16, 12,  8, 11,  8, 15, 10,\n",
      "        18,  3,  3,  3,  1,  8, 15,  3,  3,  3], device='cuda:0')\n",
      "20\n",
      "batch: 21\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.3949, 0.5208, 1.0554, 0.7980, 0.7719, 0.7784, 0.4713, 0.7102, 0.6978,\n",
      "        0.3723, 0.7618, 0.5232, 0.6935, 0.6397, 0.8063, 0.5119, 0.2678, 0.7378,\n",
      "        0.3664, 0.5146, 0.6306, 0.7547, 0.7696, 0.5895, 0.7223, 0.2850, 0.6272,\n",
      "        0.8320, 0.6007, 0.7118, 0.7706, 0.6244, 0.5546, 0.7046, 0.4440, 0.3487,\n",
      "        0.3701, 0.4665, 0.7435, 0.8156, 0.6705, 0.7889, 0.9750, 0.2110, 0.3570,\n",
      "        0.6681, 0.4881, 0.7551, 0.7644, 0.7329, 0.7379, 0.7571, 0.4696, 1.0254,\n",
      "        0.6919, 0.8232, 0.4294, 0.3814, 0.4367, 0.8133, 0.8057, 0.7031, 0.7400,\n",
      "        0.6951], device='cuda:0', grad_fn=<MaxBackward0>) tensor([16,  4,  3, 13, 18, 10,  8,  8,  8, 18,  3, 12,  5,  3, 10,  8,  5, 18,\n",
      "        11,  5,  0,  5, 10, 18,  8, 10, 18,  8, 18,  8, 10, 16, 18,  8,  3, 11,\n",
      "         5, 11,  8,  1, 10,  3, 18, 15, 10, 11, 18,  8,  3,  5, 18,  8, 16,  3,\n",
      "         8,  3,  0,  7,  8, 10, 15, 15,  5,  8], device='cuda:0')\n",
      "21\n",
      "batch: 22\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.4628, 0.5126, 0.5585, 0.9798, 0.5634, 0.6581, 0.8133, 0.3546, 0.9805,\n",
      "        0.5368, 0.6060, 0.7393, 0.8931, 0.6158, 0.5933, 0.4067, 0.6285, 0.6745,\n",
      "        0.7193, 0.4824, 0.7176, 0.8203, 1.1006, 1.0132, 0.4562, 0.8821, 0.5655,\n",
      "        0.8764, 0.5013, 0.6799, 0.5268, 0.4600, 0.5542, 0.3617, 0.5713, 0.5144,\n",
      "        0.3636, 0.7571, 1.0640, 0.6871, 0.5267, 1.1192, 0.9027, 0.6566, 0.6686,\n",
      "        0.6045, 0.3731, 0.5704, 0.7561, 0.5028, 0.5482, 0.5802, 0.3564, 0.6800,\n",
      "        0.8200, 0.7799, 0.7952, 0.8270, 0.5397, 0.3942, 0.9664, 0.5678, 0.5790,\n",
      "        0.4294], device='cuda:0', grad_fn=<MaxBackward0>) tensor([18, 18,  8,  1, 18,  3,  5, 11,  3, 14,  3,  0,  8,  8,  8, 15, 15,  8,\n",
      "         3,  5, 15, 18,  3,  3,  8,  3,  8,  8, 13,  3,  8,  6,  8,  7, 18, 14,\n",
      "         7, 12, 18,  3,  6,  3,  3,  8,  9,  7,  9, 11,  5,  3, 10, 18,  8, 18,\n",
      "         4,  0, 10, 10, 18,  8, 12, 18,  5,  7], device='cuda:0')\n",
      "22\n",
      "batch: 23\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.5045, 0.7582, 0.9678, 0.6227, 0.9494, 0.6746, 0.6521, 0.6293, 0.7728,\n",
      "        0.5938, 0.3396, 0.4823, 0.2370, 0.5071, 0.8738, 0.5095, 0.4418, 0.8300,\n",
      "        0.5575, 0.6332, 0.5989, 0.9073, 0.5341, 0.4399, 0.6891, 0.6247, 0.9348,\n",
      "        0.9232, 0.5082, 0.5580, 0.7097, 0.7468, 0.5676, 0.5268, 0.5032, 0.6226,\n",
      "        0.8065, 0.9077, 0.9049, 0.7312, 0.2322, 0.6609, 0.8116, 0.8524, 0.9534,\n",
      "        0.3197, 0.7476, 0.4593, 0.3482, 0.7822, 0.6639, 0.7488, 0.3777, 0.6571,\n",
      "        0.8320, 0.5638, 0.9616, 0.9759, 0.3298, 0.7652, 0.4960, 0.6866, 1.1953,\n",
      "        0.9012], device='cuda:0', grad_fn=<MaxBackward0>) tensor([18,  8,  5, 18, 10,  5,  8, 18, 10,  5,  9, 18, 11,  5,  3, 11, 10,  3,\n",
      "         0, 18, 16,  8, 18, 10, 18,  3,  8, 10,  6, 12, 18, 18, 11,  8,  4,  8,\n",
      "         3, 18, 10,  3, 18,  5, 18,  5,  8,  8, 14,  7, 13,  3, 18,  3, 14, 18,\n",
      "        18, 11,  8,  3, 10, 18,  3,  3,  3, 18], device='cuda:0')\n",
      "23\n",
      "batch: 24\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.5093, 0.6080, 0.4167, 0.6497, 0.6099, 0.6311, 0.4396, 0.4972, 1.0095,\n",
      "        0.3888, 0.5290, 0.5251, 0.5360, 0.5945, 0.2967, 0.4549, 0.8308, 0.6284,\n",
      "        0.4786, 0.6383, 0.5148, 0.5303, 0.3712, 0.5951, 0.6155, 0.6295, 0.5879,\n",
      "        0.8248, 0.6003, 0.8485, 0.3700, 0.8536, 0.1903, 0.8654, 0.9738, 0.6564,\n",
      "        0.6402, 0.4833, 0.5916, 0.9208, 0.6781, 0.8201, 1.3049, 0.6570, 0.5209,\n",
      "        0.4469, 0.3854, 0.8601, 0.6376, 0.3578, 1.1671, 0.6137, 1.1109, 0.7012,\n",
      "        0.8227, 0.6811, 0.3864, 0.8216, 0.8786, 0.7379, 0.5170, 0.6589, 0.6979,\n",
      "        0.7815], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 6, 10,  0, 12,  8, 18,  2,  8, 10, 10,  8,  8, 10, 18,  8, 16, 10,  0,\n",
      "         1, 18, 10,  3, 15, 18,  8, 10,  8, 10, 10, 10, 14,  5, 18, 18, 18,  3,\n",
      "        18,  6,  8,  8,  5,  8,  3, 18,  8, 13, 13,  3,  8, 18,  3,  3,  8,  0,\n",
      "        15, 10, 16, 18,  8,  8,  3,  6,  5, 18], device='cuda:0')\n",
      "24\n",
      "batch: 25\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.6535, 0.7208, 0.6971, 1.0364, 1.0383, 0.5575, 0.6258, 0.8917, 0.4134,\n",
      "        0.6362, 0.6292, 0.7720, 0.5912, 0.5118, 0.6651, 0.8169, 0.5611, 0.8364,\n",
      "        0.4213, 0.8167, 0.7616, 0.8730, 1.1187, 0.8710, 0.5604, 0.9754, 0.7504,\n",
      "        0.6184, 0.7900, 0.5046, 0.8685, 0.4694, 0.3333, 0.7353, 1.0112, 0.8151,\n",
      "        0.7888, 0.4442, 0.6492, 0.4100, 0.6309, 0.8078, 0.8541, 0.3991, 0.3919,\n",
      "        0.8949, 0.3762, 0.7190, 0.7873, 0.5402, 0.5003, 0.5147, 0.6322, 0.4870,\n",
      "        0.7510, 0.6198, 1.0435, 0.5134, 0.8326, 0.7397, 0.6585, 0.8564, 0.5794,\n",
      "        0.8275], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 3, 16,  8, 10, 11, 10,  8, 12, 10, 18,  2,  3,  3,  8,  8,  3,  8,  3,\n",
      "         0, 10,  6,  3,  3,  6,  3,  6,  3,  8, 12,  6,  8,  8,  2,  3, 18, 18,\n",
      "        10,  5, 10,  3,  7,  8, 16, 12,  0,  3, 18,  3, 16,  8,  8, 13, 18, 11,\n",
      "         3,  3,  5, 18, 10,  3,  8, 18, 18,  8], device='cuda:0')\n",
      "25\n",
      "batch: 26\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.5882, 0.5270, 0.5597, 0.5748, 0.5615, 0.8123, 0.9919, 0.5540, 0.8698,\n",
      "        0.5599, 0.7522, 1.1161, 0.7698, 0.3707, 0.5922, 0.4254, 0.5318, 0.5604,\n",
      "        0.7452, 0.4909, 0.5166, 0.6347, 0.4832, 0.4265, 0.6673, 0.4484, 0.5900,\n",
      "        0.6064, 0.5488, 0.5572, 0.6221, 0.6933, 0.5353, 0.8460, 0.6737, 0.2282,\n",
      "        0.6851, 0.4497, 1.0137, 0.8131, 0.8789, 0.5475, 0.4137, 0.6169, 0.8140,\n",
      "        0.5024, 0.4895, 0.4814, 0.8262, 0.7425, 0.8919, 0.8939, 0.6484, 0.4639,\n",
      "        0.6057, 0.6100, 0.9411, 0.5265, 0.6800, 0.7136, 0.6244, 0.7350, 0.7054,\n",
      "        0.6664], device='cuda:0', grad_fn=<MaxBackward0>) tensor([10,  5, 16,  8,  8,  3,  3,  3,  3,  5, 10,  3, 15,  6, 18, 18, 18,  8,\n",
      "        10,  3,  8,  5, 11,  3, 18, 18, 18, 15, 18,  6,  3,  8, 15, 18, 10,  1,\n",
      "        18,  8,  3,  8, 10, 18, 13,  8,  5, 11,  8, 11,  5, 10, 18,  8, 14,  5,\n",
      "         5,  8,  3,  3,  8,  3, 18, 18, 10,  8], device='cuda:0')\n",
      "26\n",
      "batch: 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.5438, 0.6118, 0.3242, 0.6356, 0.6075, 0.3657, 0.5667, 0.8426, 0.5967,\n",
      "        0.6809, 0.8243, 0.6638, 0.5408, 0.9854, 0.6155, 0.8010, 0.8352, 0.4312,\n",
      "        0.5112, 0.4418, 0.7764, 0.7094, 0.7592, 0.4344, 0.5144, 0.4298, 0.7863,\n",
      "        0.7011, 0.4972, 0.6433, 0.8628, 0.7182, 0.5826, 0.7483, 0.5449, 0.6416,\n",
      "        0.5686, 0.8316, 0.8321, 0.6577, 0.7654, 0.8134, 0.7537, 0.6319, 0.6524,\n",
      "        0.3380, 0.7408, 0.7445, 0.4637, 0.7440, 0.2573, 0.4696, 1.0600, 0.6289,\n",
      "        0.4256, 0.7606, 0.4047, 0.4143, 0.7923, 0.4506, 0.6274, 0.5649, 0.9237,\n",
      "        0.7013], device='cuda:0', grad_fn=<MaxBackward0>) tensor([16, 18, 11,  8,  4,  5,  6, 12,  8,  1, 16,  3, 12,  8,  1,  3,  8,  3,\n",
      "        15,  5, 10, 18, 10, 15,  6,  8,  8, 18, 13,  8, 10, 18, 12, 12,  8, 18,\n",
      "         5, 18,  8, 12,  3, 12, 15,  3,  8,  1,  3,  3,  3,  3, 10,  5, 18,  7,\n",
      "        10, 12, 12, 17,  3, 18,  3, 12, 10,  3], device='cuda:0')\n",
      "27\n",
      "batch: 28\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7235, 0.5548, 0.6530, 0.5737, 0.2755, 0.3226, 0.7603, 0.6643, 0.4365,\n",
      "        0.7927, 0.6520, 0.6534, 0.8582, 0.6576, 0.5243, 0.4191, 0.9273, 0.5710,\n",
      "        0.5107, 0.7576, 0.3803, 0.3415, 0.7621, 0.9507, 0.7810, 1.0069, 0.4368,\n",
      "        0.3158, 0.5377, 0.5490, 0.7353, 0.8881, 0.5608, 0.3754, 0.5617, 0.5918,\n",
      "        0.3908, 0.8600, 0.3820, 0.3824, 0.4452, 0.6354, 0.6266, 0.3454, 0.5627,\n",
      "        0.3939, 0.6715, 0.6479, 0.4397, 0.6748, 0.6103, 0.5688, 0.5989, 1.0400,\n",
      "        0.8222, 0.3898, 0.6940, 0.8359, 0.6481, 0.2791, 0.7542, 0.8144, 0.7403,\n",
      "        0.7157], device='cuda:0', grad_fn=<MaxBackward0>) tensor([18,  8, 12,  8, 15,  8,  8,  4, 18,  8,  5,  8, 18,  8,  8,  5,  3,  3,\n",
      "        18,  8,  0,  4, 10, 18,  8, 18, 18, 18,  0, 18,  8,  8,  8, 13, 11,  5,\n",
      "         5,  3, 10,  8, 18,  1, 12,  1,  8, 10, 18, 18,  1, 18, 10, 18, 18,  3,\n",
      "        10, 11, 18,  8, 18, 13, 18, 16,  3, 10], device='cuda:0')\n",
      "28\n",
      "batch: 29\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.2463, 0.7156, 0.7697, 0.8992, 0.5912, 0.6155, 0.8137, 0.7367, 1.1208,\n",
      "        0.6609, 0.6981, 0.3837, 0.6922, 0.4135, 0.8116, 0.6155, 0.3928, 0.8467,\n",
      "        0.6371, 0.6517, 0.6467, 0.5673, 0.6044, 0.7117, 0.5748, 0.5516, 0.5085,\n",
      "        0.7578, 0.8588, 0.9959, 0.5288, 1.2940, 0.5635, 0.6567, 0.6030, 0.4024,\n",
      "        0.3947, 0.7185, 0.7131, 0.7078, 1.3430, 0.7355, 0.5513, 0.4001, 0.5821,\n",
      "        0.8147, 0.9582, 0.6164, 0.5327, 0.6693, 0.4736, 0.6876, 0.7006, 0.5390,\n",
      "        0.4706, 0.7105, 0.6718, 0.7616, 0.6275, 0.4358, 0.2008, 0.2843, 0.4588,\n",
      "        0.6602], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 1,  3,  6,  3,  3,  3,  3,  8,  8, 12,  3,  7, 15, 11,  6,  3,  8, 10,\n",
      "         3, 16, 10, 18,  0,  8,  6, 10, 18, 18, 12,  3, 13,  3,  7, 18, 16,  6,\n",
      "         8,  8, 10,  2,  3,  3, 15,  8, 18,  2,  3,  2, 18,  8, 18,  0,  8, 13,\n",
      "        18, 18, 15, 15, 18,  8,  0, 11, 10,  3], device='cuda:0')\n",
      "29\n",
      "batch: 30\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.5218, 0.7668, 0.9535, 0.3976, 0.8632, 0.2851, 0.6706, 0.5394, 0.9097,\n",
      "        0.3814, 0.9982, 0.7083, 0.4914, 0.9401, 0.3533, 1.0807, 0.5585, 0.9418,\n",
      "        0.5872, 0.3924, 0.3564, 0.7821, 0.4650, 0.8683, 0.5132, 0.7932, 0.5557,\n",
      "        0.6947, 0.6493, 0.5978, 0.9697, 1.0446, 0.5680, 1.2132, 0.6151, 0.2481,\n",
      "        0.6922, 0.5291, 0.7467, 0.8471, 0.7716, 0.6478, 0.3217, 0.6549, 0.6122,\n",
      "        0.4087, 0.4600, 0.3676, 0.4754, 0.7824, 0.5529, 0.8025, 0.7376, 0.6604,\n",
      "        0.4899, 0.9321, 0.5762, 0.5370, 0.6949, 0.3677, 0.4317, 0.5625, 0.5936,\n",
      "        0.6345], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 8, 12,  8, 11, 12, 11,  3,  9,  3, 11, 16,  3,  1,  8,  9,  3,  6,  3,\n",
      "         6, 18,  4, 13, 11, 16, 18,  3,  6, 16,  6,  0, 10, 18,  8,  3, 13, 11,\n",
      "        10,  6, 10,  5,  3, 16, 16, 18, 10,  1, 11,  4, 12, 10, 10, 18,  8,  8,\n",
      "         7,  3, 18,  7,  6,  7, 10, 10, 10, 10], device='cuda:0')\n",
      "30\n",
      "batch: 31\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.8722, 0.7332, 0.7626, 0.9225, 0.4952, 0.8222, 0.8126, 0.7977, 0.8265,\n",
      "        0.7372, 0.4172, 1.0283, 0.3048, 0.9184, 0.4746, 0.5293, 0.7328, 0.8662,\n",
      "        0.3917, 0.8736, 0.5743, 0.7855, 0.4896, 0.3952, 0.5735, 0.6372, 0.7484,\n",
      "        0.7282, 0.5917, 1.0366, 0.8322, 0.6909, 0.9683, 0.8526, 0.9116, 0.5809,\n",
      "        0.2983, 0.5642, 0.5563, 0.5378, 0.4416, 0.5244, 0.6415, 0.6762, 1.0247,\n",
      "        0.7741, 0.7492, 0.3635, 0.2769, 0.6729, 0.7843, 0.5292, 0.5718, 0.5027,\n",
      "        0.7729, 0.3774, 0.3349, 0.2672, 0.4449, 0.7442, 0.7730, 0.6977, 0.2871,\n",
      "        0.2847], device='cuda:0', grad_fn=<MaxBackward0>) tensor([10, 18,  3, 18,  1,  8,  8,  8,  5,  6,  7,  3,  1,  3, 11, 13,  6,  3,\n",
      "         8, 18, 16,  6, 17, 18,  1, 18,  3,  3, 18,  3,  6,  6,  8, 15, 12,  1,\n",
      "        18,  3,  8,  3,  3,  6,  3,  7,  8,  0, 10, 11, 10,  3,  8,  8, 12,  4,\n",
      "        10, 12,  4, 18,  1,  0, 10,  3,  3, 10], device='cuda:0')\n",
      "31\n",
      "batch: 32\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.4700, 0.3096, 0.6849, 0.3980, 0.9588, 0.3583, 1.1721, 1.0023, 0.4997,\n",
      "        0.4735, 0.3860, 0.5753, 0.6490, 0.5535, 0.3578, 0.7155, 1.1713, 0.8683,\n",
      "        0.3549, 0.7036, 0.2324, 0.6005, 1.0416, 0.7702, 0.7725, 0.9906, 0.7255,\n",
      "        0.7642, 0.4312, 0.5497, 0.5968, 0.3043, 0.6119, 0.3746, 0.7002, 0.5193,\n",
      "        1.0120, 0.6147, 0.6439, 0.7294, 0.4646, 0.5091, 0.6544, 1.0121, 0.5738,\n",
      "        0.4113, 0.3213, 0.6986, 0.9506, 1.0008, 0.9443, 0.7123, 0.4514, 0.4200,\n",
      "        0.5753, 0.9054, 0.5328, 0.9366, 0.4347, 0.7474, 0.6414, 0.7307, 0.3235,\n",
      "        0.6601], device='cuda:0', grad_fn=<MaxBackward0>) tensor([16, 18, 12, 11,  3,  0,  8, 10,  8, 18, 12,  5,  8,  1, 11,  8, 10, 18,\n",
      "        12, 10,  4, 11,  1,  6,  5,  3, 10,  3,  7, 10,  1, 12, 10, 18,  5, 11,\n",
      "         3, 10,  3,  5,  0,  0, 18,  3,  3,  7, 10,  8, 18,  3, 12, 10,  3, 14,\n",
      "         0, 18, 18, 18, 10, 18,  8, 10, 11,  3], device='cuda:0')\n",
      "32\n",
      "batch: 33\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.7903, 0.4288, 0.1878, 0.7352, 0.3927, 0.4088, 0.9617, 0.5504, 0.7452,\n",
      "        0.5623, 0.4304, 0.4240, 0.9218, 1.1847, 0.5192, 0.7013, 0.8260, 0.2736,\n",
      "        0.5479, 0.4207, 0.8556, 0.8501, 0.6713, 0.3711, 0.5223, 0.9797, 0.5926,\n",
      "        1.1737, 0.6041, 0.8909, 0.6159, 0.3601, 0.7109, 0.4358, 1.0976, 0.4244,\n",
      "        0.3212, 0.6980, 0.6248, 0.8993, 0.7850, 0.7072, 0.4091, 1.0149, 0.4778,\n",
      "        0.9434, 0.5508, 0.4100, 0.7033, 0.8151, 0.5361, 0.5579, 0.3354, 0.8083,\n",
      "        0.5468, 0.5551, 0.8493, 0.6480, 0.5068, 0.5894, 0.3548, 1.1473, 0.3094,\n",
      "        0.9334], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 8,  8,  8, 18, 12, 17, 12, 13,  5,  5, 11,  3,  1, 10,  8, 18, 18, 10,\n",
      "         6,  1, 15,  3,  7, 17, 18,  6,  6, 18,  3,  5,  2,  7,  8, 11,  3, 10,\n",
      "         5,  3,  8,  3,  0,  3,  7,  3, 18, 18, 16, 11, 10, 18, 12, 18,  1,  3,\n",
      "        11,  8,  3,  7,  5, 18,  7, 18, 10, 18], device='cuda:0')\n",
      "33\n",
      "batch: 34\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.2819, 1.1411, 1.0944, 0.4822, 0.6294, 0.6596, 0.5707, 0.8824, 0.5047,\n",
      "        1.1203, 0.4583, 0.7855, 0.3960, 0.7392, 0.7761, 0.5550, 1.0538, 0.7574,\n",
      "        0.8080, 0.4897, 0.5150, 0.6923, 0.6287, 0.3035, 0.4750, 0.8155, 0.6649,\n",
      "        0.6867, 0.5347, 1.0394, 0.3665, 0.5441, 0.4902, 0.4722, 0.5349, 0.5819,\n",
      "        1.3195, 0.5518, 0.2966, 0.4817, 0.6484, 0.6174, 0.7526, 0.8082, 0.8784,\n",
      "        0.4743, 0.3544, 1.0029, 0.4783, 0.3221, 0.5316, 0.5196, 0.7533, 0.5835,\n",
      "        0.5121, 0.4665, 0.7371, 0.7934, 0.7169, 0.7192, 0.3174, 0.7998, 0.6059,\n",
      "        0.6584], device='cuda:0', grad_fn=<MaxBackward0>) tensor([ 0,  3,  6, 10,  8, 10, 10,  7,  1,  0, 16,  9,  5,  4,  8, 18,  3,  3,\n",
      "        10, 18, 15,  3,  3, 16,  7,  8,  8,  8,  3, 18, 18, 18, 14,  3, 10,  8,\n",
      "         3, 18,  6, 18,  3,  8,  5, 18,  3,  7, 11,  1,  3,  8,  8, 18,  5,  7,\n",
      "        16, 10,  8,  3,  6, 10, 17, 18, 16,  3], device='cuda:0')\n",
      "34\n",
      "batch: 35\n",
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.6309, 0.7859, 0.3783, 0.7570, 1.1303, 0.5160, 0.9666, 0.8134, 0.5358,\n",
      "        1.2718, 0.7843, 0.5058, 0.2790, 0.6311, 0.9809, 0.3800, 0.9491, 0.6677,\n",
      "        0.9610, 0.4018, 0.4087, 0.7311, 0.9966, 0.9505, 0.8025, 0.9447, 0.3952,\n",
      "        0.6563, 0.5355, 0.8300, 0.4690, 0.7655, 0.7675, 0.5258, 0.6630, 0.4892,\n",
      "        0.4386, 0.6279, 0.8491, 0.8864, 0.6894, 0.9827, 1.1585, 0.2974, 0.7917,\n",
      "        0.5963, 0.3419, 0.9704, 0.8623, 0.5827, 0.4822, 0.4692, 0.5769, 0.7014,\n",
      "        0.4293, 0.6337, 0.4879, 0.3293, 0.7971, 0.4018, 0.6611, 0.5263, 0.6380,\n",
      "        0.7045], device='cuda:0', grad_fn=<MaxBackward0>) tensor([10, 18,  5,  8,  8,  1,  3, 12,  7,  3,  8, 18, 18, 12, 12,  5, 10,  3,\n",
      "        18, 15, 17,  8, 10,  3, 10, 10, 18,  1, 18,  5, 18,  3, 11, 18, 18, 11,\n",
      "         7, 18,  4, 13, 10, 16,  8, 18, 12,  3, 10,  3, 10, 10, 10,  8,  3, 10,\n",
      "        17,  8,  8,  4,  3, 17, 18,  8, 18, 10], device='cuda:0')\n",
      "35\n",
      "batch: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 64 64 <class 'torch.Tensor'> <class 'torch.Tensor'>\n",
      "acc2: tensor([0.5151, 0.4212, 0.6872, 0.7076, 0.3962, 0.8656, 0.6426, 0.7472, 0.8611,\n",
      "        0.4887, 0.6381, 0.6075, 0.4767, 0.8687, 0.8357, 0.4623, 0.4201, 0.8126,\n",
      "        0.7714, 0.4631, 0.8167, 0.5610, 0.9970, 0.7001, 0.7392, 0.3687, 0.4980,\n",
      "        0.4891, 0.4363, 0.6100, 0.5117, 0.5871, 0.5913, 0.6563, 0.6678, 0.6410,\n",
      "        1.1003, 0.2726, 0.4186, 0.5481, 0.6290, 0.5595, 0.5113, 0.4188, 0.5543,\n",
      "        0.4540, 0.5646, 0.6443, 0.5625, 0.4622, 0.3525, 0.5407, 0.9260, 1.0122,\n",
      "        0.9254, 0.5402, 0.8638, 0.7386, 0.6798, 0.6313, 0.2405, 0.6518, 0.6940,\n",
      "        0.6817], device='cuda:0', grad_fn=<MaxBackward0>) tensor([11, 16,  6, 18, 16, 10,  8,  3,  7,  4, 12,  8,  5,  3,  8, 16,  5,  3,\n",
      "         3, 12,  8,  3, 18, 16,  3,  8, 10, 10,  0,  7, 10, 10,  0,  3,  8,  3,\n",
      "         3, 11, 18,  0,  3,  8,  6, 12,  5, 18, 18,  8, 10,  8, 10, 11,  3, 10,\n",
      "         3, 12, 18,  3,  8, 11,  4, 10,  3,  8], device='cuda:0')\n",
      "36\n",
      "batch: 37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31705/3391589793.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update learning rate schedule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/chatbot/lib/python3.7/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc_list_50 = []\n",
    "val_acc_list_50 = []\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    val_acc = 0.0\n",
    "    batch = [] \n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "        print(f'batch: {batch_id}')\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        # print(f'out: {len(out[0]), len(out), out}')\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        print(batch_id)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    train_acc_list_50.append(train_acc / (batch_id+1))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(val_dataloader), total=len(val_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        val_acc += calc_accuracy(out, label)\n",
    "    print(\"epoch {} val acc {}\".format(e+1, val_acc / (batch_id+1)))\n",
    "    val_acc_list_50.append(val_acc / (batch_id+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_acc_list_50), len(train_acc_list_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19247596153846153,\n",
       " 0.5544951923076923,\n",
       " 0.7181490384615384,\n",
       " 0.7775240384615384,\n",
       " 0.7946875,\n",
       " 0.8125240384615384,\n",
       " 0.8047115384615384,\n",
       " 0.8240865384615383,\n",
       " 0.83125,\n",
       " 0.8384375,\n",
       " 0.8216105769230769,\n",
       " 0.8328125,\n",
       " 0.8297596153846153,\n",
       " 0.838125,\n",
       " 0.8434375,\n",
       " 0.8368990384615383,\n",
       " 0.845625,\n",
       " 0.8403125,\n",
       " 0.83875,\n",
       " 0.84,\n",
       " 0.8384855769230769,\n",
       " 0.8481490384615384,\n",
       " 0.8406490384615384,\n",
       " 0.8475240384615383,\n",
       " 0.8478125,\n",
       " 0.8459615384615384,\n",
       " 0.84625,\n",
       " 0.8475240384615383,\n",
       " 0.8425,\n",
       " 0.8490865384615384,\n",
       " 0.8450240384615384,\n",
       " 0.8475240384615383,\n",
       " 0.8469230769230769,\n",
       " 0.8484375,\n",
       " 0.85125,\n",
       " 0.8525,\n",
       " 0.854375,\n",
       " 0.85125,\n",
       " 0.848125,\n",
       " 0.8484615384615384,\n",
       " 0.85,\n",
       " 0.848125,\n",
       " 0.8509375,\n",
       " 0.853125,\n",
       " 0.8515625,\n",
       " 0.8515625,\n",
       " 0.851875,\n",
       " 0.8521875,\n",
       " 0.8521875,\n",
       " 0.8521875]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc_list_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_acc_list_50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21593/1382154896.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 50번 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtest_acc_list_50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list_50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_acc_list_50' is not defined"
     ]
    }
   ],
   "source": [
    "# 10번 학습 \n",
    "# test_acc_list, train_acc_list \n",
    "\n",
    "# 50번 학습 \n",
    "test_acc_list_50, train_acc_list_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_10 = list(range(0, 10))\n",
    "epochs_50 = list(range(0, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(list(range(len(train_acc_list_50))), train_acc_list_50, label='train_acc')\n",
    "plt.plot(list(range(len(val_acc_list_50))), val_acc_list_50, label='val_acc')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(data_path + 'Wellness_Conversation_intent_test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1658213264749,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "5GRNQbDf9mtR",
    "outputId": "dd31dd73-db43-407e-b55a-b411bc8c249b",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>intent</th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>776</td>\n",
       "      <td>우울감</td>\n",
       "      <td>급 기억력 감퇴 와서 진심 우울해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18689</td>\n",
       "      <td>자살충동</td>\n",
       "      <td>자책감으로 평생을 살라고 유서도 써놓고 옆에 뒀어.</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18994</td>\n",
       "      <td>불안</td>\n",
       "      <td>긴장감 때문에 힘들다</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12983</td>\n",
       "      <td>초조함</td>\n",
       "      <td>신경질이 나는데 그 사람 옷을 벗겨주고는 침대에서 재웠어요.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6285</td>\n",
       "      <td>무기력</td>\n",
       "      <td>아무 것도 하기 싫어서 그냥 누워만 있고…</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>12206</td>\n",
       "      <td>초조함</td>\n",
       "      <td>누굴 만나면 어떻게 얘기해야 하나 걱정도 되고…</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>16000</td>\n",
       "      <td>자신감저하</td>\n",
       "      <td>지금은 내가 할 수 있는게 아무것도 없다는 생각이 많아.</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>13112</td>\n",
       "      <td>초조함</td>\n",
       "      <td>다른 애들보다 두 배로 신경 써줘야 하니까 그것도 너무 짜증나지.</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>4847</td>\n",
       "      <td>분노</td>\n",
       "      <td>이런 지질한 놈이랑 내가 왜 살아야 하나 몰라…</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>16704</td>\n",
       "      <td>자존감저하</td>\n",
       "      <td>친구들이랑 대화를 할 때도 누가 녹취를 하는 느낌이 들어서 말을 제대로 못하겠어</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3936 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id intent                                       context  label\n",
       "0       776    우울감                            급 기억력 감퇴 와서 진심 우울해      0\n",
       "1     18689   자살충동                  자책감으로 평생을 살라고 유서도 써놓고 옆에 뒀어.     17\n",
       "2     18994     불안                                   긴장감 때문에 힘들다     18\n",
       "3     12983    초조함             신경질이 나는데 그 사람 옷을 벗겨주고는 침대에서 재웠어요.     10\n",
       "4      6285    무기력                       아무 것도 하기 싫어서 그냥 누워만 있고…      4\n",
       "...     ...    ...                                           ...    ...\n",
       "3931  12206    초조함                    누굴 만나면 어떻게 얘기해야 하나 걱정도 되고…     10\n",
       "3932  16000  자신감저하               지금은 내가 할 수 있는게 아무것도 없다는 생각이 많아.     14\n",
       "3933  13112    초조함          다른 애들보다 두 배로 신경 써줘야 하니까 그것도 너무 짜증나지.     10\n",
       "3934   4847     분노                    이런 지질한 놈이랑 내가 왜 살아야 하나 몰라…      3\n",
       "3935  16704  자존감저하  친구들이랑 대화를 할 때도 누가 녹취를 하는 느낌이 들어서 말을 제대로 못하겠어     15\n",
       "\n",
       "[3936 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제 감성분석 해보기 \n",
    "X_test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1APeT3vbhcZL"
   },
   "source": [
    "torch.save(model.state_dict(), data_path + 'BERT_intent_model_50.pt')\n",
    "bertmodel, vocab = get_pytorch_kobert_model(cachedir=\".cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1266,
     "status": "ok",
     "timestamp": 1658220525448,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "TCB64SVspOhM",
    "outputId": "674f8957-0c33-4817-dab0-14a296d91d9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = torch.load(data_path + 'BERT_intent_model_50.pt')\n",
    "load_model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
    "load_model.load_state_dict(torch.load(data_path + 'BERT_intent_model_50.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1658213264750,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "AOmQMe_HEl3Q",
    "outputId": "6268944f-a379-4562-a7a0-8510e81659d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 급 기억력 감퇴 와서 진심 우울해\n",
       "1                       자책감으로 평생을 살라고 유서도 써놓고 옆에 뒀어.\n",
       "2                                        긴장감 때문에 힘들다\n",
       "3                  신경질이 나는데 그 사람 옷을 벗겨주고는 침대에서 재웠어요.\n",
       "4                            아무 것도 하기 싫어서 그냥 누워만 있고…\n",
       "                            ...                     \n",
       "3931                      누굴 만나면 어떻게 얘기해야 하나 걱정도 되고…\n",
       "3932                 지금은 내가 할 수 있는게 아무것도 없다는 생각이 많아.\n",
       "3933            다른 애들보다 두 배로 신경 써줘야 하니까 그것도 너무 짜증나지.\n",
       "3934                      이런 지질한 놈이랑 내가 왜 살아야 하나 몰라…\n",
       "3935    친구들이랑 대화를 할 때도 누가 녹취를 하는 느낌이 들어서 말을 제대로 못하겠어\n",
       "Name: context, Length: 3936, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = X_test['context']\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ofBPcHt4WMg4"
   },
   "outputs": [],
   "source": [
    "y_true = X_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Ka8UqEZjWirg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 위에서 설정한 tok, max_len, batch_size, device를 그대로 입력\n",
    "# comment : 예측하고자 하는 텍스트 데이터 리스트\n",
    "def getSentimentValue(comment, tok, max_len, batch_size, device):\n",
    "    comments_list = [] # 텍스트 데이터를 담을 리스트\n",
    "    main_list = [] # 대분류 카테고리 값을 담을 리스트\n",
    "    \n",
    "    for c in comment: # 모든 댓글\n",
    "        comments_list.append( [c, 5] ) # [댓글, 임의의 양의 정수값] 설정\n",
    "        \n",
    "    pdData = pd.DataFrame(comments_list, columns = [['context', 'intent']] )\n",
    "    pdData = pdData.values\n",
    "    test_set = BERTDataset(pdData, 0, 1, tok, max_len, True, False) \n",
    "    test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=5)\n",
    "    \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_input):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length \n",
    "    \n",
    "        # 이때, out이 예측 결과 리스트\n",
    "        out = load_model(token_ids, valid_length, segment_ids)\n",
    "\n",
    "        for pred in out: \n",
    "            main_list.append(np.argmax(pred.detach().cpu()))\n",
    "        \n",
    "    return main_list # 텍스트 데이터에 1대1 매칭되는 감성값 리스트 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903019,
     "status": "ok",
     "timestamp": 1658215529419,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "JUlGmREfYNPL",
    "outputId": "e1e13c01-13e1-4c28-e9d9-2e2e58646985"
   },
   "outputs": [],
   "source": [
    "y_pred = getSentimentValue(comments, tok, max_len, batch_size, device)   # tok, max_len, batch_size, device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1658158979345,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "wZ0MCQMrYSuE",
    "outputId": "8eae88f9-9318-43f3-c6d8-0151fc0f3508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1       17\n",
       "2       18\n",
       "3       10\n",
       "4        4\n",
       "        ..\n",
       "3931    10\n",
       "3932    14\n",
       "3933    10\n",
       "3934     3\n",
       "3935    15\n",
       "Name: label, Length: 3936, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1658216988016,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "e_6yxylmcFrR",
    "outputId": "c0bfdd75-77cd-44c5-f5b0-ac2ac048e828"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3936, 3936)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "-sdeOFEA-ndF"
   },
   "outputs": [],
   "source": [
    "y_pred = list(map(int, y_pred)) \n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1658218375237,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "rERO39oaWK_W",
    "outputId": "ec7c9102-a063-4287-b31d-bc36447d07b3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "comments = ['너무 우울해', '죽고싶다', '아무것도하기싫다']\n",
    "\n",
    "y_pred = getSentimentValue(comments, tok, max_len, batch_size, device)   # tok, max_len, batch_size, device\n",
    "y_pred = list(map(int, y_pred)) \n",
    "\n",
    "print(intent_list[y_pred[0]], intent_list[y_pred[1]], intent_list[y_pred[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3eWUc9v5dotY",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>296</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>343</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>482</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>209</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4   5   6    7   8    9    10   11   12  13  14   15  \\\n",
       "0   278    4    3    2    7   0   1    4   0    8    4    1    6   0   0    8   \n",
       "1     3  296    5    6    6   1   0    1   0    4   11    0   14   0   0    2   \n",
       "2     3   10  120    1    9   1   0    1   0    0    4    1    0   0   0    1   \n",
       "3     3    8    1  172    2   4   0    0   1    2   10    0    4   0   1    3   \n",
       "4     8    4    1    3  197   3   0    3   0    6    6   12    1   1   5    2   \n",
       "5     3    4    2    4    0  32   1    0   1    0    4    0    1   0   2    0   \n",
       "6     0    1    0    0    0   0  42    0   0    0    0    0    1   0   0    0   \n",
       "7     1    1    0    1    4   0   0  194  12    2    3    0    1   0   0    0   \n",
       "8     0    0    1    0    1   1   0    3  77    2    1    1    0   0   0    0   \n",
       "9     2    2    1    0    0   0   0    1   1  343    8    8    0   0   0    1   \n",
       "10    7    2    0    4    4   4   0    1   1    6  482    2    5   0   2    3   \n",
       "11    1    0    1    0    4   1   0    2   0   10    3  225    0   0   0    1   \n",
       "12    1   12    0   10    4   4   0    0   0    1    9    0  184   0   1    6   \n",
       "13    1    1    0    0    1   0   0    0   0    0    0    0    0  45   0    0   \n",
       "14    2    0    0    3    1   1   0    0   0    0    3    2    0   1  46    3   \n",
       "15    2    2    0    1    2   1   0    0   0    2    7    1    5   1   6  209   \n",
       "16    4    7    1    2    2   3   1    0   0    1    2    1    2   0   4    5   \n",
       "17    0    1    0    1    4   0   0    1   0    4    0    1    2   0   0    0   \n",
       "18    0    2    0    0    0   0   0    1   0    0   14    0    0   0   0    0   \n",
       "\n",
       "     16   17   18  \n",
       "0     1    3    1  \n",
       "1     6    0    3  \n",
       "2     1    2    1  \n",
       "3     2    4    0  \n",
       "4     3    3    0  \n",
       "5     0    0    0  \n",
       "6     0    0    0  \n",
       "7     0    0    0  \n",
       "8     0    0    0  \n",
       "9     0    1    5  \n",
       "10    2    2   13  \n",
       "11    0    1    0  \n",
       "12    0    3    1  \n",
       "13    0    0    1  \n",
       "14    1    0    1  \n",
       "15    5    0    1  \n",
       "16  104    5    0  \n",
       "17    1  114    0  \n",
       "18    0    0  167  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score , recall_score , confusion_matrix, f1_score, classification_report\n",
    "\n",
    "confusion_mt = pd.DataFrame(confusion_matrix(y_true, y_pred))\n",
    "confusion_mt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1658218377236,
     "user": {
      "displayName": "오재동",
      "userId": "09849167419611092646"
     },
     "user_tz": -540
    },
    "id": "TJLBiaQge8ml",
    "outputId": "26f2e011-3c8c-4186-df79-92b41762a52b"
   },
   "outputs": [],
   "source": [
    "confusion_mt.columns = intent_list \n",
    "confusion_mt.index = intent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "N6ewx1z9gl0N"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>초조함</th>\n",
       "      <th>외로움</th>\n",
       "      <th>슬픔</th>\n",
       "      <th>자신감저하</th>\n",
       "      <th>불면</th>\n",
       "      <th>죄책감</th>\n",
       "      <th>자살충동</th>\n",
       "      <th>절망감</th>\n",
       "      <th>식욕저하</th>\n",
       "      <th>분노</th>\n",
       "      <th>불안</th>\n",
       "      <th>피로</th>\n",
       "      <th>우울감</th>\n",
       "      <th>식욕증가</th>\n",
       "      <th>무기력</th>\n",
       "      <th>감정조절이상</th>\n",
       "      <th>집중력저하</th>\n",
       "      <th>자존감저하</th>\n",
       "      <th>상실감</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>초조함</th>\n",
       "      <td>278</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>외로움</th>\n",
       "      <td>3</td>\n",
       "      <td>296</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>슬픔</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자신감저하</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불면</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>죄책감</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자살충동</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>절망감</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>식욕저하</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>분노</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>343</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>불안</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>482</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>피로</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>우울감</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>식욕증가</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>무기력</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>감정조절이상</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>209</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>집중력저하</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>104</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자존감저하</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>상실감</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        초조함  외로움   슬픔  자신감저하   불면  죄책감  자살충동  절망감  식욕저하   분노   불안   피로  우울감  \\\n",
       "초조함     278    4    3      2    7    0     1    4     0    8    4    1    6   \n",
       "외로움       3  296    5      6    6    1     0    1     0    4   11    0   14   \n",
       "슬픔        3   10  120      1    9    1     0    1     0    0    4    1    0   \n",
       "자신감저하     3    8    1    172    2    4     0    0     1    2   10    0    4   \n",
       "불면        8    4    1      3  197    3     0    3     0    6    6   12    1   \n",
       "죄책감       3    4    2      4    0   32     1    0     1    0    4    0    1   \n",
       "자살충동      0    1    0      0    0    0    42    0     0    0    0    0    1   \n",
       "절망감       1    1    0      1    4    0     0  194    12    2    3    0    1   \n",
       "식욕저하      0    0    1      0    1    1     0    3    77    2    1    1    0   \n",
       "분노        2    2    1      0    0    0     0    1     1  343    8    8    0   \n",
       "불안        7    2    0      4    4    4     0    1     1    6  482    2    5   \n",
       "피로        1    0    1      0    4    1     0    2     0   10    3  225    0   \n",
       "우울감       1   12    0     10    4    4     0    0     0    1    9    0  184   \n",
       "식욕증가      1    1    0      0    1    0     0    0     0    0    0    0    0   \n",
       "무기력       2    0    0      3    1    1     0    0     0    0    3    2    0   \n",
       "감정조절이상    2    2    0      1    2    1     0    0     0    2    7    1    5   \n",
       "집중력저하     4    7    1      2    2    3     1    0     0    1    2    1    2   \n",
       "자존감저하     0    1    0      1    4    0     0    1     0    4    0    1    2   \n",
       "상실감       0    2    0      0    0    0     0    1     0    0   14    0    0   \n",
       "\n",
       "        식욕증가  무기력  감정조절이상  집중력저하  자존감저하  상실감  \n",
       "초조함        0    0       8      1      3    1  \n",
       "외로움        0    0       2      6      0    3  \n",
       "슬픔         0    0       1      1      2    1  \n",
       "자신감저하      0    1       3      2      4    0  \n",
       "불면         1    5       2      3      3    0  \n",
       "죄책감        0    2       0      0      0    0  \n",
       "자살충동       0    0       0      0      0    0  \n",
       "절망감        0    0       0      0      0    0  \n",
       "식욕저하       0    0       0      0      0    0  \n",
       "분노         0    0       1      0      1    5  \n",
       "불안         0    2       3      2      2   13  \n",
       "피로         0    0       1      0      1    0  \n",
       "우울감        0    1       6      0      3    1  \n",
       "식욕증가      45    0       0      0      0    1  \n",
       "무기력        1   46       3      1      0    1  \n",
       "감정조절이상     1    6     209      5      0    1  \n",
       "집중력저하      0    4       5    104      5    0  \n",
       "자존감저하      0    0       0      1    114    0  \n",
       "상실감        0    0       0      0      0  167  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = round(f1_score(y_true, y_pred, average='micro'), 3) \n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9117750931673644"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['초조함',\n",
       " '외로움',\n",
       " '슬픔',\n",
       " '자신감저하',\n",
       " '불면',\n",
       " '죄책감',\n",
       " '자살충동',\n",
       " '절망감',\n",
       " '식욕저하',\n",
       " '분노',\n",
       " '불안',\n",
       " '피로',\n",
       " '우울감',\n",
       " '식욕증가',\n",
       " '무기력',\n",
       " '감정조절이상',\n",
       " '집중력저하',\n",
       " '자존감저하',\n",
       " '상실감']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_idx = list(range(len(intent_list)))\n",
    "intent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '           0       0.87      0.84      0.86       331',\n",
       " '           1       0.83      0.83      0.83       358',\n",
       " '           2       0.88      0.77      0.82       155',\n",
       " '           3       0.82      0.79      0.81       217',\n",
       " '           4       0.79      0.76      0.78       258',\n",
       " '           5       0.57      0.59      0.58        54',\n",
       " '           6       0.93      0.95      0.94        44',\n",
       " '           7       0.92      0.89      0.90       219',\n",
       " '           8       0.83      0.89      0.86        87',\n",
       " '           9       0.88      0.92      0.90       373',\n",
       " '          10       0.84      0.89      0.87       540',\n",
       " '          11       0.88      0.90      0.89       249',\n",
       " '          12       0.81      0.78      0.80       236',\n",
       " '          13       0.94      0.92      0.93        49',\n",
       " '          14       0.69      0.72      0.70        64',\n",
       " '          15       0.86      0.85      0.85       245',\n",
       " '          16       0.83      0.72      0.77       144',\n",
       " '          17       0.83      0.88      0.85       129',\n",
       " '          18       0.86      0.91      0.88       184',\n",
       " '',\n",
       " '    accuracy                           0.85      3936',\n",
       " '   macro avg       0.83      0.83      0.83      3936',\n",
       " 'weighted avg       0.85      0.85      0.84      3936',\n",
       " '']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr = classification_report(y_true, y_pred).split('\\n')\n",
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['precision', 'recall', 'f1-score', 'support'],\n",
       " [],\n",
       " ['0', '0.87', '0.84', '0.86', '331'],\n",
       " ['1', '0.83', '0.83', '0.83', '358'],\n",
       " ['2', '0.88', '0.77', '0.82', '155'],\n",
       " ['3', '0.82', '0.79', '0.81', '217'],\n",
       " ['4', '0.79', '0.76', '0.78', '258'],\n",
       " ['5', '0.57', '0.59', '0.58', '54'],\n",
       " ['6', '0.93', '0.95', '0.94', '44'],\n",
       " ['7', '0.92', '0.89', '0.90', '219'],\n",
       " ['8', '0.83', '0.89', '0.86', '87'],\n",
       " ['9', '0.88', '0.92', '0.90', '373'],\n",
       " ['10', '0.84', '0.89', '0.87', '540'],\n",
       " ['11', '0.88', '0.90', '0.89', '249'],\n",
       " ['12', '0.81', '0.78', '0.80', '236'],\n",
       " ['13', '0.94', '0.92', '0.93', '49'],\n",
       " ['14', '0.69', '0.72', '0.70', '64'],\n",
       " ['15', '0.86', '0.85', '0.85', '245'],\n",
       " ['16', '0.83', '0.72', '0.77', '144'],\n",
       " ['17', '0.83', '0.88', '0.85', '129'],\n",
       " ['18', '0.86', '0.91', '0.88', '184'],\n",
       " [],\n",
       " ['accuracy', '0.85', '3936'],\n",
       " ['macro', 'avg', '0.83', '0.83', '0.83', '3936'],\n",
       " ['weighted', 'avg', '0.85', '0.85', '0.84', '3936'],\n",
       " []]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = []\n",
    "\n",
    "for idx, line in enumerate(cr):\n",
    "    clr_df.append([])\n",
    "    if line == '':\n",
    "        continue\n",
    "    \n",
    "    word_list = line.strip().split(' ')\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word != '':\n",
    "            clr_df[idx].append(word)\n",
    "\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_df[-2][0] = ' '.join([clr_df[-2][0], clr_df[-2][1]])\n",
    "clr_df[-3][0] = ' '.join([clr_df[-3][0], clr_df[-3][1]])\n",
    "clr_df[-4].insert(1, ' ')\n",
    "clr_df[-4].insert(2, ' ')\n",
    "clr_df[0].insert(0, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['index', 'precision', 'recall', 'f1-score', 'support'],\n",
       " ['0', '0.87', '0.84', '0.86', '331'],\n",
       " ['1', '0.83', '0.83', '0.83', '358'],\n",
       " ['2', '0.88', '0.77', '0.82', '155'],\n",
       " ['3', '0.82', '0.79', '0.81', '217'],\n",
       " ['4', '0.79', '0.76', '0.78', '258'],\n",
       " ['5', '0.57', '0.59', '0.58', '54'],\n",
       " ['6', '0.93', '0.95', '0.94', '44'],\n",
       " ['7', '0.92', '0.89', '0.90', '219'],\n",
       " ['8', '0.83', '0.89', '0.86', '87'],\n",
       " ['9', '0.88', '0.92', '0.90', '373'],\n",
       " ['10', '0.84', '0.89', '0.87', '540'],\n",
       " ['11', '0.88', '0.90', '0.89', '249'],\n",
       " ['12', '0.81', '0.78', '0.80', '236'],\n",
       " ['13', '0.94', '0.92', '0.93', '49'],\n",
       " ['14', '0.69', '0.72', '0.70', '64'],\n",
       " ['15', '0.86', '0.85', '0.85', '245'],\n",
       " ['16', '0.83', '0.72', '0.77', '144'],\n",
       " ['17', '0.83', '0.88', '0.85', '129'],\n",
       " ['18', '0.86', '0.91', '0.88', '184'],\n",
       " ['accuracy', ' ', ' ', '0.85', '3936'],\n",
       " ['macro avg', '0.83', '0.83', '0.83', '3936'],\n",
       " ['weighted avg', '0.85', '0.85', '0.84', '3936']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df[-2].pop(1)\n",
    "clr_df[-3].pop(1)\n",
    "clr_df.pop(1)\n",
    "clr_df.pop(-1)\n",
    "clr_df.pop(-4)\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>accuracy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index precision recall f1-score support\n",
       "0              0      0.87   0.84     0.86     331\n",
       "1              1      0.83   0.83     0.83     358\n",
       "2              2      0.88   0.77     0.82     155\n",
       "3              3      0.82   0.79     0.81     217\n",
       "4              4      0.79   0.76     0.78     258\n",
       "5              5      0.57   0.59     0.58      54\n",
       "6              6      0.93   0.95     0.94      44\n",
       "7              7      0.92   0.89     0.90     219\n",
       "8              8      0.83   0.89     0.86      87\n",
       "9              9      0.88   0.92     0.90     373\n",
       "10            10      0.84   0.89     0.87     540\n",
       "11            11      0.88   0.90     0.89     249\n",
       "12            12      0.81   0.78     0.80     236\n",
       "13            13      0.94   0.92     0.93      49\n",
       "14            14      0.69   0.72     0.70      64\n",
       "15            15      0.86   0.85     0.85     245\n",
       "16            16      0.83   0.72     0.77     144\n",
       "17            17      0.83   0.88     0.85     129\n",
       "18            18      0.86   0.91     0.88     184\n",
       "19      accuracy                      0.85    3936\n",
       "20     macro avg      0.83   0.83     0.83    3936\n",
       "21  weighted avg      0.85   0.85     0.84    3936"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df = pd.DataFrame(clr_df[1:], columns=clr_df[0])\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall f1-score support\n",
       "index                                         \n",
       "0                 0.87   0.84     0.86     331\n",
       "1                 0.83   0.83     0.83     358\n",
       "2                 0.88   0.77     0.82     155\n",
       "3                 0.82   0.79     0.81     217\n",
       "4                 0.79   0.76     0.78     258\n",
       "5                 0.57   0.59     0.58      54\n",
       "6                 0.93   0.95     0.94      44\n",
       "7                 0.92   0.89     0.90     219\n",
       "8                 0.83   0.89     0.86      87\n",
       "9                 0.88   0.92     0.90     373\n",
       "10                0.84   0.89     0.87     540\n",
       "11                0.88   0.90     0.89     249\n",
       "12                0.81   0.78     0.80     236\n",
       "13                0.94   0.92     0.93      49\n",
       "14                0.69   0.72     0.70      64\n",
       "15                0.86   0.85     0.85     245\n",
       "16                0.83   0.72     0.77     144\n",
       "17                0.83   0.88     0.85     129\n",
       "18                0.86   0.91     0.88     184\n",
       "accuracy                          0.85    3936\n",
       "macro avg         0.83   0.83     0.83    3936\n",
       "weighted avg      0.85   0.85     0.84    3936"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df.index = clr_df['index']\n",
    "\n",
    "del clr_df['index']\n",
    "clr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df_1 = clr_df[:11]\n",
    "clr_df_2 = clr_df[11:]\n",
    "\n",
    "len(clr_df_1), len(clr_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision recall f1-score support\n",
       "index                                  \n",
       "0          0.87   0.84     0.86     331\n",
       "1          0.83   0.83     0.83     358\n",
       "2          0.88   0.77     0.82     155\n",
       "3          0.82   0.79     0.81     217\n",
       "4          0.79   0.76     0.78     258\n",
       "5          0.57   0.59     0.58      54\n",
       "6          0.93   0.95     0.94      44\n",
       "7          0.92   0.89     0.90     219\n",
       "8          0.83   0.89     0.86      87\n",
       "9          0.88   0.92     0.90     373\n",
       "10         0.84   0.89     0.87     540"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall f1-score support\n",
       "index                                         \n",
       "11                0.88   0.90     0.89     249\n",
       "12                0.81   0.78     0.80     236\n",
       "13                0.94   0.92     0.93      49\n",
       "14                0.69   0.72     0.70      64\n",
       "15                0.86   0.85     0.85     245\n",
       "16                0.83   0.72     0.77     144\n",
       "17                0.83   0.88     0.85     129\n",
       "18                0.86   0.91     0.88     184\n",
       "accuracy                          0.85    3936\n",
       "macro avg         0.83   0.83     0.83    3936\n",
       "weighted avg      0.85   0.85     0.84    3936"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.90</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.87</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.86</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.85</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.85</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.82</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.80</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.77</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.70</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             precision recall f1-score support\n",
       "index                                         \n",
       "6                 0.93   0.95     0.94      44\n",
       "13                0.94   0.92     0.93      49\n",
       "9                 0.88   0.92     0.90     373\n",
       "7                 0.92   0.89     0.90     219\n",
       "11                0.88   0.90     0.89     249\n",
       "18                0.86   0.91     0.88     184\n",
       "10                0.84   0.89     0.87     540\n",
       "8                 0.83   0.89     0.86      87\n",
       "0                 0.87   0.84     0.86     331\n",
       "15                0.86   0.85     0.85     245\n",
       "17                0.83   0.88     0.85     129\n",
       "accuracy                          0.85    3936\n",
       "weighted avg      0.85   0.85     0.84    3936\n",
       "1                 0.83   0.83     0.83     358\n",
       "macro avg         0.83   0.83     0.83    3936\n",
       "2                 0.88   0.77     0.82     155\n",
       "3                 0.82   0.79     0.81     217\n",
       "12                0.81   0.78     0.80     236\n",
       "4                 0.79   0.76     0.78     258\n",
       "16                0.83   0.72     0.77     144\n",
       "14                0.69   0.72     0.70      64\n",
       "5                 0.57   0.59     0.58      54"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clr_df.sort_values(by='f1-score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize \n",
    "\n",
    "y_true = label_binarize(y_true, classes=intent_idx)\n",
    "y_pred = label_binarize(y_pred, classes=intent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "n_classes = 19\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict() \n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true[:,i], y_pred[:,i]) \n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "val = 0\n",
    "\n",
    "# font = {'size': 15}\n",
    "# plt.rc('font', **font)\n",
    "plt.rcParams.update({'font.size': 15, 'font.weight': 'normal'})\n",
    "\n",
    "for idx, i in enumerate(range(n_classes)):\n",
    "    if idx == 6 or idx == 5: \n",
    "        plt.subplot(121+val) \n",
    "        plt.plot(fpr[i], tpr[i], label = f'ROC curve(area = {round(roc_auc[i], 2)}')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=18) \n",
    "        plt.ylabel('True Positive Rate', fontsize=18)\n",
    "        plt.title(f'Class {idx}', fontsize=18)\n",
    "        plt.legend(loc='lower right')\n",
    "        val += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9265999304423614,\n",
       " 1: 0.9117277840059207,\n",
       " 2: 0.8757002329132931,\n",
       " 3: 0.8966194272034378,\n",
       " 4: 0.8607053884188829,\n",
       " 5: 0.8115948251187819,\n",
       " 6: 0.9879940203681211,\n",
       " 7: 0.9499025211818339,\n",
       " 8: 0.9465871117442058,\n",
       " 9: 0.9477505250192063,\n",
       " 10: 0.935927889019762,\n",
       " 11: 0.9591090153943683,\n",
       " 12: 0.9049793861658268,\n",
       " 13: 0.9586691378377952,\n",
       " 14: 0.8574380165289255,\n",
       " 15: 0.9381158803266633,\n",
       " 16: 0.8859880450070323,\n",
       " 17: 0.9463289778315345,\n",
       " 18: 0.9692280059330676}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.        , 0.01386963, 1.        ]),\n",
       " 1: array([0.        , 0.01453326, 1.        ]),\n",
       " 2: array([0.        , 0.00343824, 1.        ]),\n",
       " 3: array([0.        , 0.00860446, 1.        ]),\n",
       " 4: array([0.        , 0.01114736, 1.        ]),\n",
       " 5: array([0.        , 0.00643998, 1.        ]),\n",
       " 6: array([0.        , 0.00128469, 1.        ]),\n",
       " 7: array([0.        , 0.00430455, 1.        ]),\n",
       " 8: array([0.       , 0.0033775, 1.       ]),\n",
       " 9: array([0.        , 0.01066517, 1.        ]),\n",
       " 10: array([0.        , 0.02444052, 1.        ]),\n",
       " 11: array([0.        , 0.00949281, 1.        ]),\n",
       " 12: array([0.        , 0.00783784, 1.        ]),\n",
       " 13: array([0.        , 0.00102907, 1.        ]),\n",
       " 14: array([0.        , 0.00387397, 1.        ]),\n",
       " 15: array([0.        , 0.00948253, 1.        ]),\n",
       " 16: array([0.        , 0.00580169, 1.        ]),\n",
       " 17: array([0.        , 0.00656685, 1.        ]),\n",
       " 18: array([0.        , 0.00719616, 1.        ])}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([0.        , 0.86706949, 1.        ]),\n",
       " 1: array([0.        , 0.83798883, 1.        ]),\n",
       " 2: array([0.        , 0.75483871, 1.        ]),\n",
       " 3: array([0.        , 0.80184332, 1.        ]),\n",
       " 4: array([0.        , 0.73255814, 1.        ]),\n",
       " 5: array([0.        , 0.62962963, 1.        ]),\n",
       " 6: array([0.        , 0.97727273, 1.        ]),\n",
       " 7: array([0.        , 0.90410959, 1.        ]),\n",
       " 8: array([0.        , 0.89655172, 1.        ]),\n",
       " 9: array([0.        , 0.90616622, 1.        ]),\n",
       " 10: array([0.       , 0.8962963, 1.       ]),\n",
       " 11: array([0.        , 0.92771084, 1.        ]),\n",
       " 12: array([0.        , 0.81779661, 1.        ]),\n",
       " 13: array([0.        , 0.91836735, 1.        ]),\n",
       " 14: array([0.     , 0.71875, 1.     ]),\n",
       " 15: array([0.        , 0.88571429, 1.        ]),\n",
       " 16: array([0.        , 0.77777778, 1.        ]),\n",
       " 17: array([0.        , 0.89922481, 1.        ]),\n",
       " 18: array([0.        , 0.94565217, 1.        ])}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPD8x6FW4vG0NXoXRHBJD8H",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1e8sLlhMCKkL6-4wvgqN6z1c0CeIA9H6M",
   "name": "Modeling.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
