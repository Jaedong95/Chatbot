{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2f139a",
   "metadata": {},
   "source": [
    "### 0. Environment Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a1d1",
   "metadata": {},
   "source": [
    "#### 1) Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd9d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pymysql\n",
    "import os \n",
    "import torch\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad2463",
   "metadata": {},
   "source": [
    "#### 2) MySQL Connect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64925d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='localhost', user='lamda_00', password='lamda95', db='chatbot', charset='utf8')\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e526f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql):\n",
    "    curs.execute(sql)\n",
    "    \n",
    "    return curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7cf769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('context_df',),\n",
       " ('intensity_df',),\n",
       " ('polarity_df',),\n",
       " ('response_df',),\n",
       " ('wellness_df',))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'SHOW TABLES;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f55c8",
   "metadata": {},
   "source": [
    "#### 3) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f581b537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('idx', 'int(11)', 'NO', 'PRI', None, ''),\n",
       " ('intent', 'varchar(100)', 'NO', '', None, ''),\n",
       " ('keyword', 'varchar(100)', 'NO', '', None, ''),\n",
       " ('utterance', 'varchar(1000)', 'NO', '', None, ''),\n",
       " ('intent_label', 'int(11)', 'NO', '', None, ''),\n",
       " ('intent_keyword', 'varchar(100)', 'NO', '', None, ''),\n",
       " ('ik_label', 'int(11)', 'NO', '', None, ''))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'DESC wellness_df;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c162e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('idx', 'int(11)', 'NO', 'PRI', None, ''),\n",
       " ('Question', 'varchar(1000)', 'NO', '', None, ''),\n",
       " ('Answer', 'varchar(1000)', 'NO', '', None, ''))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'DESC response_df;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8523af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('12시 땡!', '하루가 또 가네요.'),\n",
       " ('1지망 학교 떨어졌어', '위로해 드립니다.'),\n",
       " ('3박4일 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
       " ('3박4일 정도 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
       " ('PPL 심하네', '눈살이 찌푸려지죠.'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'SELECT Question, Answer FROM response_df;'\n",
    "\n",
    "data = execute_sql(sql)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645f9085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list = list(map(lambda x: x[0], data))\n",
    "candidate_list = list(map(lambda x: x[1], data))\n",
    "\n",
    "candidate_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32ab22",
   "metadata": {},
   "source": [
    "#### 4) Stop MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf8f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71fe3a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4d960",
   "metadata": {},
   "source": [
    "### 1. Pretrained tokenizer, model load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f32cd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5523c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    do_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85a9931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    \"beomi/kcbert-base\"\n",
    ")\n",
    "\n",
    "model = BertModel.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    config=pretrained_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c277ffa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"beomi/kcbert-base\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 300,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.23.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30000\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1867d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c75a12",
   "metadata": {},
   "source": [
    "### 2. Candidate Embedding 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2609c",
   "metadata": {},
   "source": [
    "#### 2-1. Candidate feature 추출  (input_ids, token_type_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "448e6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "can_features = tokenizer(\n",
    "    candidate_list,\n",
    "    max_length=12,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "# list -> torch.tensor로 형변환 \n",
    "can_features = {k: torch.tensor(v) for k, v in can_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2982be03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 21748,  1052,  ...,     0,     0,     0],\n",
       "         [    2, 12235,  4032,  ...,     0,     0,     0],\n",
       "         [    2,  9135,  4057,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    2,  1849,  6687,  ...,     0,     0,     0],\n",
       "         [    2,  2483, 22375,  ...,   248, 11363,     3],\n",
       "         [    2, 26694,  4093,  ...,    17,     3,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 0]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabaf2c",
   "metadata": {},
   "source": [
    "#### 2-2. BERT 모델 전달 "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea4d76f1",
   "metadata": {},
   "source": [
    "model = BertModel.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    config=pretrained_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80cd6b55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "can_outputs = model(**can_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fb0c96c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7649,  0.5689,  0.1016,  ..., -0.5161,  0.9849,  0.3144],\n",
       "         [ 0.8451,  0.7389,  0.1029,  ..., -0.6002, -0.8049, -0.0372],\n",
       "         [ 0.9906,  0.3476, -0.7476,  ...,  0.5393,  0.2272,  0.7750],\n",
       "         ...,\n",
       "         [ 0.6325,  1.2666,  0.3002,  ...,  0.1822,  0.3950, -0.1300],\n",
       "         [ 0.0723,  1.3062,  0.3284,  ...,  1.1223,  0.6953,  0.0620],\n",
       "         [ 0.8450,  1.4619,  0.3135,  ...,  0.8846,  0.8334,  0.0699]],\n",
       "\n",
       "        [[-0.0144,  0.1817,  2.0044,  ..., -0.1886, -1.0998, -0.9490],\n",
       "         [-0.9387, -0.6190,  1.2955,  ...,  1.2500, -1.5786, -0.5666],\n",
       "         [-0.5842, -0.1151,  0.5393,  ...,  1.3651,  0.4317, -0.5529],\n",
       "         ...,\n",
       "         [ 0.6114,  0.4347,  2.2687,  ...,  1.2959, -0.4257, -0.8346],\n",
       "         [-0.7241,  0.7371,  2.2564,  ...,  0.7626, -0.6816, -1.0712],\n",
       "         [ 0.6431,  0.0905,  2.3470,  ...,  1.0541, -0.9329, -1.0942]],\n",
       "\n",
       "        [[ 0.0663, -0.8979,  1.1598,  ...,  0.0529,  0.3811,  0.9280],\n",
       "         [-0.9288, -0.5393,  0.4914,  ..., -0.6593,  0.8537,  0.3696],\n",
       "         [-0.2456,  0.5598,  0.3012,  ..., -0.4037, -0.1205,  0.0317],\n",
       "         ...,\n",
       "         [ 0.1945, -0.4256,  1.5060,  ...,  0.6041,  0.9195, -0.0977],\n",
       "         [ 0.4320, -0.3540,  1.1957,  ...,  0.4490,  1.7543,  0.3418],\n",
       "         [-0.0847,  0.3059,  0.8514,  ...,  1.0575,  0.7323,  0.1138]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.3394, -1.0631,  0.0879,  ..., -0.2889,  0.5747,  0.7868],\n",
       "         [-0.0830,  1.2028, -0.8282,  ..., -0.3506, -1.8250,  1.7632],\n",
       "         [-0.3333, -0.4438,  0.0934,  ...,  1.5969, -0.3216, -0.4645],\n",
       "         ...,\n",
       "         [-0.1911,  0.6678,  0.0114,  ...,  0.6481,  0.9946,  0.8201],\n",
       "         [ 0.2597,  1.2965, -0.0080,  ...,  0.3715,  0.4703,  0.9980],\n",
       "         [ 0.4454,  0.5277,  0.2054,  ...,  0.7373,  1.2296,  0.8218]],\n",
       "\n",
       "        [[-0.9082, -0.4249,  0.3569,  ..., -0.5193,  0.5024,  0.2870],\n",
       "         [-1.2454,  0.1415,  1.3550,  ..., -0.3070,  0.3258, -1.3889],\n",
       "         [-0.7158,  0.8608,  0.2654,  ...,  0.7476,  0.9501, -0.2925],\n",
       "         ...,\n",
       "         [-1.3332, -0.2572,  0.7400,  ...,  0.9413, -2.0312, -0.3709],\n",
       "         [ 0.1552,  0.3408, -0.6876,  ...,  1.0656, -1.4200, -2.2419],\n",
       "         [-1.2221,  0.2763,  1.1338,  ...,  0.8688, -0.9088, -0.5285]],\n",
       "\n",
       "        [[-0.6928, -0.6735,  0.0952,  ...,  0.2815, -0.1821,  1.0504],\n",
       "         [-0.8574, -1.1487, -0.1316,  ..., -0.7869, -1.0963, -0.3476],\n",
       "         [-0.3075,  1.5379,  0.3572,  ...,  0.8090, -0.8345, -0.7594],\n",
       "         ...,\n",
       "         [-0.6946,  0.3604,  0.8113,  ...,  1.1018, -0.1252,  0.1800],\n",
       "         [-0.6942,  0.3560,  0.8079,  ...,  1.1012, -0.1214,  0.1799],\n",
       "         [-0.0056,  0.1583,  1.9063,  ...,  1.9229, -0.8554, -0.4235]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4633c15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11823, 12, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(can_outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30ebf81c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((768,), 11823)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_emb_list = [can_output[0].detach().numpy() for can_output in can_outputs.last_hidden_state]\n",
    "np.shape(cand_emb_list[0]), len(cand_emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db3fd827",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(data_path, 'cand_emb.npy'), cand_emb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52947454",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_emb_list = np.load(os.path.join(data_path, 'cand_emb.npy'))\n",
    "cand_emb_list = torch.Tensor(cand_emb_list).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195c083",
   "metadata": {},
   "source": [
    "### 3. Poly-encoder 내부 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847c986",
   "metadata": {},
   "source": [
    "#### 3-1. 입력 문장에 대한 Key, Value 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33c77433",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctxt = '오늘 조금 우울했어'\n",
    "\n",
    "c_list = [] \n",
    "c_list.append(ctxt)\n",
    "\n",
    "con_features = tokenizer(   # CLS 토큰: input_ids - 2, SEP 토큰: input_ids - 3\n",
    "    c_list,\n",
    "    max_length=12,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "con_features = {k: torch.tensor(v) for k, v in con_features.items()}\n",
    "con_outputs = model(**con_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03f03061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(con_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f514a9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = con_outputs[0].to(device)\n",
    "values = con_outputs[0].to(device)\n",
    "np.shape(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cff1a4",
   "metadata": {},
   "source": [
    "#### 3-2.Code vector 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9188e083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(64, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_poly_codes = 64\n",
    "poly_code_embeddings = nn.Embedding(num_poly_codes, 768)\n",
    "poly_code_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2ae535c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size= con_features['input_ids'].size(0)   # 11823\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81bf6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_code_ids = torch.arange(num_poly_codes, dtype=torch.long)\n",
    "poly_code_ids = poly_code_ids.unsqueeze(0).expand(batch_size, num_poly_codes)\n",
    "poly_codes = poly_code_embeddings(poly_code_ids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1922f576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0028,  1.1321, -1.0948,  ..., -0.1663,  0.1290,  0.7286],\n",
       "         [-0.3181,  0.7342,  2.3381,  ..., -0.8215,  0.9368, -0.2901],\n",
       "         [-0.0865,  1.4424,  1.0132,  ..., -1.3077, -1.2281, -1.5445],\n",
       "         ...,\n",
       "         [ 0.1829, -0.2042,  0.4350,  ..., -1.0578, -1.4291, -0.0060],\n",
       "         [ 0.9348, -0.3873, -1.4193,  ...,  1.4314, -1.0584,  0.5294],\n",
       "         [-0.3095, -0.9734,  1.2445,  ...,  0.8609, -0.2726,  1.0917]]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4027f3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(poly_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570e223",
   "metadata": {},
   "source": [
    "#### 3-3. m 번의 Attention 적용"
   ]
  },
  {
   "cell_type": "raw",
   "id": "084b4530",
   "metadata": {},
   "source": [
    "def dot_attention(query, key, value):\n",
    "    attn = torch.matmul(query, key.transpose(2, 1))\n",
    "    attn = F.softmax(attn, -1)\n",
    "    return torch.matmul(attn, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80a7bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 5.],\n",
       "        [3., 6.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "a.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a271c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_attention(query, key, value):\n",
    "    # start = time.time() \n",
    "    d_k = key.shape[-1]   # 차원 수\n",
    "    attention_score = torch.matmul(query, key.transpose(-2, -1))  # Q x K^T \n",
    "    attention_score = attention_score / math.sqrt(d_k)\n",
    "    attention_prob = F.softmax(attention_score, dim=-1) \n",
    "    out = torch.matmul(attention_prob, value)\n",
    "    # print(f'attention: {round(time.time() - start, 4)}(s)')\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5407063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9511,  1.1084,  0.5343,  ...,  1.1770,  0.6928,  0.4643],\n",
       "         [-0.8440,  1.0626,  0.5704,  ...,  1.0553,  0.6216,  0.4649],\n",
       "         [-0.8834,  0.9825,  0.3839,  ...,  1.0053,  0.7659,  0.3162],\n",
       "         ...,\n",
       "         [-0.9909,  1.1230,  0.5928,  ...,  1.1719,  0.5845,  0.5288],\n",
       "         [-0.9373,  1.0452,  0.4642,  ...,  1.2145,  0.6493,  0.3140],\n",
       "         [-0.8185,  1.0068,  0.4836,  ...,  1.0503,  0.5845,  0.3462]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = dot_attention(poly_codes, keys, values)   #  shape of context: [1, 64, 768]\n",
    "\n",
    "print(np.shape(contexts))\n",
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a13f407a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9511,  1.1084,  0.5343,  ...,  1.1770,  0.6928,  0.4643],\n",
       "         [-0.8440,  1.0626,  0.5704,  ...,  1.0553,  0.6216,  0.4649],\n",
       "         [-0.8834,  0.9825,  0.3839,  ...,  1.0053,  0.7659,  0.3162],\n",
       "         ...,\n",
       "         [-0.9909,  1.1230,  0.5928,  ...,  1.1719,  0.5845,  0.5288],\n",
       "         [-0.9373,  1.0452,  0.4642,  ...,  1.2145,  0.6493,  0.3140],\n",
       "         [-0.8185,  1.0068,  0.4836,  ...,  1.0503,  0.5845,  0.3462]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts = dot_attention(poly_codes, keys, values)   #  shape of context: [1, 64, 768]\n",
    "\n",
    "print(np.shape(contexts))\n",
    "contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94061a",
   "metadata": {},
   "source": [
    "#### 3-4. 점수 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f823ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(contexts, responses):\n",
    "    contexts = dot_attention(responses, contexts, contexts)\n",
    "    # print(np.shape(contexts[2]))\n",
    "    # print(np.shape(responses))\n",
    "    score = (contexts * responses).sum(-1)\n",
    "    return int(score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6646175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 768])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_emb = dot_attention(cand_emb_list[0], contexts, contexts)\n",
    "np.shape(con_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b560ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(con_emb[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e482422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(con_emb, cand_emb_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7bf25",
   "metadata": {},
   "source": [
    "### 4. Poly-encoder 데모"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ab58f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly_code(num_poly_codes):\n",
    "    poly_code_embeddings = nn.Embedding(num_poly_codes, 768)\n",
    "    poly_code_ids = torch.arange(num_poly_codes, dtype=torch.long)\n",
    "    poly_code_ids = poly_code_ids.unsqueeze(0).expand(batch_size, num_poly_codes)\n",
    "    poly_codes = poly_code_embeddings(poly_code_ids).to(device)\n",
    "    \n",
    "    return poly_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cfac766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_poly(ctxt):\n",
    "    '''\n",
    "    ctxt을 입력으로 받아 가장 높은 score를 보이는 후보 답변 반환 \n",
    "    '''\n",
    "    start = time.time()\n",
    "    c_list = [] \n",
    "    c_list.append(ctxt)\n",
    "    num_poly_codes = 64\n",
    "    \n",
    "    con_features = tokenizer(   # CLS 토큰: input_ids - 2, SEP 토큰: input_ids - 3\n",
    "        c_list,\n",
    "        max_length=12,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    con_features = {k: torch.tensor(v) for k, v in con_features.items()}\n",
    "    con_outputs = model(**con_features)\n",
    "    batch_size= con_features['input_ids'].size(0)   # 1\n",
    "    poly_codes = get_poly_code(num_poly_codes)\n",
    "    print(f'소요 시간: {round(time.time() - start, 2)}(s)')\n",
    "    \n",
    "    keys = con_outputs[0].to(device); values = con_outputs[0].to(device)\n",
    "    contexts = dot_attention(poly_codes, keys, values)\n",
    "    \n",
    "    print(f'소요 시간2: {round(time.time() - start, 2)}(s)')\n",
    "    \n",
    "    # contexts = contexts.detach().numpy()\n",
    "    print(np.shape(contexts))\n",
    "    score = []\n",
    "    for can_emb in cand_emb_list:\n",
    "        con_emb = dot_attention(can_emb, contexts, contexts)\n",
    "        con_emb = con_emb.cpu().detach().numpy()\n",
    "        can_emb = can_emb.cpu().detach().numpy()\n",
    "        score.append(np.dot(con_emb, can_emb))\n",
    "        \n",
    "    print(f'소요 시간3: {round(time.time() - start, 2)}(s)')\n",
    "    return candidate_list[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fdec4125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Poly-encoder 구현 ====== \n",
      "입력 문장: 오늘 날씨 어때 ?\n",
      "소요 시간: 0.03(s)\n",
      "소요 시간2: 0.03(s)\n",
      "torch.Size([1, 64, 768])\n",
      "소요 시간3: 2.3(s)\n",
      "챗봇 대답: 오늘 미세먼지가 많데요.\n",
      "소요 시간: 2.31(s), len(candidate): 11823\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "context = '오늘 날씨 어때 ?'\n",
    "\n",
    "start = time.time()\n",
    "print(f'===== Poly-encoder 구현 ====== ') \n",
    "print(f'입력 문장: {context}')\n",
    "print(f'챗봇 대답: {get_answer_poly(context)}')\n",
    "print(f'소요 시간: {round(time.time() - start, 2)}(s), len(candidate): {len(candidate_list)}')\n",
    "print(f'==============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f106724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
