{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2f139a",
   "metadata": {},
   "source": [
    "### 0. Environment Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a1d1",
   "metadata": {},
   "source": [
    "#### 1) Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dd9d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pymysql\n",
    "import os \n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad2463",
   "metadata": {},
   "source": [
    "#### 2) MySQL Connect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e64925d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='localhost', user='lamda_00', password='lamda95', db='chatbot', charset='utf8')\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e526f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql):\n",
    "    curs.execute(sql)\n",
    "    \n",
    "    return curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7cf769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('context_df',),\n",
       " ('intensity_df',),\n",
       " ('polarity_df',),\n",
       " ('response_df',),\n",
       " ('wellness_df',))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'SHOW TABLES;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f55c8",
   "metadata": {},
   "source": [
    "#### 3) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f581b537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('idx', 'int(11)', 'NO', 'PRI', None, ''),\n",
       " ('intent', 'varchar(100)', 'NO', '', None, ''),\n",
       " ('keyword', 'varchar(100)', 'NO', '', None, ''),\n",
       " ('utterance', 'varchar(1000)', 'NO', '', None, ''),\n",
       " ('intent_label', 'int(11)', 'NO', '', None, ''),\n",
       " ('intent_keyword', 'varchar(100)', 'NO', '', None, ''),\n",
       " ('ik_label', 'int(11)', 'NO', '', None, ''))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'DESC wellness_df;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82c162e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('idx', 'int(11)', 'NO', 'PRI', None, ''),\n",
       " ('Question', 'varchar(1000)', 'NO', '', None, ''),\n",
       " ('Answer', 'varchar(1000)', 'NO', '', None, ''))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'DESC response_df;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd8523af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('12시 땡!', '하루가 또 가네요.'),\n",
       " ('1지망 학교 떨어졌어', '위로해 드립니다.'),\n",
       " ('3박4일 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
       " ('3박4일 정도 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
       " ('PPL 심하네', '눈살이 찌푸려지죠.'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'SELECT Question, Answer FROM response_df;'\n",
    "\n",
    "data = execute_sql(sql)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645f9085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list = list(map(lambda x: x[0], data))\n",
    "candidate_list = list(map(lambda x: x[1], data))\n",
    "\n",
    "candidate_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32ab22",
   "metadata": {},
   "source": [
    "#### 4) Stop MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbf8f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71fe3a1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4d960",
   "metadata": {},
   "source": [
    "### 1. Pretrained tokenizer, model load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aff5263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5523c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    do_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85a9931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    \"beomi/kcbert-base\"\n",
    ")\n",
    "\n",
    "model = BertModel.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    config=pretrained_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcaba6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPU\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c75a12",
   "metadata": {},
   "source": [
    "### 2. Candidate Embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b2c9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_emb_list = np.load(os.path.join(data_path, 'cand_emb.npy'))\n",
    "cand_emb_list = torch.Tensor(cand_emb_list).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecafdb4c",
   "metadata": {},
   "source": [
    "### 3. Bi-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2142ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_bi(ctxt):\n",
    "    '''\n",
    "    ctxt을 입력으로 받아 가장 높은 score를 보이는 후보 답변 반환 \n",
    "    '''\n",
    "    \n",
    "    c_list = [] \n",
    "    c_list.append(ctxt)\n",
    "    \n",
    "    con_features = tokenizer(   # CLS 토큰: input_ids - 2, SEP 토큰: input_ids - 3\n",
    "        c_list,\n",
    "        max_length=12,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    con_features = {k: torch.tensor(v).to(device) for k, v in con_features.items()}\n",
    "    con_features = con_features\n",
    "    con_outputs = model(**con_features)\n",
    "    ctxt_emb = con_outputs.last_hidden_state[0][0].cpu().detach().numpy()\n",
    "    \n",
    "    score = []\n",
    "    for cand_emb in cand_emb_list:\n",
    "        cand_emb = cand_emb.cpu().detach().numpy()\n",
    "        score.append(np.dot(ctxt_emb, cand_emb))\n",
    "    \n",
    "    return candidate_list[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb4f66cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Bi-encoder 구현 ====== \n",
      "입력 문장: 가족들이랑 서먹해\n",
      "챗봇 대답: 마음이랑 잘 인사해요.\n",
      "소요 시간: 0.24(s), len(candidate): 11823\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "context = context_list[30]\n",
    "\n",
    "start = time.time()\n",
    "print(f'===== Bi-encoder 구현 ====== ') \n",
    "print(f'입력 문장: {context}')\n",
    "print(f'챗봇 대답: {get_answer_bi(context)}')\n",
    "print(f'소요 시간: {round(time.time() - start, 2)}(s), len(candidate): {len(candidate_list)}')\n",
    "print(f'==============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f406ba2",
   "metadata": {},
   "source": [
    "### 4. Cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "564c9a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder('beomi/kcbert-base', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e50a52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_cross(ctxt):\n",
    "    '''\n",
    "    ctxt을 입력으로 받아 가장 높은 score를 보이는 후보 답변 반환 \n",
    "    '''\n",
    "    sentence_combinations = [[ctxt, candidate] for candidate in candidate_list]\n",
    "    similarity_scores = cross_encoder.predict(sentence_combinations)\n",
    "    return candidate_list[np.argmax(similarity_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02b7be51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Cross-encoder 구현 =====\n",
      "입력 문장: 가족들이랑 서먹해\n",
      "챗봇 대답: 당신은 정말 멋진 사람이에요. 깍아 내리지 마세요.\n",
      "소요 시간: 4.35(s), len(candidate): 11823\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "context = context_list[30]\n",
    "\n",
    "start = time.time()\n",
    "print('===== Cross-encoder 구현 =====')\n",
    "print(f'입력 문장: {context}')\n",
    "print(f'챗봇 대답: {get_answer_cross(context)}')\n",
    "print(f'소요 시간: {round(time.time() - start, 2)}(s), len(candidate): {len(candidate_list)}')\n",
    "print(f'==============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8121a",
   "metadata": {},
   "source": [
    "### 5. Poly-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52f89b39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'con_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m con_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'con_features' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = con_features['input_ids'].size(0)   # 11823"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18abb7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly_code(batch_size, num_poly_codes):\n",
    "    poly_code_embeddings = nn.Embedding(num_poly_codes, 768)\n",
    "    poly_code_ids = torch.arange(num_poly_codes, dtype=torch.long)\n",
    "    poly_code_ids = poly_code_ids.unsqueeze(0).expand(batch_size, num_poly_codes)\n",
    "    poly_codes = poly_code_embeddings(poly_code_ids).to(device)\n",
    "    \n",
    "    return poly_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55d6df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_attention(query, key, value):\n",
    "    # start = time.time() \n",
    "    d_k = key.shape[-1]   # 차원 수\n",
    "    attention_score = torch.matmul(query, key.transpose(-2, -1))  # Q x K^T \n",
    "    attention_score = attention_score / math.sqrt(d_k)\n",
    "    attention_prob = F.softmax(attention_score, dim=-1) \n",
    "    out = torch.matmul(attention_prob, value)\n",
    "    # print(f'attention: {round(time.time() - start, 4)}(s)')\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4fde2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(contexts, responses):\n",
    "    contexts = dot_attention(responses, contexts, contexts)\n",
    "    # print(np.shape(contexts[2]))\n",
    "    # print(np.shape(responses))\n",
    "    score = (contexts * responses).sum(-1)\n",
    "    return int(score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b40c6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_poly(ctxt):\n",
    "    '''\n",
    "    ctxt을 입력으로 받아 가장 높은 score를 보이는 후보 답변 반환 \n",
    "    '''\n",
    "    start = time.time()\n",
    "    c_list = [] \n",
    "    c_list.append(ctxt)\n",
    "    num_poly_codes = 64\n",
    "    \n",
    "    con_features = tokenizer(   # CLS 토큰: input_ids - 2, SEP 토큰: input_ids - 3\n",
    "        c_list,\n",
    "        max_length=12,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    con_features = {k: torch.tensor(v).to(device) for k, v in con_features.items()}\n",
    "    con_outputs = model(**con_features)\n",
    "    batch_size= con_features['input_ids'].size(0)   # 1\n",
    "    poly_codes = get_poly_code(batch_size, num_poly_codes)\n",
    "    print(f'소요 시간: {round(time.time() - start, 2)}(s)')\n",
    "    \n",
    "    keys = con_outputs[0].to(device); values = con_outputs[0].to(device)\n",
    "    contexts = dot_attention(poly_codes, keys, values)\n",
    "    \n",
    "    print(f'소요 시간2: {round(time.time() - start, 2)}(s)')\n",
    "    \n",
    "    # contexts = contexts.detach().numpy()\n",
    "    print(np.shape(contexts))\n",
    "    score = []\n",
    "    for can_emb in cand_emb_list:\n",
    "        con_emb = dot_attention(can_emb, contexts, contexts)\n",
    "        con_emb = con_emb.cpu().detach().numpy()\n",
    "        can_emb = can_emb.cpu().detach().numpy()\n",
    "        score.append(np.dot(con_emb, can_emb))\n",
    "        \n",
    "    print(f'소요 시간3: {round(time.time() - start, 2)}(s)')\n",
    "    return candidate_list[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7514daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Poly-encoder 구현 ====== \n",
      "입력 문장: 오늘 날씨 어때 ?\n",
      "소요 시간: 0.01(s)\n",
      "소요 시간2: 0.01(s)\n",
      "torch.Size([1, 64, 768])\n",
      "소요 시간3: 2.44(s)\n",
      "챗봇 대답: 오늘 미세먼지가 많데요.\n",
      "소요 시간: 2.45(s), len(candidate): 11823\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "context = '오늘 날씨 어때 ?'\n",
    "\n",
    "start = time.time()\n",
    "print(f'===== Poly-encoder 구현 ====== ') \n",
    "print(f'입력 문장: {context}')\n",
    "print(f'챗봇 대답: {get_answer_poly(context)}')\n",
    "print(f'소요 시간: {round(time.time() - start, 2)}(s), len(candidate): {len(candidate_list)}')\n",
    "print(f'==============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453fb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26aa3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
