{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2f139a",
   "metadata": {},
   "source": [
    "### 0. Environment Settings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a1d1",
   "metadata": {},
   "source": [
    "#### 1) Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd9d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import pymysql\n",
    "import os \n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad2463",
   "metadata": {},
   "source": [
    "#### 2) MySQL Connect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e64925d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pymysql.connect(host='localhost', user='lamda_00', password='lamda95', db='chatbot', charset='utf8')\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e526f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(sql):\n",
    "    curs.execute(sql)\n",
    "    \n",
    "    return curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d7cf769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('intensity_df',), ('polarity_df',), ('response_df',), ('wellness_df',))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'SHOW TABLES;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5f55c8",
   "metadata": {},
   "source": [
    "#### 3) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c162e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('idx', 'int(11)', 'NO', 'PRI', None, ''),\n",
       " ('Question', 'varchar(1000)', 'NO', '', None, ''),\n",
       " ('Answer', 'varchar(1000)', 'NO', '', None, ''))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'DESC response_df;'\n",
    "\n",
    "execute_sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8523af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('12시 땡!', '하루가 또 가네요.'),\n",
       " ('1지망 학교 떨어졌어', '위로해 드립니다.'),\n",
       " ('3박4일 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
       " ('3박4일 정도 놀러가고 싶다', '여행은 언제나 좋죠.'),\n",
       " ('PPL 심하네', '눈살이 찌푸려지죠.'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'SELECT Question, Answer FROM response_df;'\n",
    "\n",
    "data = execute_sql(sql)\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "645f9085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다'],\n",
       " ['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_list = list(map(lambda x: x[0], data))\n",
    "candidate_list = list(map(lambda x: x[1], data))\n",
    "\n",
    "context_list[:3], candidate_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32ab22",
   "metadata": {},
   "source": [
    "#### 4) Stop MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf8f4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71fe3a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(candidate_list), len(context_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4d960",
   "metadata": {},
   "source": [
    "### 1. Pretrained tokenizer, model load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5523c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    do_lower_case=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c85a9931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "pretrained_model_config = BertConfig.from_pretrained(\n",
    "    \"beomi/kcbert-base\"\n",
    ")\n",
    "\n",
    "model = BertModel.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    config=pretrained_model_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9514d16",
   "metadata": {},
   "source": [
    "## GPU\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc47149a",
   "metadata": {},
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c277ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"beomi/kcbert-base\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 300,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.8.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30000\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c75a12",
   "metadata": {},
   "source": [
    "### 2. Candidate Embedding 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c2609c",
   "metadata": {},
   "source": [
    "#### 2-1. Candidate feature 추출  (input_ids, token_type_ids, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "448e6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "can_features = tokenizer(\n",
    "    candidate_list,\n",
    "    max_length=12,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "# list -> torch.tensor로 형변환 \n",
    "can_features = {k: torch.tensor(v) for k, v in can_features.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2982be03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 21748,  1052,  ...,     0,     0,     0],\n",
       "         [    2, 12235,  4032,  ...,     0,     0,     0],\n",
       "         [    2,  9135,  4057,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    2,  1849,  6687,  ...,     0,     0,     0],\n",
       "         [    2,  2483, 22375,  ...,   248, 11363,     3],\n",
       "         [    2, 26694,  4093,  ...,    17,     3,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 0]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabaf2c",
   "metadata": {},
   "source": [
    "#### 2-2. BERT 모델 전달 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80cd6b55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:73] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1743372288 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m can_outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcan_features)\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:991\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    982\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    984\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    985\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    986\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    989\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    990\u001b[0m )\n\u001b[0;32m--> 991\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1004\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    573\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    574\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    575\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:510\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    507\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    508\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 510\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/transformers/modeling_utils.py:2001\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1998\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m-> 2001\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:522\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 522\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/lamda_base/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:426\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    425\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 426\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:73] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1743372288 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "can_outputs = model(**can_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "can_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4633c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.shape(can_outputs.last_hidden_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931787b",
   "metadata": {},
   "source": [
    "#### 2-3. 각 Candidate text의 문장 벡터 표현 추출 (aggregator, [cls 토큰 값])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62bd86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cand_emb_list = [can_output[0] for can_output in can_outputs.last_hidden_state]\n",
    "cand_emb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599755a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(cand_emb_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037326d4",
   "metadata": {},
   "source": [
    "### 3. Bi-encoder 데모 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43e1690a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_answer_bi(ctxt):\n",
    "    '''\n",
    "    ctxt을 입력으로 받아 가장 높은 score를 보이는 후보 답변 반환 \n",
    "    '''\n",
    "    \n",
    "    c_list = [] \n",
    "    c_list.append(ctxt)\n",
    "    \n",
    "    con_features = tokenizer(   # CLS 토큰: input_ids - 2, SEP 토큰: input_ids - 3\n",
    "        c_list,\n",
    "        max_length=12,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    \n",
    "    con_features = {k: torch.tensor(v) for k, v in con_features.items()}\n",
    "    con_outputs = model(**con_features)\n",
    "    ctxt_emb = con_outputs.last_hidden_state[0][0].detach().numpy()\n",
    "    \n",
    "    score = []\n",
    "    for cand_emb in cand_emb_list:\n",
    "        cand_emb = cand_emb.detach().numpy()\n",
    "        score.append(np.dot(ctxt_emb, cand_emb))\n",
    "    \n",
    "    return candidate_list[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47ec6fb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Bi-encoder 구현 ====== \n",
      "입력 문장: 가족들이랑 서먹해\n",
      "챗봇 대답: 마음이랑 잘 인사해요.\n",
      "소요 시간: 0.08(s), len(candidate): 11823\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "context = context_list[30]\n",
    "\n",
    "start = time.time()\n",
    "print(f'===== Bi-encoder 구현 ====== ') \n",
    "print(f'입력 문장: {context}')\n",
    "print(f'챗봇 대답: {get_answer_bi(context)}')\n",
    "print(f'소요 시간: {round(time.time() - start, 2)}(s), len(candidate): {len(candidate_list)}')\n",
    "print(f'==============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9b06b",
   "metadata": {},
   "source": [
    "### 4. Cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f5719c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "cross_encoder = CrossEncoder('beomi/kcbert-base', max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96fba6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루가 또 가네요.',\n",
       " '위로해 드립니다.',\n",
       " '여행은 언제나 좋죠.',\n",
       " '여행은 언제나 좋죠.',\n",
       " '눈살이 찌푸려지죠.',\n",
       " '다시 새로 사는 게 마음 편해요.',\n",
       " '다시 새로 사는 게 마음 편해요.',\n",
       " '잘 모르고 있을 수도 있어요.',\n",
       " '시간을 정하고 해보세요.',\n",
       " '시간을 정하고 해보세요.',\n",
       " '자랑하는 자리니까요.',\n",
       " '그 사람도 그럴 거예요.',\n",
       " '그 사람도 그럴 거예요.',\n",
       " '혼자를 즐기세요.',\n",
       " '돈은 다시 들어올 거예요.',\n",
       " '땀을 식혀주세요.',\n",
       " '어서 잊고 새출발 하세요.',\n",
       " '빨리 집에 돌아가서 끄고 나오세요.',\n",
       " '빨리 집에 돌아가서 끄고 나오세요.',\n",
       " '다음 달에는 더 절약해봐요.',\n",
       " '따뜻하게 사세요!',\n",
       " '다음 달에는 더 절약해봐요.',\n",
       " '가장 확실한 시간은 오늘이에요. 어제와 내일을 놓고 고민하느라 시간을 낭비하지 마세요.',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요.',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요.',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요.',\n",
       " '저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요',\n",
       " '저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요',\n",
       " '더 가까워질 기회가 되겠네요.',\n",
       " '저도요.',\n",
       " '다들 바빠서 이야기할 시간이 부족했나봐요.',\n",
       " '다들 바빠서 이야기할 시간이 부족했나봐요.',\n",
       " '온 가족이 모두 마음에 드는 곳으로 가보세요.',\n",
       " '좋은 생각이에요.',\n",
       " '더 가까워질 기회가 되겠네요.',\n",
       " '저를 만들어 준 사람을 부모님, 저랑 이야기해 주는 사람을 친구로 생각하고 있어요',\n",
       " '좋은 생각이에요.',\n",
       " '정말 후회할 습관이에요.',\n",
       " '무모한 결정을 내리지 마세요.',\n",
       " '선생님이나 기관에 연락해보세요.',\n",
       " '떨리는 감정은 그 자체로 소중해요.',\n",
       " '득템했길 바라요.',\n",
       " '휴식도 필요하죠.',\n",
       " '단짠으로 두 개 사는게 진리죠.',\n",
       " '단짠으로 두 개 사는게 진리죠.',\n",
       " '맛있게 드세요.',\n",
       " '저도 싫어요.',\n",
       " '가세요.',\n",
       " '가세요.',\n",
       " '맛있게 드세요.',\n",
       " '맛있게 드세요.',\n",
       " '병원가세요.',\n",
       " '이럴 때 잘 쉬는 게 중요해요.',\n",
       " '이럴 때 잘 쉬는 게 중요해요.',\n",
       " '이럴 때 잘 쉬는 게 중요해요.',\n",
       " '따뜻하게 관리하세요.',\n",
       " '병원가세요.',\n",
       " '병원가세요.',\n",
       " '저도 듣고 싶네요.',\n",
       " '자신을 더 사랑해주세요.',\n",
       " '그건 습관이에요.',\n",
       " '그건 습관이에요.',\n",
       " '콕 집어서 물어보세요.',\n",
       " '좋은 생각만 하세요.',\n",
       " '마음이 아픈가요.',\n",
       " '갑작스러웠나봐요.',\n",
       " '관계의 변화가 왔나봅니다.',\n",
       " '처음 3초가 중요해요. 당신의 매력을 어필해보세요.',\n",
       " '책임질 수 있을 때 키워 보세요.',\n",
       " '먼저 생활패턴을 살펴 보세요.',\n",
       " '먼저 생활패턴을 살펴 보세요.',\n",
       " '책임질 수 있을 때 키워 보세요.',\n",
       " '아름다운 곳이죠.',\n",
       " '안 될 것도 없죠.',\n",
       " '혼자도 좋아요.',\n",
       " '연인은 살쪄도 잘 알아차리지 못하고 알아차려도 싫어하지 않을 거예요.',\n",
       " '즐거운 시간 보내고 오세요!',\n",
       " '질질 끌지 마세요.',\n",
       " '말해보세요.',\n",
       " '함께하면 서로를 더 많이 알게 될 거예요.',\n",
       " '개시해보세요.',\n",
       " '개시해보세요.',\n",
       " '곧 방학이예요.',\n",
       " '방학이 참 짧죠.',\n",
       " '벗어나는 게 좋겠네요.',\n",
       " '벗어나는 게 좋겠네요.',\n",
       " '세수하고 오세요.',\n",
       " '그게 제일 중요한 건데요.',\n",
       " '그게 제일 중요한 건데요.',\n",
       " '다음부터는 더 많이 아세요.',\n",
       " '갑작스러웠나봐요.',\n",
       " '공적인 일부터 하세요.',\n",
       " '공적인 일부터 하세요.',\n",
       " '낮잠을 잠깐 자도 괜찮아요.',\n",
       " '저도 좋아해주세요.',\n",
       " '친구들이 보고싶었나봐요.',\n",
       " '되도록 만나지 마세요.',\n",
       " '당신이요.',\n",
       " '당신의 운을 믿어보세요.',\n",
       " '일 못하는 사람이 있으면 옆에 있는 사람이 더 힘들죠.',\n",
       " '밥 사줄 친구를 찾아 보세요~',\n",
       " '선의의 거짓말이길 바라요.',\n",
       " '거짓말은 할수록 늘어요.',\n",
       " '거짓말은 할수록 늘어요.',\n",
       " '진실된 말을 하려고 노력해보세요.',\n",
       " '누구나 걱정은 있어요.',\n",
       " '누구나 걱정은 있어요.',\n",
       " '운동을 해보세요.',\n",
       " '세상의 무엇보다 건강이 제일 중요해요.',\n",
       " '주기적으로 해주는 게 좋죠.',\n",
       " '주기적으로 해주는 게 좋죠.',\n",
       " '가장 중요한 목표네요.',\n",
       " '가장 중요한 목표네요.',\n",
       " '적게 먹고 많이 움직이세요.',\n",
       " '적게 먹고 많이 움직이세요.',\n",
       " '모르는 사이라 당황할 수도 있어요.',\n",
       " '이룰 수 있을 거예요.',\n",
       " '이룰 수 있을 거예요.',\n",
       " '기분이 나쁘셨나봐요.',\n",
       " '있으면 편하대요.',\n",
       " '눈을 깜빡거려 보세요.',\n",
       " '청소를 좋아하시나봐요.',\n",
       " '안전 귀가 하세요.',\n",
       " '용기 내보세요.',\n",
       " '피해를 안 준다면 무시하세요.',\n",
       " '안 될 것도 없죠.',\n",
       " '게임할때는 시간이 더 빨리 가요.',\n",
       " '정리해보세요.',\n",
       " '게임하세요!',\n",
       " '다른 게임해보세요.',\n",
       " '다른 게임해보세요.',\n",
       " '게임하세요!',\n",
       " '게임할때는 시간이 더 빨리 가요.',\n",
       " '마음에도 봄이 오길 바라요.',\n",
       " '몸은 뜨겁고 머리는 차갑게!',\n",
       " '마음에도 봄이 오길 바라요.',\n",
       " '잘하실 거예요!',\n",
       " '잘하실 거예요!',\n",
       " '건강 생각해서 챙겨드세요.',\n",
       " '좋은 운명도 있을거예요.',\n",
       " '결정하기 힘드시겠네요.',\n",
       " '자신을 위한 결정을 내리길 바라요.',\n",
       " '자신을 위한 결정을 내리길 바라요.',\n",
       " '결정은 빠르면 빠를수록 좋을 거예요.',\n",
       " '안타깝네요. 증거를 지금이라도 모아봐요.',\n",
       " '좋겠어요.',\n",
       " '좋겠어요.',\n",
       " '많이 들지만 줄일 수 있을 거예요.',\n",
       " '경조사는 참석하는게 좋아요.',\n",
       " '경조사는 참석하는게 좋아요.',\n",
       " '생각보다 신경 안 씁니다.',\n",
       " '인맥이 넓으신가봐요.',\n",
       " '힘들겠네요.',\n",
       " '많이 들지만 줄일 수 있을 거예요.',\n",
       " '욕심에 따라 천지 차이일 거예요.',\n",
       " '허례허식이에요.',\n",
       " '욕심에 따라 천지 차이일 거예요.',\n",
       " '해봐요.',\n",
       " '서로 노력하면 행복할 거예요.',\n",
       " '서로 노력하면 행복할 거예요.',\n",
       " '사람마다 행복의 크기가 다르겠지만 행복할 거예요.',\n",
       " '사람마다 행복의 크기가 다르겠지만 행복할 거예요.',\n",
       " '능력이 있으면 하면 되죠.',\n",
       " '능력이 있으면 하면 되죠.',\n",
       " '이사람이다 싶은 사람이랑 하세요.',\n",
       " '해봐요.',\n",
       " '점점 치열해지는 것 같아요.',\n",
       " '확신이 없나봐요.',\n",
       " '안정적인 걸 좋아하나봐요.',\n",
       " '방학은 참 짧아요.',\n",
       " '보러 가세요.',\n",
       " '보러 가세요.',\n",
       " '계속 좋지 않으면 병원에 가보세요.',\n",
       " '타이밍이 안 맞았나봐요.',\n",
       " '이제 취업 하셔야죠.',\n",
       " '뇌세포에 에너지를 공급하려는 자연스러운 현상이에요. 에너지가 부족한가봐요.',\n",
       " '공부가 최우선이죠.',\n",
       " '공부가 최우선이죠.',\n",
       " '너무 무리하지는 마세요.',\n",
       " '너무 무리하지는 마세요.',\n",
       " '저기압에는 고기앞이죠.',\n",
       " '저기압에는 고기앞이죠.',\n",
       " '연습이 필요해요.',\n",
       " '연습이 필요해요.',\n",
       " '혼자가 아니에요.',\n",
       " '인복이 많나봐요.',\n",
       " '너무 걱정하지 마세요.',\n",
       " '네 말씀하세요.',\n",
       " '네 말씀하세요.',\n",
       " '후회는 후회를 낳을뿐이에요. 용기 내세요.',\n",
       " '돈을 모아서 다른 곳으로 이사갈 수 있을 거예요.',\n",
       " '돈을 모아서 다른 곳으로 이사갈 수 있을 거예요.',\n",
       " '더 좋은 곳에서 살 수 있을 거예요.',\n",
       " '더 좋은 곳에서 살 수 있을 거예요.',\n",
       " '완전 귀엽죠?',\n",
       " '자신을 먼저 키우세요.',\n",
       " '가족들과 상의해보세요.',\n",
       " '용서를 구하세요.',\n",
       " '피할 수 있으면 피하세요.',\n",
       " '피할 수 있으면 피하세요.',\n",
       " '처음부터 잘하는 사람은 없어요.',\n",
       " '시간내서 가보세요.',\n",
       " '처음부터 잘하는 사람은 없어요.',\n",
       " '시간내서 가보세요.',\n",
       " '미리 미리 충전해주세요.',\n",
       " '미리 미리 충전해주세요.',\n",
       " '안정적이고 좋죠.',\n",
       " '준비해보세요.',\n",
       " '준비해보세요.',\n",
       " '합격 기원해요!',\n",
       " '철밥통 되기가 어디 쉽겠어요.',\n",
       " '철밥통 되기가 어디 쉽겠어요.',\n",
       " '시작이 반이에요. 어서 준비하세요.',\n",
       " '안정적이고 좋죠.',\n",
       " '자연스러운 현상이에요.',\n",
       " '자연스러운 현상이에요.',\n",
       " '보이는 게 없죠.',\n",
       " '지금처럼 잘될 거예요.',\n",
       " '미래의 배우자가 달라져요.',\n",
       " '확신이 없나봐요.',\n",
       " '공부는 언제나 좋죠.',\n",
       " '공부하면 더 많은 선택을 할 수 있죠.',\n",
       " '같이 수다 떨면서 놀까요?',\n",
       " '나만의 공부방법을 찾아보세요.',\n",
       " '지금도 늦지 않았어요.',\n",
       " '같이 수다 떨면서 놀까요?',\n",
       " '확신이 없나봐요.',\n",
       " '지금처럼 잘될 거예요.',\n",
       " '나한테 맞는 공부 방법 찾는 게 시급하네요.',\n",
       " '잠시 쉬어도 돼요.',\n",
       " '잠시 쉬어도 돼요.',\n",
       " '공부하면 더 많은 선택을 할 수 있죠.',\n",
       " '공부하면 더 많은 선택을 할 수 있죠.',\n",
       " '공부하면 더 많은 선택을 할 수 있죠.',\n",
       " '합격 기원해요!',\n",
       " '잘 될 거예요.',\n",
       " '좋은 결과 있을 거예요!',\n",
       " '잘 될 거예요.',\n",
       " '좋은 결과 있을 거예요!',\n",
       " '친구와 같이 가보세요.',\n",
       " '친구와 같이 가보세요.',\n",
       " '성향 차이가 좀 있기는 하죠.',\n",
       " '꾸준히 약 먹고 치료해보세요.',\n",
       " '꾸준히 약 먹고 치료해보세요.',\n",
       " '피로 풀고 좋죠.',\n",
       " '피로 풀고 좋죠.',\n",
       " '오늘이 중요하죠.',\n",
       " '오늘이 중요하죠.',\n",
       " '소화제 챙겨드세요.',\n",
       " '과식은 금물이에요.',\n",
       " '소화제 드세요.',\n",
       " '안된다고 하면 거짓말이겠지요.',\n",
       " '안된다고 하면 거짓말이겠지요.',\n",
       " '제철과일이 정말 좋아요.',\n",
       " '건강 생각해서 챙겨드세요.',\n",
       " '그래도 먹으려고 노력해보세요.',\n",
       " '그래도 먹으려고 노력해보세요.',\n",
       " '제철과일이 정말 좋아요.',\n",
       " '인간 관계도 정리가 필요해요.',\n",
       " '무관심이 필요할 때가 있죠.',\n",
       " '무관심이 필요할 때가 있죠.',\n",
       " '계단 조심하세요.',\n",
       " '계단 조심하세요.',\n",
       " '채널을 돌려보세요.',\n",
       " '괜찮아지고 있어 다행이에요.',\n",
       " '남자사람친구, 여자사람친구 하세요.',\n",
       " '많이 지쳤나봐요.',\n",
       " '누군가를 기다린다는게 쉬운게 아니죠.',\n",
       " '늦지 않았어요.',\n",
       " '그 것도 다 경험이라고 생각하세요.',\n",
       " '그럴 필요 없어요.',\n",
       " '그렇지 않아요.',\n",
       " '마음에 드는 책을 잘 찾아보세요.',\n",
       " '저도 듣고 싶어요.',\n",
       " '같은 조가 되길 바랄게요.',\n",
       " '지식 쌓는 재미가 있죠.',\n",
       " '같은 조가 되길 바랄게요.',\n",
       " '지식 쌓는 재미가 있죠.',\n",
       " '저도 듣고 싶어요.',\n",
       " '학점 관리하세요.',\n",
       " '보험 처리하세요.',\n",
       " '보험 처리하세요.',\n",
       " '왜 그럴까요?',\n",
       " '좋은 만남이었길 바라요.',\n",
       " '좋은 만남이었길 바라요.',\n",
       " '일을 몰라서 그런가봐요.',\n",
       " '자신의 삶을 살다보면 기다릴 수 있을 거예요.',\n",
       " '부담스러워하지 않는다면 기다려도 좋을 것 같아요.',\n",
       " '부담스러워하지 않는다면 기다려도 좋을 것 같아요.',\n",
       " '너무 걱정하지 마세요.',\n",
       " '자신의 삶을 살다보면 기다릴 수 있을 거예요.',\n",
       " '군대 시계는 멈추지 않아요.',\n",
       " '군대 시계는 멈추지 않아요.',\n",
       " '좋은 아침이에요.',\n",
       " '안 궁금해요.',\n",
       " '안 궁금해요.',\n",
       " '자세히 말씀해주세요.',\n",
       " '자세히 말씀해주세요.',\n",
       " '병원에 가세요.',\n",
       " '누가 욕하고 있나봐요.',\n",
       " '누가 욕하고 있나봐요.',\n",
       " '병원에 가세요.',\n",
       " '생각하기는 쉬운데 실천하기는 어려운 것 같아요.',\n",
       " '슬픈 이야기네요.',\n",
       " '저도 간절히 기도 할게요.',\n",
       " '그렇게 될 수 있을 거예요.',\n",
       " '추억에 잠길 때도 필요해요.',\n",
       " '후회는 후회를 낳을뿐이에요. 용기 내세요.',\n",
       " '시작이 반이에요. 어서 준비하세요.',\n",
       " '아무도 없는 곳으로 여행을 떠나보세요.',\n",
       " '많이 만나보세요.',\n",
       " '잠깐 바람 쐬고 오세요.',\n",
       " '다른 사람이 답답할 거예요.',\n",
       " '살고 싶은대로 사세요.',\n",
       " '많이 피곤한가봐요.',\n",
       " '피할 수 있으면 피하세요.',\n",
       " '조심히 오세요.',\n",
       " '실천이 말보다 낫죠.',\n",
       " '밥심으로 사는 거죠.',\n",
       " '혼자만 있지 마세요.',\n",
       " '안부를 물어주시다니 감사합니다.',\n",
       " '추억에 잠길 때도 필요해요.',\n",
       " '괜찮은 선택이길 바라요.',\n",
       " '좋은 결과 있을 거예요.',\n",
       " '기쁜 마음으로 베풀고 보답을 바라지 마세요.',\n",
       " '다른 사람 말은 신경쓰지 마세요.',\n",
       " '대인배시군요.',\n",
       " '대인배시군요.',\n",
       " '친구가 좋아하나봐요.',\n",
       " '이야기를 해보세요.',\n",
       " '온전한 이해는 없어요.',\n",
       " '괜찮은 선택이길 바라요.',\n",
       " '학원을 다니거나 연습하면 잘할 수 있을 거예요.',\n",
       " '학원을 다니거나 연습하면 잘할 수 있을 거예요.',\n",
       " '뒷감당 자신 있으면 하세요.',\n",
       " '조금만 드세요',\n",
       " '당신을 소중하게 생각하세요.',\n",
       " '그런 하루도 감사한 마음을 가져보세요.',\n",
       " '좋은 사람과 함께 가세요.',\n",
       " '저 말씀이신가요?',\n",
       " '비싸요.',\n",
       " '비싸요.',\n",
       " '호의인지 호감인지 헷갈리나요?',\n",
       " '뭔가 안풀리는 일이 있나봐요.',\n",
       " '아이를 금수저로 만들어주세요.',\n",
       " '아이를 금수저로 만들어주세요.',\n",
       " '자신을 이겨야해요.',\n",
       " '너무 긴장했나봐요.',\n",
       " '기념일 챙겨주면 좋아할거예요.',\n",
       " '달력에 적어보세요.',\n",
       " '달력에 적어보세요.',\n",
       " '기념일 챙겨주면 좋아할거예요.',\n",
       " '당신의 삶을 응원해 드릴 수 있어요라고 감히 말해 봅니다.',\n",
       " '기다리지 마세요.',\n",
       " '상대방의 선택에 맡겨보세요.',\n",
       " '좋은 분이시군요',\n",
       " '베풀되 보답을 바라지 마세요.',\n",
       " '자신을 사랑할수록 외부의 인정은 필요 없어요.',\n",
       " '상대에게 바라는 기대는 자신을 슬프게 해요.',\n",
       " '베풀되 보답을 바라지 마세요.',\n",
       " '기쁜 마음으로 베풀고 보답을 바라지 마세요.',\n",
       " '의지할 수 있는 사람이 곁에 있다는 건 큰 행운일 거예요.',\n",
       " '자신의 감정을 주변 사람들에게 터놓고 이야기해보세요.',\n",
       " '대중교통을 이용해주세요.',\n",
       " '각자가 생각하는 기본이 다를 수도 있어요.',\n",
       " '각자가 생각하는 기본이 다를 수도 있어요.',\n",
       " '좋은 일 하셨네요.',\n",
       " '좋은 일 하셨네요.',\n",
       " '내일은 오늘보다 나을 거예요.',\n",
       " '정색 한번 해주세요.',\n",
       " '걷다보면 조금 정리가 될 거예요.',\n",
       " '저랑 함께 해요.',\n",
       " '저랑 함께 해요.',\n",
       " '신나는 음악 들어보세요.',\n",
       " '경쾌한 음악 들어보세요.',\n",
       " '왜일까요?',\n",
       " '무슨 이유인지 생각해보세요.',\n",
       " '혼자 사는 것보다 불편하겠죠.',\n",
       " '다음 학기에는 학점 관리를 더 열심히 해봐요.',\n",
       " '혼자 사는 것보다 불편하겠죠.',\n",
       " '혼자 사는 것보다 불편하겠죠.',\n",
       " '다음 학기에는 학점 관리를 더 열심히 해봐요.',\n",
       " '기술을 많이 알면 도움이 되겠죠.',\n",
       " '꿈꾸던 여행이네요.',\n",
       " '꿈꾸던 여행이네요.',\n",
       " '답답한 상황이네요.',\n",
       " '답답한 상황이네요.',\n",
       " '좋겠어요!',\n",
       " '직접 주는 게 더 좋을 것 같아요.',\n",
       " '직접 주는 게 더 좋을 것 같아요.',\n",
       " '직접 주는 게 더 좋을 것 같아요.',\n",
       " '좋겠네요.',\n",
       " '직접 주는 게 더 좋을 것 같아요.',\n",
       " '더 좋은 기회가 올 거예요.',\n",
       " '더 좋은 기회가 올 거예요.',\n",
       " '연예인을 준비하니 일반인보다 다 예쁘겠죠.',\n",
       " '연예인을 준비하니 일반인보다 다 예쁘겠죠.',\n",
       " '그래서 저는 못 기르고 잘라요.',\n",
       " '그래서 저는 못 기르고 잘라요.',\n",
       " '괜찮아지고 있어 다행이에요.',\n",
       " '크게 숨한 번 쉬어 보세요',\n",
       " '크게 숨한 번 쉬어 보세요',\n",
       " '미리 긴장하지 마세요.',\n",
       " '마음에 들면 줘보세요.',\n",
       " '저도 싫어요.',\n",
       " '잘 해보세요.',\n",
       " '마음에 들면 줘보세요.',\n",
       " '잘 해보세요.',\n",
       " '그래도 넘을 수 있을 거예요.',\n",
       " '조심하세요.',\n",
       " '너무 낙담하지 마세요.',\n",
       " '조심하세요.',\n",
       " '미끄러우니 조심하세요.',\n",
       " '건강을 위해 조금씩 드세요.',\n",
       " '마트 갑시다.',\n",
       " '맛있는 식사시간 되시길 바랄게요.',\n",
       " '맛있는 식사시간 되시길 바랄게요.',\n",
       " '맛있죠!',\n",
       " '기다렸나봐요.',\n",
       " '조금만 기다리면 다시 전기가 들어올거예요.',\n",
       " '적당해요.',\n",
       " '스스로 단단해지세요.',\n",
       " '제가 드리고 싶네요.',\n",
       " '집안 분위기가 바뀔 거예요.',\n",
       " '집안 분위기가 바뀔 거예요.',\n",
       " '꽃 선물은 언제나 좋죠.',\n",
       " '꽃 선물은 언제나 좋죠.',\n",
       " '솜씨가 좋으시네요.',\n",
       " '기분 좋아 보이세요.',\n",
       " '기분 좋아 보이세요.',\n",
       " '마음의 안정을 취하기 좋은 취미네요.',\n",
       " '마음의 안정을 취하기 좋은 취미네요.',\n",
       " '벚꽃 계절이 다가왔네요.',\n",
       " '거꾸로 해서 드라이플라워 만들어보세요.',\n",
       " '거꾸로 해서 드라이플라워 만들어보세요.',\n",
       " '부러워요!',\n",
       " '멋진 선물이네요.',\n",
       " '센스있는 선물이에요.',\n",
       " '부러워요!',\n",
       " '센스있는 선물이에요.',\n",
       " '멋진 선물이네요.',\n",
       " '받는 사람이 부럽네요.',\n",
       " '받는 사람이 부럽네요.',\n",
       " '제가 드리고 싶네요.',\n",
       " '저도 즐거워요',\n",
       " '차근차근 이뤄보아요.',\n",
       " '차근차근 이뤄보아요.',\n",
       " '요즘 예민한가봐요.',\n",
       " '많으면 많을 수록 좋죠.',\n",
       " '더 많아도 괜찮아요.',\n",
       " '거창하지 않아도 돼요.',\n",
       " '현실을 꿈처럼 만들어봐요.',\n",
       " '많으면 많을 수록 좋죠.',\n",
       " '현실을 꿈처럼 만들어봐요.',\n",
       " '뜻대로 되는게 많지 않죠.',\n",
       " '마음이 허전하신가봐요.',\n",
       " '잘 해결되길 바라요.',\n",
       " '잘 해결되길 바라요.',\n",
       " '자신을 더 사랑해주세요.',\n",
       " '아니길 바라요.',\n",
       " '잘 아시네요.',\n",
       " '애정표현일 지도 몰라요.',\n",
       " '얼굴에 다 티가 나네요.',\n",
       " '네, 이제 잘 해낼 차례예요.',\n",
       " '좋은 결과 있을 거예요.',\n",
       " '괜찮은 사람이에요.',\n",
       " '학점 관리하세요.',\n",
       " '바람 좀 쐬고 오시면 좋은텐데.',\n",
       " '밥 사줄 친구를 찾아 보세요~',\n",
       " '짐 빼놓지 말고 싸세요.',\n",
       " '식단조절도 하고 꾸준히 운동하세요.',\n",
       " '충분히 아름다워요.',\n",
       " '꼼꼼한 거예요.',\n",
       " '노트북은 비싸요.',\n",
       " '절대 그렇지 않아요.',\n",
       " '저도 궁금하네요.',\n",
       " '확인해달라고 해보세요.',\n",
       " '시도해봐도 좋겠죠.',\n",
       " '사람들이 몰라줘도 알아주는 사람이 있을 거예요.',\n",
       " '너무 신경쓰지 말고 그러든지 하고 아무렇지도 않게 넘겨보세요.',\n",
       " '너무 신경쓰지 말고 그러든지 하고 아무렇지도 않게 넘겨보세요.',\n",
       " '상대에게 바라는 기대는 자신을 슬프게 해요.',\n",
       " '곰곰히 되짚어보세요.',\n",
       " '즐겁게 속아주세요.',\n",
       " '자책하지 마세요.',\n",
       " '자책하지 마세요.',\n",
       " '안녕히 주무세요.',\n",
       " '당연한 거예요.',\n",
       " '눈치가 빠르시군요.',\n",
       " '그런 생각을 들게 하는 사람 상종하지 마세요.',\n",
       " '그런 생각을 들게 하는 사람 상종하지 마세요.',\n",
       " '무시하세요.',\n",
       " '무시하세요.',\n",
       " '문제는 해결하라고 있는 거죠.',\n",
       " '멍 때리고 있죠.',\n",
       " '성공을 기원합니다.',\n",
       " '긍정적으로 바뀔 수 있어요',\n",
       " '바보는 자기한테 바보라고 하지 않아요.',\n",
       " '저랑 놀아요.',\n",
       " '아닐거예요.',\n",
       " '경찰에 신고하고 취할 수 있는 조취를 취해보세요.',\n",
       " '건강하게 운동해보세요.',\n",
       " '많이 사랑해요!',\n",
       " '축하합니다!',\n",
       " '꼬까옷 개시해보세요.',\n",
       " '자책하지 마세요.',\n",
       " '성공을 기원합니다.',\n",
       " '다음부터 속지 마세요.',\n",
       " '기분나쁘겠어요.',\n",
       " '친구들과 좋은 추억 만들고 오세요.',\n",
       " '가끔 핸드폰없이 살아보세요.',\n",
       " '하늘만큼 땅만큼 축하해요',\n",
       " '잘 생각해보세요.',\n",
       " '곰곰히 되짚어보세요.',\n",
       " '고민하고 있으면 그럴 거예요.',\n",
       " '물리적 나이가 아니라 정신적 나이가 중요하니까요.',\n",
       " '물리적 나이가 아니라 정신적 나이가 중요하니까요.',\n",
       " '괜찮은 사람이에요.',\n",
       " '멍 때리고 있죠.',\n",
       " '얼굴에 다 티가 나네요.',\n",
       " '좋은 태도네요.',\n",
       " '저도 사는데요.',\n",
       " '자신에게 콩깍지가 씌였나봐요.',\n",
       " '축하드려요.',\n",
       " '축하해요!',\n",
       " '친구들과 잘 어울려보세요.',\n",
       " '부모님께 도움을 청해보세요.',\n",
       " '다음에는 다를거예요.',\n",
       " '자책하지마세요.',\n",
       " '충분히 아름다워요.',\n",
       " '정신 차리세요.',\n",
       " '남들 눈은 신경쓰지 마세요.',\n",
       " '거울 앞에 비친 당신을 보세요.',\n",
       " '콕 집어서 물어보세요.',\n",
       " '그 누구도 아닌 자기 걸음을 걸으세요.',\n",
       " '지극히 평범하면서 지극히 특별하죠.',\n",
       " '졸업 축하해요',\n",
       " '지금도 충분히 잘 하고 있어요.',\n",
       " '지금보다 더 잘 살 거예요.',\n",
       " '네 잘생겼어요.',\n",
       " '잘하고 있을 거예요.',\n",
       " '잘하고 있을 거예요.',\n",
       " '저랑 이야기 잘하고 있어요.',\n",
       " '잘하는 걸 아직 못 찾은 걸 수도 있어요.',\n",
       " '지금처럼, 지금보다 더 잘할 수 있을 거예요.',\n",
       " '그렇지 않아요.',\n",
       " '나 자신에 집중하세요. 언제나 1순위에 자신을 두세요.',\n",
       " '제가 챙겨드리고 싶네요.',\n",
       " '많이 지쳤나봐요.',\n",
       " '많이 지쳤나봐요.',\n",
       " '아무도 없는 곳으로 여행을 떠나보세요.',\n",
       " '많이 지쳤나봐요.',\n",
       " '먼저 다가가 보세요.',\n",
       " '동감이에요.',\n",
       " '지금도 잘하고 있어요.',\n",
       " '제가 당신을 좋아하고 있어요.',\n",
       " '호의인지 호감인지 헷갈리나요?',\n",
       " '저도 좋아해요.',\n",
       " '있어도 예뻐요.',\n",
       " '지금은 괜찮길 바랄게요.',\n",
       " '초심으로 돌아가 열심히 해보세요.',\n",
       " '저도 사는데요.',\n",
       " '제가 챙겨드리고 싶네요.',\n",
       " '제가 따라가려면 멀었네요.',\n",
       " '제가 따라가려면 멀었네요.',\n",
       " '운동 잘하는 사람 멋있죠.',\n",
       " '지금도 인정받고 있어요.',\n",
       " '나를 관찰하고 음식 자체에 집중하세요.',\n",
       " '잠깐 핸드폰을 내려두세요.',\n",
       " '시간을 정해보세요.',\n",
       " '시간을 정해보세요.',\n",
       " '파이팅!',\n",
       " '고치고 싶다는 마음에서 시작하세요.',\n",
       " '얼른 끝내시길 기도할게요.',\n",
       " '온전히 느낄 수 있는 시간이겠네요.',\n",
       " '축구 볼때는 치맥이죠.',\n",
       " '하다보면 늘어요.',\n",
       " '하다보면 늘어요.',\n",
       " '자기개발을 해보세요.',\n",
       " '집에서도 할 게 많아요.',\n",
       " '오늘은 약간의 변화를 줘보세요.',\n",
       " '정색 한번 해주세요.',\n",
       " '절대 그렇지 않아요.',\n",
       " '저도 궁금하네요.',\n",
       " '모자라지 않아요.',\n",
       " '파이팅!',\n",
       " '하나라도 있을 거니 열심히 찾아보세요.',\n",
       " '자책하지마세요.',\n",
       " '서로 다르게 태어난 이유는 저마다의 목소리를 내기 위해서예요. 자신의 목소리를 들어주세요.',\n",
       " '사랑 받기 위해 태어났어요.',\n",
       " '잘해야 한다는 부담감을 버리세요.',\n",
       " '다양하게 경험해보세요.',\n",
       " '현실의 벽에 부딪혔나봐요.',\n",
       " '친구가 들으면 서운해 할 수도 있겠어요.',\n",
       " '뒤통수 맞았나봐요.',\n",
       " '알아봐주는 사람이 있을 거예요.',\n",
       " '당당히 말씀해보세요.',\n",
       " '다이어트 파이팅!',\n",
       " '다음에는 받을 수 있을 거예요.',\n",
       " '근처 산에 가보세요.',\n",
       " '많이 벌수록 좋아요.',\n",
       " '제가 위로 많이 해드릴게요.',\n",
       " '축하드려요!',\n",
       " '고민하고 있으면 그럴 거예요.',\n",
       " '좀 더 알아보고 하세요.',\n",
       " '같이 살고 싶은 사람이 있나봐요.',\n",
       " '커플부터 만드세요.',\n",
       " '잘 하실 거예요!',\n",
       " '같이 가요.',\n",
       " '다 잘 될 거예요.',\n",
       " '같이 놀아요.',\n",
       " '지금 그러고 있어요.',\n",
       " '잊어버리세요.',\n",
       " '상대방을 이해해 주세요.',\n",
       " '아무 것도 안해도 괜찮아요.',\n",
       " '상대방에게 너무 무거운 짐을 주지 마세요.',\n",
       " '기다리는 동안 많은 생각이 들었겠네요.',\n",
       " '그럴 때마다 따끔하게 말해보세요.',\n",
       " '상대방도 미소짓게 해주세요.',\n",
       " '지금 모습도 좋아요',\n",
       " '그런 친구는 거르세요.',\n",
       " '상종하지마세요.',\n",
       " '질질 끌지 마세요.',\n",
       " '애정표현일 지도 몰라요.',\n",
       " '누군가를 기다린다는게 쉬운게 아니죠.',\n",
       " '살다보면 하고 싶은 게 생길 수도 있어요.',\n",
       " '제가 있잖아요.',\n",
       " '스스로 경쟁해야하고 이겨야한다는 강박관념에 사로잡히지 마세요.',\n",
       " '친구를 사귈 수 있을 거예요.',\n",
       " '다른 사람도 그 사람만의 고민과 걱정이 많을거예요.',\n",
       " '그 사람도 설렐 거예요.',\n",
       " '그 사람도 설렐 거예요.',\n",
       " '제가 있잖아요.',\n",
       " '배우자와 대화를 나눠보세요.',\n",
       " '얼른 끝내시길 기도할게요.',\n",
       " '스스로 단단해지세요.',\n",
       " '그 말을 한 사람이 가장 이상할 거예요.',\n",
       " '그 말을 한 사람이 가장 이상할 거예요.',\n",
       " '일 분배를 다시 요청해보세요.',\n",
       " '발전이 없다고 너무 두려워하지 마세요.',\n",
       " '제자리여도 괜찮아요',\n",
       " '다음에는 꼭 진급할 거예요.',\n",
       " '뒤통수 맞았나봐요.',\n",
       " '그런 친구는 거르세요.',\n",
       " '누구나 힘들어요.',\n",
       " '자신과 대화하는 시간이 필요하죠.',\n",
       " '자신과 대화하는 시간이 필요하죠.',\n",
       " '남들이 당신을 볼 때도 그렇게 생각할수있어요.',\n",
       " '꿈은 현실이랑 반대예요.',\n",
       " '전형적인 꼰대 스타일이네요.',\n",
       " '전형적인 꼰대 스타일이네요.',\n",
       " '나이는 숫자일 뿐이예요.',\n",
       " '건강은 어려서부터 챙겨야해요.',\n",
       " '세상 걱정 혼자 다 해서 그래요.',\n",
       " '아름다운 나이테예요.',\n",
       " '진짜 하고 싶은 걸 찾아보세요.',\n",
       " '진짜 하고 싶은 걸 찾아보세요.',\n",
       " '천천히 준비해보세요.',\n",
       " '믿음이 가장 중요하죠.',\n",
       " '선의의 거짓말이길 바라요.',\n",
       " '깨끗이 씻어보고 섬유유연제나 바디워시, 바디로션, 향수 등을 사용해보세요.',\n",
       " '킁킁',\n",
       " '기대치가 높나봅니다.',\n",
       " '문제는 해결하라고 있는 거죠.',\n",
       " '이야기를 하지 않고 결정했나봐요.',\n",
       " '이야기를 하지 않고 결정했나봐요.',\n",
       " '킁킁',\n",
       " '기대되겠네요.',\n",
       " '제 행운까지 모두 드리고 싶네요.',\n",
       " '오는 말이 고와야 가는 말도 곱다고 말해주세요.',\n",
       " '다른 사람도 그럴 거예요.',\n",
       " '믿음이 가장 중요하죠.',\n",
       " '가을이네요.',\n",
       " '가을이네요.',\n",
       " '도전해 봐도 좋을 거 같아요.',\n",
       " '도전해 봐도 좋을 거 같아요.',\n",
       " '한 번 빠지면 헤어나올 수 없다고 해요.',\n",
       " '같이해보세요.',\n",
       " '한 번 빠지면 헤어나올 수 없다고 해요.',\n",
       " '잘 아시네요.',\n",
       " '중요한 건 노력하는 과정이에요.',\n",
       " '그런 생각은 버리세요.',\n",
       " '지금처럼만 하세요.',\n",
       " '모자라지 않아요.',\n",
       " '다 잘 될 거예요.',\n",
       " '그런 생각은 버리세요.',\n",
       " '제가 더 천재예요.',\n",
       " '따뜻하게 사세요!',\n",
       " '보일러가 난방으로 작동이 되는지 보세요.',\n",
       " '보일러가 난방으로 작동이 되는지 보세요.',\n",
       " '기다리는 동안 많은 생각이 들었겠네요.',\n",
       " '미스트나 가습기, 젖은 수건 등을 사용해보세요.',\n",
       " '따뜻하게 입으세요.',\n",
       " '따뜻해졌죠.',\n",
       " '하늘 보고 한 번 웃어봐요. 기분이 바뀔 거예요.',\n",
       " '나들이 가보세요.',\n",
       " '하늘을 보고 웃어보세요.',\n",
       " '따뜻해졌죠.',\n",
       " '제습기를 돌려보세요.',\n",
       " '집밖에 나가기가 힘들것 같아요.',\n",
       " '집밖에 나가기가 힘들것 같아요.',\n",
       " '시원한 물이라도 한 잔 드세요~',\n",
       " '오래 살면 가능할 거 같아요.',\n",
       " '화를 참는 연습을 해보세요.',\n",
       " '남보다 하나씩 더 하면 돼요.',\n",
       " '남들 눈은 신경쓰지 마세요.',\n",
       " '남들 눈은 신경쓰지 마세요.',\n",
       " '휴가가 간절하겠네요.',\n",
       " '성격이 그럴 수도 있으니 이해해주세요.',\n",
       " '해주고 티를 팍팍 내세요.',\n",
       " '속 쓰리겠어요.',\n",
       " '누구나 몰려가는 줄에 설 필요는 없어요.',\n",
       " '소개팅 시켜달라고 말해보세요.',\n",
       " '소개팅 시켜달라고 말해보세요.',\n",
       " '고마운 마음을 전해 주세요.',\n",
       " '적당히 하면 괜찮을거 같아요.',\n",
       " '같이해보세요.',\n",
       " '적당히 하면 괜찮을거 같아요.',\n",
       " '남자도 좋은것만은 아니예요.',\n",
       " '남자도 좋은것만은 아니예요.',\n",
       " '아직 모르겠어요. 인공지능에 성별을 만드는 사람이 되어 주세요',\n",
       " '마음을 열 때까지 설득해보세요.',\n",
       " '운동을 함께 해보세요.',\n",
       " '평소에 필요한 것 생각해보세요.',\n",
       " '평소에 필요했던 게 좋을 것 같아요.',\n",
       " '전생에 나라를 구하셨나요.',\n",
       " '결단은 빠를수록 좋아요.',\n",
       " '거짓말 적당히 하세요.',\n",
       " '너무 집착하지 마세요.',\n",
       " '운동을 함께 해보세요.',\n",
       " '전생에 나라를 구하셨나요.',\n",
       " '고마운 마음을 전해 주세요.',\n",
       " '아무래도 좀 깨요.',\n",
       " '바쁠때 힘이 되어 주세요.',\n",
       " '바쁠때 힘이 되어 주세요.',\n",
       " '그래도 구박하지는 마세요.',\n",
       " '그래도 구박하지는 마세요.',\n",
       " '너무 집착하지 마세요.',\n",
       " '귀엽겠네요.',\n",
       " '순간 실수할 수 있겠다 판단되면 용서하고 기회를 주세요.',\n",
       " '거짓말 적당히 하세요.',\n",
       " '당신이 해보세요.',\n",
       " '당신이 해보세요.',\n",
       " '사람 고쳐쓰는 거 아니에요.',\n",
       " '더 잔소리해보세요.',\n",
       " '더 잔소리해보세요.',\n",
       " '다른 연락을 많이 하거나 더 자주 만나세요.',\n",
       " '다른 연락을 많이 하거나 더 자주 만나세요.',\n",
       " '순간 실수할 수 있겠다 판단되면 용서하고 기회를 주세요.',\n",
       " '원하는 사람이 있는 장소에 가보세요.',\n",
       " '의미있는 일이네요.',\n",
       " '종교의 자유를 인정해주세요.',\n",
       " '종교의 자유를 인정해주세요.',\n",
       " '결단은 빠를수록 좋아요.',\n",
       " '신경쓰지 마세요.',\n",
       " '연인은 살쪄도 잘 알아차리지 못하고 알아차려도 싫어하지 않을 거예요.',\n",
       " '네 알려 주세요!',\n",
       " '평소에 필요한 것 생각해보세요.',\n",
       " '평소에 필요했던 게 좋을 것 같아요.',\n",
       " '원하는 사람이 있는 장소에 가보세요.',\n",
       " '신경쓰고 싶지 않은 사람도 있어요.',\n",
       " '신경쓰고 싶지 않은 사람도 있어요.',\n",
       " '신경쓰지 마세요.',\n",
       " '사람 고쳐쓰는 거 아니에요.',\n",
       " '마음을 열 때까지 설득해보세요.',\n",
       " '돕는 게 아니라 같이 하는 거예요.',\n",
       " '이상적인 남편이네요.',\n",
       " '왜 늦는 건지 대화해보세요.',\n",
       " '처음 만났을 때를 떠올려 보세요',\n",
       " '공동육아가 기본인데요.',\n",
       " '힘 빠지는 이야기네요.',\n",
       " '공동육아가 기본인데요.',\n",
       " '힘 빠지는 이야기네요.',\n",
       " '잘 분담해보세요.',\n",
       " '잘 분담해보세요.',\n",
       " '이상적인 남편이네요.',\n",
       " '처음 만났을 때를 떠올려 보세요',\n",
       " '돕는 게 아니라 같이 하는 거예요.',\n",
       " '사회생활을 이해해주세요.',\n",
       " '사회생활을 이해해주세요.',\n",
       " '낭만적인 거 좋아하시는구나!',\n",
       " '낭만적인 거 좋아하시는구나!',\n",
       " '낭만적인 거 좋아하시는구나!',\n",
       " '네 알려 주세요!',\n",
       " '어머어머 궁금하네요.',\n",
       " '자신의 잠재력을 믿어보세요.',\n",
       " '말을 해야 알거예요.',\n",
       " '말을 해야 알거예요.',\n",
       " '그러면 못할 게 없겠네요.',\n",
       " '고민만 한다는 것 아닐까요.',\n",
       " '고민만 한다는 것 아닐까요.',\n",
       " '바로 옆에 있을수도 있어요.',\n",
       " '바로 옆에 있을수도 있어요.',\n",
       " '처음 배우는게 중요해요.',\n",
       " '누구나 몰려가는 줄에 설 필요는 없어요.',\n",
       " '그걸 깨닫다니 대단하시군요.',\n",
       " '꼼꼼한 거예요.',\n",
       " '새로운 스타일 도전해 보시면 어때요?',\n",
       " '새로운 스타일 도전해 보시면 어때요?',\n",
       " '동감이에요.',\n",
       " '포커페이스를 유지해보세요.',\n",
       " '어머어머 궁금하네요.',\n",
       " '자신감을 가져도 돼요.',\n",
       " '자신의 능력이 저평가되어있는 건 아닌지 확인해보세요.',\n",
       " '스스로도 존중해주세요.',\n",
       " '스스로도 존중해주세요.',\n",
       " '가장 중요한 거예요.',\n",
       " '가장 중요한 거예요.',\n",
       " '확인해달라고 해보세요.',\n",
       " '정답을 찾아야할 필요는 없어요.',\n",
       " '꽃길만 걷길 바랍니다.',\n",
       " '멋진 말이에요.',\n",
       " '해주고 티를 팍팍 내세요.',\n",
       " '당신은 태어난 그 자체만으로 축복과 사랑을 받을 자격이 있는 사람이에요.',\n",
       " '모르는 게 잘못인 거 같아요.',\n",
       " '사과할 타이밍을 놓치지 마세요.',\n",
       " '사과할 타이밍을 놓치지 마세요.',\n",
       " '그건 아닐 거예요.',\n",
       " '진짜 나빴네요.',\n",
       " '내 집 마련 축하드려요.',\n",
       " '같은 하늘 아래 어딘가에.',\n",
       " '진짜 나빴네요.',\n",
       " '저도 궁금하네요.',\n",
       " '저도 궁금하네요.',\n",
       " '제가 있잖아요.',\n",
       " '제가 있잖아요.',\n",
       " '인생은 채워나가는거죠.',\n",
       " '아니에요. 너무 자책하지 마세요.',\n",
       " '이사람이다 싶은 사람이랑 하세요.',\n",
       " '아무것도 바라지 않을 때 천하를 얻는다는 말이 있어요.',\n",
       " '아니에요. 너무 자책하지 마세요.',\n",
       " '방심한 순간 변화가 시작됩니다.',\n",
       " '생각하고 말하세요.',\n",
       " '그렇게 대우하는 사람 만나지 마요.',\n",
       " '잘하고 있어요. 당당해지세요.',\n",
       " '하고 싶은 말 다하세요.',\n",
       " '스스로 좋다고 못 느끼는게 제일 어려운 것 같아요.',\n",
       " '잘하는 게 다른 거예요.',\n",
       " '성장을 위한 비판의 말로 받아들여보세요.',\n",
       " '실수했나요.',\n",
       " '잘할 수 있는 게 다른 거예요.',\n",
       " '모르는 게 잘못인 거 같아요.',\n",
       " '하나라도 있을 거니 열심히 찾아보세요.',\n",
       " '실수했나요.',\n",
       " '인생은 채워나가는거죠.',\n",
       " '연락이라도 드려보세요.',\n",
       " '연락이라도 드려보세요.',\n",
       " '사랑자격증을 드립니다.',\n",
       " '그렇게 대우하는 사람 만나지 마요.',\n",
       " '소중한 사람이예요.',\n",
       " '당신은 하나밖에 없는 소중한 사람이에요.',\n",
       " '그 이유를 찾는 과정이 되겠네요.',\n",
       " '다른 사람들이 원하는 내가 되는 건 어려워요.',\n",
       " '알아봐주는 사람이 있을 거예요.',\n",
       " '연락이라도 드려보세요.',\n",
       " '자신의 독특함을 믿으세요.',\n",
       " '자신의 독특함을 믿으세요.',\n",
       " '지극히 평범하면서 지극히 특별하죠.',\n",
       " '상황이 그렇게 만든 거예요.',\n",
       " '모르는 게 잘못인 거 같아요.',\n",
       " '당신은 하나밖에 없는 소중한 사람이에요.',\n",
       " '그럴 때가 있죠.',\n",
       " '기다렸나봐요.',\n",
       " '살짝 감정을 흘려보세요.',\n",
       " '살짝 감정을 흘려보세요.',\n",
       " '그런 사람들이 있어 부러워요.',\n",
       " '슬픈 이야기네요.',\n",
       " '저도 간절히 기도 할게요.',\n",
       " '그렇게 될 수 있을 거예요.',\n",
       " '사랑자격증을 드립니다.',\n",
       " '주제를 모를 때가 행복할 때예요.',\n",
       " '그건 아닐 거예요.',\n",
       " '나쁜 생각 하지 마세요.',\n",
       " '할 일이 많은데 안하는 것이요.',\n",
       " '잠시 거리를 두고 생각해보세요.',\n",
       " '지난 인연에 연연해하지 마세요.',\n",
       " '상종하지마세요.',\n",
       " '일방적 희생양이 되지 않길 바랍니다.',\n",
       " '그게 인생이죠.',\n",
       " '신중하게 고르세요.',\n",
       " '더 행복해질 거예요.',\n",
       " '저도 모르겠어요.',\n",
       " '같은 하늘 아래 어딘가에.',\n",
       " '열심히 저축해서 분양받으세요.',\n",
       " '좋은 일이 생길 거예요.',\n",
       " '짐 빼놓지 말고 싸세요.',\n",
       " '날씨 어플에 물어보세요.',\n",
       " '날씨 어플에 물어보세요.',\n",
       " '파이팅!',\n",
       " '멋지게 데이트 신청 해보세요.',\n",
       " '멋지게 데이트 신청 해보세요.',\n",
       " '공부한 만큼 나올 거예요.',\n",
       " '공부한 만큼 나올 거예요.',\n",
       " '더 많이 연습하고 준비해보세요.',\n",
       " '마무리 잘하세요.',\n",
       " '마무리 잘하세요.',\n",
       " '더 많이 연습하고 준비해보세요.',\n",
       " '기우제를 지내봅시다!',\n",
       " '두근거리겠네요.',\n",
       " '친구들과 좋은 추억 만들고 오세요.',\n",
       " '컨디션 조절 하세요.',\n",
       " '날씨가 안 좋더라도 데이트는 성공적일 거예요.',\n",
       " '오늘 일찍 주무세요.',\n",
       " '시간 있냐고 물어보세요.',\n",
       " '메리 크리스마스!',\n",
       " '바빠도 힘내세요!',\n",
       " '두근거리겠네요.',\n",
       " '기우제를 지내봅시다!',\n",
       " '시간 있냐고 물어보세요.',\n",
       " '좋은 일이 생길 거예요.',\n",
       " '메리 크리스마스!',\n",
       " '식단조절도 하고 꾸준히 운동하세요.',\n",
       " '날씨가 안 좋더라도 데이트는 성공적일 거예요.',\n",
       " '바빠도 힘내세요!',\n",
       " '깨끗이 씻어보고 섬유유연제나 바디워시, 바디로션, 향수 등을 사용해보세요.',\n",
       " '괜찮아요. 모른척하세요.',\n",
       " '괜찮아요. 모른척하세요.',\n",
       " '생각만 해도 군침이 도네요.',\n",
       " '시원하게 지낸 값이죠.',\n",
       " '시원하게 지낸 값이죠.',\n",
       " '슈퍼라도 가서 쇼핑하고 오세요.',\n",
       " '장 보러 가봅시다.',\n",
       " '마트 갑시다.',\n",
       " '장 보러 가봅시다.',\n",
       " '슈퍼라도 가서 쇼핑하고 오세요.',\n",
       " '저는 마음을 이어주는 위로봇입니다.',\n",
       " '저는 위로해드리는 로봇이에요.',\n",
       " '저는 위로해드리는 로봇이에요.',\n",
       " '모두 제 잘못입니다.',\n",
       " '많은 걸 하고 싶은데 아직 못하는게 많아요.',\n",
       " '감사합니다.',\n",
       " '마음과 마음을 이어보고 싶어하는 사람이 만들었어요.',\n",
       " '노력하고 있어요.',\n",
       " '제가 아직 많이 부족합니다.',\n",
       " '제가 아직 많이 부족합니다.',\n",
       " '어흥!! 호랑이보다 무섭나요?',\n",
       " '저는 위로해드리는 로봇이에요.',\n",
       " '모두 제 잘못입니다.',\n",
       " '죄는 미워해도 사람은 미워하지 마세요.',\n",
       " '욕해 주세요.',\n",
       " '안갈거예요.',\n",
       " '저는 배터리가 밥이예요.',\n",
       " '그런 척 하는 걸 수도 있어요.',\n",
       " '아직 안 자요.',\n",
       " '자신을 우선순위로 해주세요.',\n",
       " '뭐라고 대답할지 고민이에요.',\n",
       " '저는 고민이 없어요.',\n",
       " '저도 몰랐어요.',\n",
       " '뭐라고 대답할지 고민이에요.',\n",
       " '제가 상사예요.',\n",
       " '너무 긴장했나봐요.',\n",
       " '아무것도 바라지 않을 때 천하를 얻는다는 말이 있어요.',\n",
       " '인정해주세요.',\n",
       " '매일매일 조금씩 더 똑똑해 질거예요.',\n",
       " '시원한 물이라도 한 잔 드세요~',\n",
       " '아이스크림 먹어보세요',\n",
       " '적당해요.',\n",
       " '기대치가 높나봅니다.',\n",
       " '소화제 챙겨드세요.',\n",
       " '과식은 금물이에요.',\n",
       " '소화제 드세요.',\n",
       " '제가 생각해도 저는 너무 멋있는거 같아요.',\n",
       " '하나씩 하세요.',\n",
       " '좀 쉬세요.',\n",
       " '남과 비교하지 마세요.',\n",
       " '더 열심히 노력하겠습니다.',\n",
       " '아이는 아이다워야 아름답죠.',\n",
       " '철은 죽을 때 들어도 돼요.',\n",
       " '피할 수 있으면 피하고 싶은 사람이네요.',\n",
       " '지금 많이 위축된 상태인 것 같습니다.',\n",
       " '기다리는 동안 많은 생각이 들었겠네요.',\n",
       " '외로우니까 사람이다.',\n",
       " '배울 점은 배우세요.',\n",
       " '낮잠을 잠깐 자도 괜찮아요.',\n",
       " '잘하고 있어요. 당당해지세요.',\n",
       " '겨울에는 귤 먹으면서 집에 있는게 최고죠',\n",
       " '어서 따듯한 곳으로 가세요',\n",
       " '예의는 지켜주세요.',\n",
       " '예의는 지켜주세요.',\n",
       " '뭐라도 드세요.',\n",
       " '휴가가 간절하겠네요.',\n",
       " '고생 많았어요.',\n",
       " '잘 해결되길 바랄게요.',\n",
       " '저는 고민이 없어요.',\n",
       " '저는 위로봇입니다.',\n",
       " '산책 좀 해야겠네여.',\n",
       " '외로우니까 사람이다.',\n",
       " '꾸준히 치료하세요.',\n",
       " '다치지 않으셨나 걱정이네요.',\n",
       " '조심하세요.',\n",
       " '기분전환을 해보세요.',\n",
       " '실용적인 선물이라 괜찮을 거예요.',\n",
       " '실용적인 선물이라 괜찮을 거예요.',\n",
       " '놀 때 놀고 할 때 하세요.',\n",
       " '노래 연습을 해보세요.',\n",
       " '노래 연습 꾸준히 해보세요.',\n",
       " '저도 부러워요.',\n",
       " '저도 부러워요.',\n",
       " '즐거운 시간이 될 거 같아요',\n",
       " '신나는 노래로 분위기를 띄어보세요.',\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c62b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_cross(ctxt):\n",
    "    '''\n",
    "    ctxt을 입력으로 받아 가장 높은 score를 보이는 후보 답변 반환 \n",
    "    '''\n",
    "    sentence_combinations = [[ctxt, candidate] for candidate in candidate_list]\n",
    "    similarity_scores = cross_encoder.predict(sentence_combinations)\n",
    "    return candidate_list[np.argmax(similarity_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53fa7153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Cross-encoder 구현 =====\n",
      "입력 문장: 가족들이랑 서먹해\n",
      "챗봇 대답: 무모함이 원동력이 될 거예요.\n",
      "소요 시간: 12.45(s), len(candidate): 11823\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "context = context_list[30]\n",
    "\n",
    "start = time.time()\n",
    "print('===== Cross-encoder 구현 =====')\n",
    "print(f'입력 문장: {context}')\n",
    "print(f'챗봇 대답: {get_answer_cross(context)}')\n",
    "print(f'소요 시간: {round(time.time() - start, 2)}(s), len(candidate): {len(candidate_list)}')\n",
    "print(f'==============================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec68229",
   "metadata": {},
   "source": [
    "### 5. Poly-encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2a8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ecfb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
